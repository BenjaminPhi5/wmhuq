{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0f17b7-2d77-4cff-b5a1-9e65edeb869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strawberry\n"
     ]
    }
   ],
   "source": [
    "print(\"strawberry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30a30ac-ab1c-47fd-b725-1e8719756516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# dataset\n",
    "from twaidata.torchdatasets.in_ram_ds import MRISegmentation2DDataset, MRISegmentation3DDataset\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "\n",
    "# model\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_deterministic import HyperMapp3r\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_DDU import HyperMapp3rDDU\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_SSN import HyperMapp3rSSN\n",
    "\n",
    "\n",
    "# augmentation and pretrain processing\n",
    "from trustworthai.utils.augmentation.standard_transforms import RandomFlip, GaussianBlur, GaussianNoise, \\\n",
    "                                                            RandomResizeCrop, RandomAffine, \\\n",
    "                                                            NormalizeImg, PairedCompose, LabelSelect, \\\n",
    "                                                            PairedCentreCrop, CropZDim\n",
    "# loss function\n",
    "from trustworthai.utils.losses_and_metrics.per_individual_losses import (\n",
    "    dice_loss,\n",
    "    log_cosh_dice_loss,\n",
    "    TverskyLoss,\n",
    "    FocalTverskyLoss,\n",
    "    DiceLossMetric\n",
    ")\n",
    "from torch.nn import BCELoss, MSELoss, BCEWithLogitsLoss\n",
    "import torch.nn as nn\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import torch.distributions as td\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e3f18-0236-4cf8-8e26-e76661200c01",
   "metadata": {},
   "source": [
    "### Set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a450935a-a087-4b81-816b-cd4397db8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3407\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd568d-9fc6-4868-9d4a-617163ae6e9e",
   "metadata": {},
   "source": [
    "### define datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401f9272-0a3b-4670-8880-82f04714d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "is3D = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91099153-5471-4603-8d5e-f8079445aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_dir = \"/disk/scratch/s2208943/ipdis/preprep/out_data/collated/\"\n",
    "root_dir = \"/media/benp/NVMEspare/datasets/preprocessing_attempts/local_results/collated/\"\n",
    "wmh_dir = root_dir + \"WMH_challenge_dataset/\"\n",
    "ed_dir = root_dir + \"EdData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c6f9d9-dd1d-411f-a85b-26a3d82cc48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = [\n",
    "            wmh_dir + d for d in [\"Singapore\", \"Utrecht\", \"GE3T\"]\n",
    "          ]\n",
    "\n",
    "# domains = [\n",
    "#             wmh_dir + d for d in [\"Singapore\", \"Utrecht\", \"GE3T\"]\n",
    "#           ] + [\n",
    "#             ed_dir + d for d in [\"domainA\", \"domainB\", \"domainC\", \"domainD\"]\n",
    "#           ]\n",
    "\n",
    "\n",
    "# domains = [\n",
    "#             ed_dir + d for d in [\"domainA\", \"domainB\", \"domainC\", \"domainD\"]\n",
    "#           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c807e6-40f1-48bc-aed7-d395b569b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation definintion\n",
    "def get_transforms(is_3D):\n",
    "    transforms = [\n",
    "        LabelSelect(label_id=1),\n",
    "        RandomFlip(p=0.5, orientation=\"horizontal\"),\n",
    "        # GaussianBlur(p=0.5, kernel_size=7, sigma=(.1, 1.5)),\n",
    "        # GaussianNoise(p=0.2, mean=0, sigma=0.2),\n",
    "        # RandomAffine(p=0.2, shear=(.1,3.)),\n",
    "        # RandomAffine(p=0.2, degrees=5),\n",
    "        #RandomResizeCrop(p=1., scale=(0.6, 1.), ratio=(3./4., 4./3.))\n",
    "        RandomResizeCrop(p=1., scale=(0.3, 0.5), ratio=(3./4., 4./3.)) # ssn\n",
    "    ]\n",
    "    if not is_3D:\n",
    "        transforms.append(lambda x, y: (x, y.squeeze().type(torch.long)))\n",
    "        return PairedCompose(transforms)\n",
    "    else:\n",
    "        transforms.append(CropZDim(size=32, minimum=0, maximum=-1))\n",
    "        transforms.append(lambda x, y: (x, y.squeeze().type(torch.long)))\n",
    "        return PairedCompose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e417fb72-4419-456d-b5ce-e14f0591651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do train validate test split\n",
    "test_proportion = 0.1\n",
    "validation_proportion = 0.2\n",
    "\n",
    "def train_val_test_split(dataset, val_prop, test_prop, seed):\n",
    "    # I think the sklearn version might be prefereable for determinism and things\n",
    "    # but that involves fiddling with the dataset implementation I think....\n",
    "    size = len(dataset)\n",
    "    test_size = int(test_prop*size) \n",
    "    val_size = int(val_prop*size)\n",
    "    train_size = size - val_size - test_size\n",
    "    train, val, test = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567c247d-2265-4012-bc80-a92b4f2adec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "# this step is quite slow, all the data is being loaded into memory\n",
    "if is3D:\n",
    "    datasets_domains = [MRISegmentation3DDataset(root_dir, domain, transforms=get_transforms(is_3D=True)) for domain in domains]\n",
    "else:\n",
    "    datasets_domains = [MRISegmentation2DDataset(root_dir, domain, transforms=get_transforms(is_3D=False)) for domain in domains]\n",
    "\n",
    "# split into train, val test datasets\n",
    "datasets = [train_val_test_split(dataset, validation_proportion, test_proportion, seed) for dataset in datasets_domains]\n",
    "\n",
    "# concat the train val test datsets\n",
    "train_dataset = ConcatDataset([ds[0] for ds in datasets])\n",
    "val_dataset = ConcatDataset([ds[1] for ds in datasets])\n",
    "test_dataset = ConcatDataset([ds[2] for ds in datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f5844a-5c39-47ff-897e-ad36de855931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2506, 716, 358)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abfe0f1c-3c76-4069-b698-d7dd2a9c67f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataloaders\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size = 16, shuffle=False, num_workers=4)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 8, shuffle=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71898c27-608d-4ad3-9375-7710bfeb23a5",
   "metadata": {},
   "source": [
    "### setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cf9f593-6e8a-4c26-b9de-0ae024870248",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels = 1\n",
    "\n",
    "if is3D:\n",
    "    pass\n",
    "else:\n",
    "    # encoder_features=[16, 32, 64, 128, 256] # orig: [16, 32, 64, 128, 256]\n",
    "    # decoder_features=encoder_features[::-1][1:]\n",
    "    model = HyperMapp3r(dims=2,\n",
    "                 in_channels=3,\n",
    "                 out_channels=2,\n",
    "                 encoder_features=[16, 32, 64, 128, 256],\n",
    "                 decoder_features=[128, 64, 32, 16],\n",
    "                 softmax=False,\n",
    "                 up_res_blocks=False,\n",
    "                 block_params={\n",
    "                     \"dropout_p\":0.1,\n",
    "                     \"norm_type\":\"in\", \n",
    "                     \"dropout_both_layers\":False,\n",
    "                 }\n",
    "                   )\n",
    "    \n",
    "    \n",
    "    optimizer_params={\"lr\":2e-3}\n",
    "    lr_scheduler_params={\"step_size\":20, \"gamma\":0.1}\n",
    "    # optimizer_params={\"lr\":2e-3, \"momentum\":0.6}\n",
    "    # optimizer = torch.optim.RMSprop\n",
    "    # lr_scheduler_params={\"milestones\":[10,100,200], \"gamma\":0.5}\n",
    "    # lr_scheduler_constructor = torch.optim.lr_scheduler.MultiStepLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d24859dc-d219-4d6f-8a17-7c9b8cb79211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "HyperMapp3r                              --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─Conv2d: 2-1                       [1, 16, 64, 64]           448\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─HM3Block: 2-2                     [1, 16, 64, 64]           --\n",
       "│    │    └─InstanceNorm2d: 3-1          [1, 16, 64, 64]           --\n",
       "│    │    └─LeakyReLU: 3-2               [1, 16, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-3                  [1, 16, 64, 64]           2,304\n",
       "│    │    └─Dropout2d: 3-4               [1, 16, 64, 64]           --\n",
       "│    │    └─InstanceNorm2d: 3-5          [1, 16, 64, 64]           --\n",
       "│    │    └─LeakyReLU: 3-6               [1, 16, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 16, 64, 64]           2,304\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─Conv2d: 2-3                       [1, 32, 32, 32]           4,640\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─HM3Block: 2-4                     [1, 32, 32, 32]           --\n",
       "│    │    └─InstanceNorm2d: 3-8          [1, 32, 32, 32]           --\n",
       "│    │    └─LeakyReLU: 3-9               [1, 32, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 32, 32, 32]           9,216\n",
       "│    │    └─Dropout2d: 3-11              [1, 32, 32, 32]           --\n",
       "│    │    └─InstanceNorm2d: 3-12         [1, 32, 32, 32]           --\n",
       "│    │    └─LeakyReLU: 3-13              [1, 32, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-14                 [1, 32, 32, 32]           9,216\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─Conv2d: 2-5                       [1, 64, 16, 16]           18,496\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─HM3Block: 2-6                     [1, 64, 16, 16]           --\n",
       "│    │    └─InstanceNorm2d: 3-15         [1, 64, 16, 16]           --\n",
       "│    │    └─LeakyReLU: 3-16              [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-17                 [1, 64, 16, 16]           36,864\n",
       "│    │    └─Dropout2d: 3-18              [1, 64, 16, 16]           --\n",
       "│    │    └─InstanceNorm2d: 3-19         [1, 64, 16, 16]           --\n",
       "│    │    └─LeakyReLU: 3-20              [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-21                 [1, 64, 16, 16]           36,864\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─Conv2d: 2-7                       [1, 128, 8, 8]            73,856\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─HM3Block: 2-8                     [1, 128, 8, 8]            --\n",
       "│    │    └─InstanceNorm2d: 3-22         [1, 128, 8, 8]            --\n",
       "│    │    └─LeakyReLU: 3-23              [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-24                 [1, 128, 8, 8]            147,456\n",
       "│    │    └─Dropout2d: 3-25              [1, 128, 8, 8]            --\n",
       "│    │    └─InstanceNorm2d: 3-26         [1, 128, 8, 8]            --\n",
       "│    │    └─LeakyReLU: 3-27              [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-28                 [1, 128, 8, 8]            147,456\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─Conv2d: 2-9                       [1, 256, 4, 4]            295,168\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─HM3Block: 2-10                    [1, 256, 4, 4]            --\n",
       "│    │    └─InstanceNorm2d: 3-29         [1, 256, 4, 4]            --\n",
       "│    │    └─LeakyReLU: 3-30              [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-31                 [1, 256, 4, 4]            589,824\n",
       "│    │    └─Dropout2d: 3-32              [1, 256, 4, 4]            --\n",
       "│    │    └─InstanceNorm2d: 3-33         [1, 256, 4, 4]            --\n",
       "│    │    └─LeakyReLU: 3-34              [1, 256, 4, 4]            --\n",
       "│    │    └─Conv2d: 3-35                 [1, 256, 4, 4]            589,824\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─HMUpsampleBlock: 2-11             [1, 128, 8, 8]            --\n",
       "│    │    └─InstanceNorm2d: 3-36         [1, 256, 4, 4]            --\n",
       "│    │    └─LeakyReLU: 3-37              [1, 256, 4, 4]            --\n",
       "│    │    └─ConvTranspose2d: 3-38        [1, 128, 8, 8]            295,040\n",
       "│    │    └─InstanceNorm2d: 3-39         [1, 128, 8, 8]            --\n",
       "│    │    └─LeakyReLU: 3-40              [1, 128, 8, 8]            --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─HMFeatureBlock: 2-12              [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-41                 [1, 128, 8, 8]            295,040\n",
       "│    │    └─InstanceNorm2d: 3-42         [1, 128, 8, 8]            --\n",
       "│    │    └─LeakyReLU: 3-43              [1, 128, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-44                 [1, 128, 8, 8]            16,512\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─HMUpsampleBlock: 2-13             [1, 64, 16, 16]           --\n",
       "│    │    └─InstanceNorm2d: 3-45         [1, 128, 8, 8]            --\n",
       "│    │    └─LeakyReLU: 3-46              [1, 128, 8, 8]            --\n",
       "│    │    └─ConvTranspose2d: 3-47        [1, 64, 16, 16]           73,792\n",
       "│    │    └─InstanceNorm2d: 3-48         [1, 64, 16, 16]           --\n",
       "│    │    └─LeakyReLU: 3-49              [1, 64, 16, 16]           --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─HMFeatureBlock: 2-14              [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-50                 [1, 64, 16, 16]           73,792\n",
       "│    │    └─InstanceNorm2d: 3-51         [1, 64, 16, 16]           --\n",
       "│    │    └─LeakyReLU: 3-52              [1, 64, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-53                 [1, 64, 16, 16]           4,160\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─HMUpsampleBlock: 2-15             [1, 32, 32, 32]           --\n",
       "│    │    └─InstanceNorm2d: 3-54         [1, 64, 16, 16]           --\n",
       "│    │    └─LeakyReLU: 3-55              [1, 64, 16, 16]           --\n",
       "│    │    └─ConvTranspose2d: 3-56        [1, 32, 32, 32]           18,464\n",
       "│    │    └─InstanceNorm2d: 3-57         [1, 32, 32, 32]           --\n",
       "│    │    └─LeakyReLU: 3-58              [1, 32, 32, 32]           --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─HMFeatureBlock: 2-16              [1, 32, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-59                 [1, 32, 32, 32]           18,464\n",
       "│    │    └─InstanceNorm2d: 3-60         [1, 32, 32, 32]           --\n",
       "│    │    └─LeakyReLU: 3-61              [1, 32, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-62                 [1, 32, 32, 32]           1,056\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─HMUpsampleBlock: 2-17             [1, 16, 64, 64]           --\n",
       "│    │    └─InstanceNorm2d: 3-63         [1, 32, 32, 32]           --\n",
       "│    │    └─LeakyReLU: 3-64              [1, 32, 32, 32]           --\n",
       "│    │    └─ConvTranspose2d: 3-65        [1, 16, 64, 64]           4,624\n",
       "│    │    └─InstanceNorm2d: 3-66         [1, 16, 64, 64]           --\n",
       "│    │    └─LeakyReLU: 3-67              [1, 16, 64, 64]           --\n",
       "├─Conv2d: 1-6                            [1, 32, 64, 64]           9,248\n",
       "├─LeakyReLU: 1-7                         [1, 32, 64, 64]           --\n",
       "├─Conv2d: 1-8                            [1, 2, 64, 64]            66\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "│    └─Conv2d: 2-18                      [1, 2, 16, 16]            130\n",
       "│    └─Conv2d: 2-19                      [1, 2, 32, 32]            66\n",
       "==========================================================================================\n",
       "Total params: 2,774,390\n",
       "Trainable params: 2,774,390\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 288.90\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 6.08\n",
       "Params size (MB): 11.10\n",
       "Estimated Total Size (MB): 17.38\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7054dd-9102-46c2-b23d-071bcf816d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "debcacdf-f434-48e8-875b-83f641a8707c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = dice_loss\n",
    "#loss = torch.nn.CrossEntropyLoss(weight=torch.Tensor([0.968, 0.032]))\n",
    "#loss = FocalLoss(gamma=1., reduction='mean', alpha=torch.Tensor([1-0.968, 1-0.032]))\n",
    "#loss = log_cosh_dice_loss\n",
    "#loss = TverskyLoss(beta=0.7)\n",
    "#loss = FocalTverskyLoss(beta=0.7, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429aa4cb-2158-4b7f-96c3-992fc32faf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_params={\"lr\":2e-4, \"momentum\":0.6}\n",
    "optimizer = torch.optim.RMSprop\n",
    "lr_scheduler_params={\"milestones\":[100,200], \"gamma\":0.5}\n",
    "lr_scheduler_constructor = torch.optim.lr_scheduler.MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e60ae5da-3073-4c42-86b1-753fc874b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = StandardLitModelWrapper(model, loss, \n",
    "#                                 logging_metric=lambda : None,\n",
    "#                                 optimizer_params=optimizer_params,\n",
    "#                                 lr_scheduler_params=lr_scheduler_params,\n",
    "#                                 is_uq_model=False,\n",
    "#                                 optimizer_constructor=optimizer,\n",
    "#                                 lr_scheduler_constructor=lr_scheduler_constructor\n",
    "#                                )\n",
    "checkpoint=\"epoch=38-step=1560.ckpt\"\n",
    "model = StandardLitModelWrapper.load_from_checkpoint(checkpoint, model=model, loss=loss, logging_metric = lambda : None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "669b2864-efcf-4e7b-bbd8-ea20000f128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"./lightning_logs\"\n",
    "strategy = None\n",
    "# strategy = \"deepspeed_stage_2\"\n",
    "# strategy = \"dp\"\n",
    "#strategy = \"deepspeed_stage_2_offload\"\n",
    "\n",
    "accelerator=\"gpu\"\n",
    "devices=1\n",
    "max_epochs=500\n",
    "precision = 32\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_dir, save_top_k=2, monitor=\"val_loss\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=500, verbose=\"False\", mode=\"min\", check_finite=True)\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    max_epochs=max_epochs,\n",
    "    strategy=strategy,\n",
    "    precision=precision,\n",
    "    default_root_dir=checkpoint_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6dcd70-e508-4f86-853b-a11a8f58e777",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22b84231-df5d-4cb4-ae82-2dc586ebb311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "517528f4-459e-42b4-af21-254a1f5f7bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1656a72d7a83459a9b666334a6b19bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss            0.20572760701179504\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.20572760701179504}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef8ff8b4-a942-44ec-ac7d-8183cf8f74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b28501-0faa-4856-bf63-e6224cdaca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_hat = model(x1.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "958ecf07-fba2-4dee-9117-de2872009bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 224, 160]),\n",
       " torch.Size([8, 2, 224, 160]),\n",
       " torch.Size([8, 3, 224, 160]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape, y_hat.shape, x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9a09448-a5c4-4cf5-9775-de22b8d145ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.6490)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac0566ec-d196-4fb3-ae30-4441125935aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3567)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_loss(y_hat, y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd8f839d-8dca-4c55-b9ed-9a364dba3e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3293)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TverskyLoss(beta=0.7)(y_hat, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13e4d419-da3b-4888-b790-17530235518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_dice(y_hat, y_true):\n",
    "    y_hat = torch.nn.functional.softmax(y_hat, dim=1).argmax(dim=1)\n",
    "    # count how many times the ground truth and target have nothing in them\n",
    "    s0 = y_hat.shape[0]\n",
    "    y_hat = y_hat.view(s0, -1)\n",
    "    y_true = y_true.view(s0, -1)\n",
    "    # print(torch.sum(torch.sum(y_true, dim=1) == 0))\n",
    "    # print(torch.sum(torch.sum(y_hat, dim=1) == 0))\n",
    "    # print(torch.sum(torch.logical_and(torch.sum(y_hat, dim=1) == 0, torch.sum(y_true, dim=1) == 0)))\n",
    "    ignores = torch.sum(torch.logical_and(torch.sum(y_hat, dim=1) == 0, torch.sum(y_true, dim=1) == 0))\n",
    "    \n",
    "    \n",
    "    numerator = torch.sum(2 * y_true * y_hat, dim=1)\n",
    "    # print(numerator)\n",
    "    denominator = torch.sum(y_true + y_hat, dim=1)\n",
    "    # print(denominator)\n",
    "    \n",
    "    return torch.sum((numerator)/ (denominator + 1e-8)) / (s0-ignores) # s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4800f5e4-2592-4890-bc98-21a839b13692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_dice(y_hat, y_true):\n",
    "    # print(y_hat.shape)\n",
    "    y_hat = torch.nn.functional.softmax(y_hat, dim=0).argmax(dim=0)\n",
    "    \n",
    "    if torch.sum(y_hat) == 0 and torch.sum(y_true) == 0:\n",
    "        return \"n/a\"\n",
    "    \n",
    "    # print(y_hat.shape)\n",
    "    # print(y_true.shape)\n",
    "    \n",
    "    numerator = torch.sum(2 * y_hat * y_true)\n",
    "    denominator = torch.sum(y_hat + y_true)\n",
    "    return numerator / (denominator + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e664ad3f-74f0-46e3-ae32-01fe9242016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_pred, y_true):\n",
    "    y_pred = torch.nn.functional.softmax(y_pred, dim=1).argmax(dim=1)\n",
    "    denominator = torch.sum(y_pred) + torch.sum(y_true)\n",
    "    numerator = 2. * torch.sum(torch.logical_and(y_pred, y_true))\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b20193f-5480-48e0-8047-4e180b1402a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7433)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice(y_hat, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c63b0a17-f3e3-4cce-a2b4-e2ab4f6db039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4111)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_dice(y_hat, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2af3c58a-1578-40d8-bff2-5a639a283650",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 49 is out of bounds for dimension 0 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mx1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m,:,:])\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(y1[ind])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 49 is out of bounds for dimension 0 with size 8"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 49\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(x1[ind][0,:,:])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(y1[ind])\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(y_hat.softmax(dim=1).argmax(dim=1)[ind])\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(y_hat[ind][1])\n",
    "print(slice_dice(y_hat[ind], y1[ind]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d864b7a-37a7-4d6d-97fb-8dcce2983208",
   "metadata": {},
   "source": [
    "### Glow normalizing flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659cfab6-e99e-4939-bf0f-833f22b9d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from math import log, pi, exp\n",
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "\n",
    "logabs = lambda x: torch.log(torch.abs(x))\n",
    "\n",
    "\n",
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, in_channel, logdet=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.loc = nn.Parameter(torch.zeros(1, in_channel, 1, 1))\n",
    "        self.scale = nn.Parameter(torch.ones(1, in_channel, 1, 1))\n",
    "\n",
    "        self.register_buffer(\"initialized\", torch.tensor(0, dtype=torch.uint8))\n",
    "        self.logdet = logdet\n",
    "\n",
    "    def initialize(self, input):\n",
    "        with torch.no_grad():\n",
    "            flatten = input.permute(1, 0, 2, 3).contiguous().view(input.shape[1], -1)\n",
    "            mean = (\n",
    "                flatten.mean(1)\n",
    "                .unsqueeze(1)\n",
    "                .unsqueeze(2)\n",
    "                .unsqueeze(3)\n",
    "                .permute(1, 0, 2, 3)\n",
    "            )\n",
    "            std = (\n",
    "                flatten.std(1)\n",
    "                .unsqueeze(1)\n",
    "                .unsqueeze(2)\n",
    "                .unsqueeze(3)\n",
    "                .permute(1, 0, 2, 3)\n",
    "            )\n",
    "\n",
    "            self.loc.data.copy_(-mean)\n",
    "            self.scale.data.copy_(1 / (std + 1e-6))\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, _, height, width = input.shape\n",
    "\n",
    "        if self.initialized.item() == 0:\n",
    "            self.initialize(input)\n",
    "            self.initialized.fill_(1)\n",
    "\n",
    "        log_abs = logabs(self.scale)\n",
    "\n",
    "        logdet = height * width * torch.sum(log_abs)\n",
    "\n",
    "        if self.logdet:\n",
    "            return self.scale * (input + self.loc), logdet\n",
    "\n",
    "        else:\n",
    "            return self.scale * (input + self.loc)\n",
    "\n",
    "    def reverse(self, output):\n",
    "        return output / self.scale - self.loc\n",
    "\n",
    "\n",
    "class InvConv2d(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = torch.randn(in_channel, in_channel)\n",
    "        q, _ = torch.qr(weight)\n",
    "        weight = q.unsqueeze(2).unsqueeze(3)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, _, height, width = input.shape\n",
    "\n",
    "        out = F.conv2d(input, self.weight)\n",
    "        logdet = (\n",
    "            height * width * torch.slogdet(self.weight.squeeze().double())[1].float()\n",
    "        )\n",
    "\n",
    "        return out, logdet\n",
    "\n",
    "    def reverse(self, output):\n",
    "        return F.conv2d(\n",
    "            output, self.weight.squeeze().inverse().unsqueeze(2).unsqueeze(3)\n",
    "        )\n",
    "\n",
    "\n",
    "class InvConv2dLU(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = np.random.randn(in_channel, in_channel)\n",
    "        q, _ = la.qr(weight)\n",
    "        w_p, w_l, w_u = la.lu(q.astype(np.float32))\n",
    "        w_s = np.diag(w_u)\n",
    "        w_u = np.triu(w_u, 1)\n",
    "        u_mask = np.triu(np.ones_like(w_u), 1)\n",
    "        l_mask = u_mask.T\n",
    "\n",
    "        w_p = torch.from_numpy(w_p)\n",
    "        w_l = torch.from_numpy(w_l)\n",
    "        w_s = torch.from_numpy(w_s)\n",
    "        w_u = torch.from_numpy(w_u)\n",
    "\n",
    "        self.register_buffer(\"w_p\", w_p)\n",
    "        self.register_buffer(\"u_mask\", torch.from_numpy(u_mask))\n",
    "        self.register_buffer(\"l_mask\", torch.from_numpy(l_mask))\n",
    "        self.register_buffer(\"s_sign\", torch.sign(w_s))\n",
    "        self.register_buffer(\"l_eye\", torch.eye(l_mask.shape[0]))\n",
    "        self.w_l = nn.Parameter(w_l)\n",
    "        self.w_s = nn.Parameter(logabs(w_s))\n",
    "        self.w_u = nn.Parameter(w_u)\n",
    "\n",
    "    def forward(self, input):\n",
    "        _, _, height, width = input.shape\n",
    "\n",
    "        weight = self.calc_weight()\n",
    "\n",
    "        out = F.conv2d(input, weight)\n",
    "        logdet = height * width * torch.sum(self.w_s)\n",
    "\n",
    "        return out, logdet\n",
    "\n",
    "    def calc_weight(self):\n",
    "        weight = (\n",
    "            self.w_p\n",
    "            @ (self.w_l * self.l_mask + self.l_eye)\n",
    "            @ ((self.w_u * self.u_mask) + torch.diag(self.s_sign * torch.exp(self.w_s)))\n",
    "        )\n",
    "\n",
    "        return weight.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "    def reverse(self, output):\n",
    "        weight = self.calc_weight()\n",
    "\n",
    "        return F.conv2d(output, weight.squeeze().inverse().unsqueeze(2).unsqueeze(3))\n",
    "\n",
    "\n",
    "class ZeroConv2d(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, padding=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, 3, padding=0)\n",
    "        self.conv.weight.data.zero_()\n",
    "        self.conv.bias.data.zero_()\n",
    "        self.scale = nn.Parameter(torch.zeros(1, out_channel, 1, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = F.pad(input, [1, 1, 1, 1], value=1)\n",
    "        out = self.conv(out)\n",
    "        out = out * torch.exp(self.scale * 3)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, in_channel, filter_size=512, affine=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.affine = affine\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channel // 2, filter_size, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(filter_size, filter_size, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ZeroConv2d(filter_size, in_channel if self.affine else in_channel // 2),\n",
    "        )\n",
    "\n",
    "        self.net[0].weight.data.normal_(0, 0.05)\n",
    "        self.net[0].bias.data.zero_()\n",
    "\n",
    "        self.net[2].weight.data.normal_(0, 0.05)\n",
    "        self.net[2].bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        in_a, in_b = input.chunk(2, 1)\n",
    "\n",
    "        if self.affine:\n",
    "            log_s, t = self.net(in_a).chunk(2, 1)\n",
    "            # s = torch.exp(log_s)\n",
    "            s = F.sigmoid(log_s + 2)\n",
    "            # out_a = s * in_a + t\n",
    "            out_b = (in_b + t) * s\n",
    "\n",
    "            logdet = torch.sum(torch.log(s).view(input.shape[0], -1), 1)\n",
    "\n",
    "        else:\n",
    "            net_out = self.net(in_a)\n",
    "            out_b = in_b + net_out\n",
    "            logdet = None\n",
    "\n",
    "        return torch.cat([in_a, out_b], 1), logdet\n",
    "\n",
    "    def reverse(self, output):\n",
    "        out_a, out_b = output.chunk(2, 1)\n",
    "\n",
    "        if self.affine:\n",
    "            log_s, t = self.net(out_a).chunk(2, 1)\n",
    "            # s = torch.exp(log_s)\n",
    "            s = F.sigmoid(log_s + 2)\n",
    "            # in_a = (out_a - t) / s\n",
    "            in_b = out_b / s - t\n",
    "\n",
    "        else:\n",
    "            net_out = self.net(out_a)\n",
    "            in_b = out_b - net_out\n",
    "\n",
    "        return torch.cat([out_a, in_b], 1)\n",
    "\n",
    "\n",
    "class Flow(nn.Module):\n",
    "    def __init__(self, in_channel, affine=True, conv_lu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.actnorm = ActNorm(in_channel)\n",
    "\n",
    "        if conv_lu:\n",
    "            self.invconv = InvConv2dLU(in_channel)\n",
    "\n",
    "        else:\n",
    "            self.invconv = InvConv2d(in_channel)\n",
    "\n",
    "        self.coupling = AffineCoupling(in_channel, affine=affine)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, logdet = self.actnorm(input)\n",
    "        out, det1 = self.invconv(out)\n",
    "        out, det2 = self.coupling(out)\n",
    "\n",
    "        logdet = logdet + det1\n",
    "        if det2 is not None:\n",
    "            logdet = logdet + det2\n",
    "\n",
    "        return out, logdet\n",
    "\n",
    "    def reverse(self, output):\n",
    "        input = self.coupling.reverse(output)\n",
    "        input = self.invconv.reverse(input)\n",
    "        input = self.actnorm.reverse(input)\n",
    "\n",
    "        return input\n",
    "\n",
    "\n",
    "def gaussian_log_p(x, mean, log_sd):\n",
    "    return -0.5 * log(2 * pi) - log_sd - 0.5 * (x - mean) ** 2 / torch.exp(2 * log_sd)\n",
    "\n",
    "\n",
    "def gaussian_sample(eps, mean, log_sd):\n",
    "    return mean + torch.exp(log_sd) * eps\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channel, n_flow, split=True, affine=True, conv_lu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        squeeze_dim = in_channel * 4\n",
    "\n",
    "        self.flows = nn.ModuleList()\n",
    "        for i in range(n_flow):\n",
    "            self.flows.append(Flow(squeeze_dim, affine=affine, conv_lu=conv_lu))\n",
    "\n",
    "        self.split = split\n",
    "\n",
    "        if split:\n",
    "            self.prior = ZeroConv2d(in_channel * 2, in_channel * 4)\n",
    "\n",
    "        else:\n",
    "            self.prior = ZeroConv2d(in_channel * 4, in_channel * 8)\n",
    "\n",
    "    def forward(self, input):\n",
    "        b_size, n_channel, height, width = input.shape\n",
    "        squeezed = input.view(b_size, n_channel, height // 2, 2, width // 2, 2)\n",
    "        squeezed = squeezed.permute(0, 1, 3, 5, 2, 4)\n",
    "        out = squeezed.contiguous().view(b_size, n_channel * 4, height // 2, width // 2)\n",
    "\n",
    "        logdet = 0\n",
    "\n",
    "        for flow in self.flows:\n",
    "            out, det = flow(out)\n",
    "            logdet = logdet + det\n",
    "\n",
    "        if self.split:\n",
    "            out, z_new = out.chunk(2, 1)\n",
    "            mean, log_sd = self.prior(out).chunk(2, 1)\n",
    "            log_p = gaussian_log_p(z_new, mean, log_sd)\n",
    "            log_p = log_p.view(b_size, -1).sum(1)\n",
    "\n",
    "        else:\n",
    "            zero = torch.zeros_like(out)\n",
    "            mean, log_sd = self.prior(zero).chunk(2, 1)\n",
    "            log_p = gaussian_log_p(out, mean, log_sd)\n",
    "            log_p = log_p.view(b_size, -1).sum(1)\n",
    "            z_new = out\n",
    "\n",
    "        return out, logdet, log_p, z_new\n",
    "\n",
    "    def reverse(self, output, eps=None, reconstruct=False):\n",
    "        input = output\n",
    "\n",
    "        if reconstruct:\n",
    "            if self.split:\n",
    "                input = torch.cat([output, eps], 1)\n",
    "\n",
    "            else:\n",
    "                input = eps\n",
    "\n",
    "        else:\n",
    "            if self.split:\n",
    "                mean, log_sd = self.prior(input).chunk(2, 1)\n",
    "                z = gaussian_sample(eps, mean, log_sd)\n",
    "                input = torch.cat([output, z], 1)\n",
    "\n",
    "            else:\n",
    "                zero = torch.zeros_like(input)\n",
    "                # zero = F.pad(zero, [1, 1, 1, 1], value=1)\n",
    "                mean, log_sd = self.prior(zero).chunk(2, 1)\n",
    "                z = gaussian_sample(eps, mean, log_sd)\n",
    "                input = z\n",
    "\n",
    "        for flow in self.flows[::-1]:\n",
    "            input = flow.reverse(input)\n",
    "\n",
    "        b_size, n_channel, height, width = input.shape\n",
    "\n",
    "        unsqueezed = input.view(b_size, n_channel // 4, 2, 2, height, width)\n",
    "        unsqueezed = unsqueezed.permute(0, 1, 4, 2, 5, 3)\n",
    "        unsqueezed = unsqueezed.contiguous().view(\n",
    "            b_size, n_channel // 4, height * 2, width * 2\n",
    "        )\n",
    "\n",
    "        return unsqueezed\n",
    "\n",
    "\n",
    "class Glow(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channel, n_flow, n_block, affine=True, conv_lu=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        n_channel = in_channel\n",
    "        for i in range(n_block - 1):\n",
    "            self.blocks.append(Block(n_channel, n_flow, affine=affine, conv_lu=conv_lu))\n",
    "            n_channel *= 2\n",
    "        self.blocks.append(Block(n_channel, n_flow, split=False, affine=affine))\n",
    "\n",
    "    def forward(self, input):\n",
    "        log_p_sum = 0\n",
    "        logdet = 0\n",
    "        out = input\n",
    "        z_outs = []\n",
    "\n",
    "        for block in self.blocks:\n",
    "            out, det, log_p, z_new = block(out)\n",
    "            z_outs.append(z_new)\n",
    "            logdet = logdet + det\n",
    "\n",
    "            if log_p is not None:\n",
    "                log_p_sum = log_p_sum + log_p\n",
    "\n",
    "        return log_p_sum, logdet, z_outs\n",
    "\n",
    "    def reverse(self, z_list, reconstruct=False):\n",
    "        for i, block in enumerate(self.blocks[::-1]):\n",
    "            if i == 0:\n",
    "                input = block.reverse(z_list[-1], z_list[-1], reconstruct=reconstruct)\n",
    "\n",
    "            else:\n",
    "                input = block.reverse(input, z_list[-(i + 1)], reconstruct=reconstruct)\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "491865c4-2e1f-4ecd-a254-7d3449313467",
   "metadata": {},
   "outputs": [],
   "source": [
    "glow = Glow(2, 8, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8567c184-d45b-4466-8454-ca82b6f59d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "Glow                                                    --\n",
       "├─ModuleList: 1-1                                       --\n",
       "│    └─Block: 2-1                                       --\n",
       "│    │    └─ModuleList: 3-1                             2,549,056\n",
       "│    │    └─ZeroConv2d: 3-2                             304\n",
       "│    └─Block: 2-2                                       --\n",
       "│    │    └─ModuleList: 3-3                             2,994,816\n",
       "│    │    └─ZeroConv2d: 3-4                             4,672\n",
       "================================================================================\n",
       "Total params: 5,548,616\n",
       "Trainable params: 5,548,616\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(glow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad5b8e1f-cb4b-438a-929b-9a600c376fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benp/anaconda3/envs/ip/lib/python3.9/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "Glow                                                    --                        --\n",
       "├─ModuleList: 1-1                                       --                        --\n",
       "│    └─Block: 2                                         --                        --\n",
       "│    │    └─ModuleList: 3-1                             --                        5,098,112\n",
       "│    └─Block: 2                                         --                        --\n",
       "│    │    └─ModuleList: 3-2                             --                        5,989,632\n",
       "│    └─Block: 2-1                                       [1, 4, 56, 40]            --\n",
       "│    │    └─ZeroConv2d: 3-3                             [1, 8, 56, 40]            304\n",
       "│    └─Block: 2-2                                       [1, 16, 28, 20]           --\n",
       "│    │    └─ZeroConv2d: 3-4                             [1, 32, 28, 20]           4,672\n",
       "=========================================================================================================\n",
       "Total params: 11,092,296\n",
       "Trainable params: 11,092,296\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 14.77\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 377.61\n",
       "Params size (MB): 44.37\n",
       "Estimated Total Size (MB): 422.05\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(glow, (1, 2, 224//2, 160//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95baf895-e1a4-4984-a292-51edd7e40a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlowWrapper(nn.Module):\n",
    "    def __init__(self, encoder, glow_model):\n",
    "        super().__init__()\n",
    "        self.enc = encoder\n",
    "        self.nf = glow_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            features = self.enc(x)\n",
    "            features = torch.nn.functional.interpolate(features, scale_factor=0.5, mode='bilinear')\n",
    "            \n",
    "        return self.nf(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cda2d12-078d-4241-b7fa-226e375db71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped = GlowWrapper(model, glow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "215eb6e5-507c-4d92-858e-c20432c5e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_params={\"lr\":2e-3}\n",
    "optimizer = torch.optim.Adam\n",
    "lr_scheduler_params={\"milestones\":[100,200], \"gamma\":0.5}\n",
    "lr_scheduler_constructor = torch.optim.lr_scheduler.MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a007b46-eaad-4b22-8831-683bda65e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (2, 224, 160)\n",
    "n_pixel = dims[0] * dims[1] * dims[2]\n",
    "def calc_loss(out, target):\n",
    "#     # log_p = calc_log_p([z_list])\n",
    "#     n_pixel = dims[0] * dims[1] * \n",
    "\n",
    "#     loss = -log(n_bins) * n_pixel\n",
    "#     loss = loss + logdet + log_p\n",
    "    log_p, logdet, _ = out\n",
    "    loss = logdet + log_p\n",
    "\n",
    "    # return (\n",
    "    #     (-loss / (log(2) * n_pixel)).mean(),\n",
    "    #     (log_p / (log(2) * n_pixel)).mean(),\n",
    "    #     (logdet / (log(2) * n_pixel)).mean(),\n",
    "    # )\n",
    "    return (-loss / log(2) * n_pixel).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "348745ee-9771-4751-9705-b58aacadbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = StandardLitModelWrapper(wrapped, calc_loss, \n",
    "                                logging_metric=lambda : None,\n",
    "                                optimizer_params=optimizer_params,\n",
    "                                lr_scheduler_params=lr_scheduler_params,\n",
    "                                is_uq_model=False,\n",
    "                                optimizer_constructor=optimizer,\n",
    "                                lr_scheduler_constructor=lr_scheduler_constructor\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df3436b2-2b1f-4b85-8fe7-7b33a08c026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"./lightning_logs\"\n",
    "strategy = None\n",
    "# strategy = \"deepspeed_stage_2\"\n",
    "# strategy = \"dp\"\n",
    "#strategy = \"deepspeed_stage_2_offload\"\n",
    "\n",
    "accelerator=\"gpu\"\n",
    "devices=1\n",
    "max_epochs=500\n",
    "precision = 32\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_dir, save_top_k=2, monitor=\"val_loss\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=500, verbose=\"False\", mode=\"min\", check_finite=True)\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    max_epochs=max_epochs,\n",
    "    strategy=strategy,\n",
    "    precision=precision,\n",
    "    default_root_dir=checkpoint_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd84281-d9d7-4b1d-aef9-21f905d4ae1a",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "523cae78-5b9e-42ec-952c-1f487634796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benp/anaconda3/envs/ip/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/benp/Documents/Dissertation/Trustworthai-MRI-WMH/trustworthai/models/uq_models/initial_variants/ddu/lightning_logs exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | GlowWrapper | 13.9 M\n",
      "--------------------------------------\n",
      "13.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.9 M    Total params\n",
      "55.468    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337888f5679f4acd9ee650d8cd3dc9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benp/anaconda3/envs/ip/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(nf, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1924314-9991-4ab3-91a2-88fe7e422b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ZeroConv2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         crop_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform\n\u001b[0;32m---> 66\u001b[0m Glow_model \u001b[38;5;241m=\u001b[39m \u001b[43mgetGLOW\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mgetGLOW\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mMultiscaleCompositeTransform(num_scale)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_scale):\n\u001b[0;32m---> 59\u001b[0m     next_input \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39madd_transform(\u001b[43mgetGlowScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_flow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_size\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     60\u001b[0m                                          [num_channels, crop_size, crop_size])\n\u001b[1;32m     61\u001b[0m     num_channels \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     62\u001b[0m     crop_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mgetGlowScale\u001b[0;34m(num_channels, num_flow, crop_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetGlowScale\u001b[39m(num_channels, num_flow, crop_size):\n\u001b[0;32m---> 45\u001b[0m     z \u001b[38;5;241m=\u001b[39m [getGlowStep(num_channels, crop_size, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_flow)]\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mCompositeTransform([\n\u001b[1;32m     47\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mSqueezeTransform(),\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;241m*\u001b[39mz\n\u001b[1;32m     49\u001b[0m     ])\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetGlowScale\u001b[39m(num_channels, num_flow, crop_size):\n\u001b[0;32m---> 45\u001b[0m     z \u001b[38;5;241m=\u001b[39m [\u001b[43mgetGlowStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_flow)]\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mCompositeTransform([\n\u001b[1;32m     47\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mSqueezeTransform(),\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;241m*\u001b[39mz\n\u001b[1;32m     49\u001b[0m     ])\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mgetGlowStep\u001b[0;34m(num_channels, crop_size, i)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetNet\u001b[39m(in_channel, out_channels):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Net(in_channel, out_channels)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mCompositeTransform([\n\u001b[1;32m     37\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mActNorm(num_channels),\n\u001b[1;32m     38\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mOneByOneConvolution(num_channels),\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoupling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAffineCouplingTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgetNet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m ])\n",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/nflows/transforms/coupling.py:51\u001b[0m, in \u001b[0;36mCouplingTransform.__init__\u001b[0;34m(self, mask, transform_net_create_fn, unconditional_transform)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, features_vector\u001b[38;5;241m.\u001b[39mmasked_select(mask \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_identity_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_transform_features \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_net \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_net_create_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_identity_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_transform_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_dim_multiplier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unconditional_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconditional_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mgetGlowStep.<locals>.getNet\u001b[0;34m(in_channel, out_channels)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetNet\u001b[39m(in_channel, out_channels):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mNet.__init__\u001b[0;34m(self, in_channel, out_channels)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channel, out_channels):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     14\u001b[0m         nn\u001b[38;5;241m.\u001b[39mConv2d(in_channel, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     15\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     16\u001b[0m         nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     17\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m---> 18\u001b[0m         \u001b[43mZeroConv2d\u001b[49m(\u001b[38;5;241m64\u001b[39m, out_channels),\n\u001b[1;32m     19\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ZeroConv2d' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nflows import transforms\n",
    "import numpy as np\n",
    "from torchvision.transforms.functional import resize\n",
    "from nflows.transforms.base import Transform\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, out_channels):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ZeroConv2d(64, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, inp, context=None):\n",
    "        return self.net(inp)\n",
    "\n",
    "\n",
    "def getGlowStep(num_channels, crop_size, i):\n",
    "    mask = [1] * num_channels\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        mask[::2] = [-1] * (len(mask[::2]))\n",
    "    else:\n",
    "        mask[1::2] = [-1] * (len(mask[1::2]))\n",
    "\n",
    "    def getNet(in_channel, out_channels):\n",
    "        return Net(in_channel, out_channels)\n",
    "\n",
    "    return transforms.CompositeTransform([\n",
    "        transforms.ActNorm(num_channels),\n",
    "        transforms.OneByOneConvolution(num_channels),\n",
    "        transforms.coupling.AffineCouplingTransform(mask, getNet)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "def getGlowScale(num_channels, num_flow, crop_size):\n",
    "    z = [getGlowStep(num_channels, crop_size, i) for i in range(num_flow)]\n",
    "    return transforms.CompositeTransform([\n",
    "        transforms.SqueezeTransform(),\n",
    "        *z\n",
    "    ])\n",
    "\n",
    "\n",
    "def getGLOW():\n",
    "    num_channels = 1 * 4\n",
    "    num_flow = 32\n",
    "    num_scale = 3\n",
    "    crop_size = 28 // 2\n",
    "    transform = transforms.MultiscaleCompositeTransform(num_scale)\n",
    "    for i in range(num_scale):\n",
    "        next_input = transform.add_transform(getGlowScale(num_channels, num_flow, crop_size),\n",
    "                                             [num_channels, crop_size, crop_size])\n",
    "        num_channels *= 2\n",
    "        crop_size //= 2\n",
    "\n",
    "    return transform\n",
    "\n",
    "Glow_model = getGLOW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656e9384-5352-44cf-88cd-7d7be61afc06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Glow_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summary(\u001b[43mGlow_model\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Glow_model' is not defined"
     ]
    }
   ],
   "source": [
    "summary(Glow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f5a26c11-ac24-4a2a-abcb-fbb6a145d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 4, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6fec4d58-1276-4bd3-b599-2900975d708d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiscaleCompositeTransform' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mGlow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1185\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiscaleCompositeTransform' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "Glow_model.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fa2a2c6-bd03-45f8-9b49-fbe9857c85a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MultiscaleCompositeTransform in module nflows.transforms.base object:\n",
      "\n",
      "class MultiscaleCompositeTransform(Transform)\n",
      " |  MultiscaleCompositeTransform(num_transforms, split_dim=1)\n",
      " |  \n",
      " |  A multiscale composite transform as described in the RealNVP paper.\n",
      " |  \n",
      " |  Splits the outputs along the given dimension after every transform, outputs one half, and\n",
      " |  passes the other half to further transforms. No splitting is done before the last transform.\n",
      " |  \n",
      " |  Note: Inputs could be of arbitrary shape, but outputs will always be flattened.\n",
      " |  \n",
      " |  Reference:\n",
      " |  > L. Dinh et al., Density estimation using Real NVP, ICLR 2017.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MultiscaleCompositeTransform\n",
      " |      Transform\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_transforms, split_dim=1)\n",
      " |      Constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          num_transforms: int, total number of transforms to be added.\n",
      " |          split_dim: dimension along which to split.\n",
      " |  \n",
      " |  add_transform(self, transform, transform_output_shape)\n",
      " |      Add a transform. Must be called exactly `num_transforms` times.\n",
      " |      \n",
      " |      Parameters:\n",
      " |          transform: the `Transform` object to be added.\n",
      " |          transform_output_shape: tuple, shape of transform's outputs, excl. the first batch\n",
      " |              dimension.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape for the next transform, or None if adding the last transform.\n",
      " |  \n",
      " |  forward(self, inputs, context=None)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  inverse(self, inputs, context=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be pickleable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block::text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]', strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  __annotations__ = {'__call__': typing.Callable[..., typing.Any], '_is_...\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Glow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4cce78-8309-406a-be8a-8c288d00807c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
