{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669a7d7f-040c-454c-8007-f29d6e2f7cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strawberry\n"
     ]
    }
   ],
   "source": [
    "print(\"strawberry\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# dataset\n",
    "from twaidata.torchdatasets.in_ram_ds import MRISegmentation2DDataset, MRISegmentation3DDataset\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "\n",
    "# model\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_deterministic import HyperMapp3r\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_DDU import HyperMapp3rDDU\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_SSN import HyperMapp3rSSN\n",
    "\n",
    "\n",
    "# augmentation and pretrain processing\n",
    "from trustworthai.utils.augmentation.standard_transforms import RandomFlip, GaussianBlur, GaussianNoise, \\\n",
    "                                                            RandomResizeCrop, RandomAffine, \\\n",
    "                                                            NormalizeImg, PairedCompose, LabelSelect, \\\n",
    "                                                            PairedCentreCrop, CropZDim\n",
    "# loss function\n",
    "from trustworthai.utils.losses_and_metrics.per_individual_losses import (\n",
    "    log_cosh_dice_loss,\n",
    "    TverskyLoss,\n",
    "    FocalTverskyLoss,\n",
    "    DiceLossMetric\n",
    ")\n",
    "from torch.nn import BCELoss, MSELoss, BCEWithLogitsLoss\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import argparse\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchmetrics import Metric\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698e780c-eb54-4881-8d25-0b73796a5da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8856d0b0-6b20-4ad7-973e-a9bc806e36d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbba00f4870>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f64062-e112-43b7-a1e2-1c03c0733b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    transforms = [\n",
    "        LabelSelect(label_id=1),\n",
    "        RandomFlip(p=0.5, orientation=\"horizontal\"),\n",
    "        # GaussianBlur(p=0.5, kernel_size=7, sigma=(.1, 1.5)),\n",
    "        # GaussianNoise(p=0.2, mean=0, sigma=0.2),\n",
    "        RandomAffine(p=0.2, shear=(-18,18)),\n",
    "        RandomAffine(p=0.2, degrees=15),\n",
    "        RandomAffine(p=0.2, translate=(-0.1,0.1)),\n",
    "        RandomAffine(p=0.2, scale=(0.9, 1.1)),\n",
    "#         #RandomResizeCrop(p=1., scale=(0.6, 1.), ratio=(3./4., 4./3.))\n",
    "\n",
    "#         #RandomResizeCrop(p=1., scale=(0.3, 0.5), ratio=(3./4., 4./3.)) # ssn\n",
    "            \n",
    "    ]\n",
    "    transforms.append(lambda x, y: (x, y.squeeze().type(torch.long)))\n",
    "    return PairedCompose(transforms)\n",
    "\n",
    "def none_transform():\n",
    "    transforms = [\n",
    "        LabelSelect(label_id=1),\n",
    "        lambda x, y: (x, y.squeeze().type(torch.long))\n",
    "    ]\n",
    "    return PairedCompose(transforms)\n",
    "\n",
    "def train_val_test_split(dataset, val_prop, test_prop, seed):\n",
    "        # I think the sklearn version might be prefereable for determinism and things\n",
    "        # but that involves fiddling with the dataset implementation I think....\n",
    "        size = len(dataset)\n",
    "        test_size = int(test_prop*size) \n",
    "        val_size = int(val_prop*size)\n",
    "        train_size = size - val_size - test_size\n",
    "        train, val, test = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(seed))\n",
    "        return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26505c65-bf8e-47b9-b05b-549a08c2fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from trustworthai.models.uq_models.drop_UNet import normalization_layer\n",
    "import torch.nn.functional as F\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_deterministic import HyperMapp3r\n",
    "import torch.distributions as td\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ec78e1-1405-4ca7-8302-e220059461c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = None\n",
    "is3D = False\n",
    "root_dir = \"/disk/scratch/s2208943/ipdis/preprep/out_data/collated/\"\n",
    "#root_dir = \"/media/benp/NVMEspare/datasets/preprocessing_attempts/local_results/collated/\"\n",
    "wmh_dir = root_dir + \"WMH_challenge_dataset/\"\n",
    "ed_dir = root_dir + \"EdData/\"\n",
    "\n",
    "domains = [ed_dir + d for d in [\"domainA\", \"domainB\", \"domainC\", \"domainD\"]]\n",
    "# domains = [ wmh_dir + d for d in ['Singapore', 'GE3T', 'Utrecht']]\n",
    "\n",
    "train_proportion = 0.7\n",
    "test_proportion = 0.15\n",
    "validation_proportion = 0.15\n",
    "seed = 3407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4ffd5c-1ee1-4a6b-acc3-9100001ff5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3d to 2d dataset\n",
    "class MRISegDataset2DFrom3D(Dataset):\n",
    "    def __init__(self, dataset3D, transforms=None):\n",
    "        # calculate total number of slices (note need to iterate through every item\n",
    "        # because each image may have a different number of slices\n",
    "        size = 0\n",
    "        for data in dataset3D:\n",
    "            x = data[0]\n",
    "            size += x.shape[1]\n",
    "            \n",
    "        self.size = size\n",
    "        self.dataset3D = dataset3D\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        idx_to_scan_index = []\n",
    "        scan_starting_index = []\n",
    "        \n",
    "        scan_count = 0\n",
    "        starting_index = 0\n",
    "        for (ind, _) in dataset3D:\n",
    "            d_size = ind.shape[1] # slices are the second dim of 3D scan\n",
    "            idx_to_scan_index.append(torch.ones(d_size) * scan_count)\n",
    "            scan_starting_index.append(starting_index)\n",
    "            \n",
    "            scan_count += 1\n",
    "            starting_index += d_size\n",
    "            \n",
    "        self.idx_to_scan = torch.cat(idx_to_scan_index, dim=0).type(torch.int32)\n",
    "        # print(self.idx_to_scan.shape)\n",
    "        self.scan_starting_index = scan_starting_index\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # find out which scan to use\n",
    "        scan_idx = self.idx_to_scan[idx]\n",
    "        # get that dataset\n",
    "        scan_img, scan_label = self.dataset3D[scan_idx]\n",
    "        # find out where the element is in that dataset\n",
    "        item_idx = idx - self.scan_starting_index[scan_idx]\n",
    "        \n",
    "        #print(scan_img.shape, scan_label.shape)\n",
    "        slice_x = scan_img[:, item_idx]\n",
    "        slice_y = scan_label[:, item_idx] # slices are the second dim of a 3D scan (its channels, z, x, y for 3D scans)\n",
    "        \n",
    "        if self.transforms:\n",
    "            slice_x, slice_y = self.transforms(slice_x, slice_y)\n",
    "        \n",
    "        return slice_x, slice_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932abecb-e8e6-49d6-875e-d6766184fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### empty slice splitting\n",
    "class FilteredEmptyElementsDataset(Dataset):\n",
    "    def __init__(self, dataset, seed, transforms=None, empty_proportion_retained=0.1):\n",
    "        # print(len(dataset))\n",
    "        self.base_dataset = dataset\n",
    "        self.transforms = transforms\n",
    "        empty_indices = []\n",
    "        self.non_empty_indices = []\n",
    "        count = 0\n",
    "        for i, (x, y) in enumerate(dataset):\n",
    "            if y.sum() == 0:\n",
    "                count += 1\n",
    "                empty_indices.append(i)\n",
    "            else:\n",
    "                self.non_empty_indices.append(i)\n",
    "           \n",
    "        # print(count)\n",
    "        # print(len(self.non_empty_indices))\n",
    "        #print(count * empty_proportion_retained)\n",
    "                \n",
    "        # extract only a limited proportion of empty slices (take a random selection)\n",
    "        shuffled_indices = torch.randperm(count, generator=torch.Generator().manual_seed(seed))\n",
    "        emtpy_indices = torch.Tensor(empty_indices)\n",
    "        self.retained_empty_indices = torch.Tensor(empty_indices)[shuffled_indices[0:int(count * empty_proportion_retained)]]\n",
    "        self.size = len(self.non_empty_indices) + len(self.retained_empty_indices)\n",
    "        self.non_empty_size = len(self.non_empty_indices)\n",
    "        \n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.non_empty_size:\n",
    "            # select an empty slice\n",
    "            new_idx = self.retained_empty_indices[idx - self.non_empty_size]\n",
    "        else:\n",
    "            # select a slice with label in it\n",
    "            new_idx = self.non_empty_indices[idx]\n",
    "        new_idx = int(new_idx)\n",
    "        \n",
    "        img, label = self.base_dataset[new_idx]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img, label = self.transforms(img, label)\n",
    "            \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f861d0-6122-4cb9-be23-04c1788c6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_domains = [MRISegmentation3DDataset(root_dir, domain, transforms=None) for domain in domains]\n",
    "\n",
    "# split into train, val test datasets\n",
    "datasets_3d = [train_val_test_split(dataset, validation_proportion, test_proportion, seed) for dataset in datasets_domains]\n",
    "\n",
    "# concat the train val test datsets\n",
    "train_dataset_3d = ConcatDataset([ds[0] for ds in datasets_3d])\n",
    "val_dataset_3d = ConcatDataset([ds[1] for ds in datasets_3d])\n",
    "test_dataset_3d = ConcatDataset([ds[2] for ds in datasets_3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94058b2b-78b3-4709-89c7-41952d29483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_2d = [MRISegDataset2DFrom3D(ds, transforms=None) for ds in [train_dataset_3d, val_dataset_3d, test_dataset_3d]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c6ef865-e39c-4fb2-8113-b6b66269257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = [FilteredEmptyElementsDataset(ds, seed=seed, transforms=get_transforms()) for ds in datasets_2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8dd4332-4fd7-4aba-9d3b-f69da5a293fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 160])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d11f7e9-5b50-4f66-b37b-b918b44accde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 30, shuffle=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01e286aa-f2ac-498b-976c-3ea2b2b49e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_class_prob(p_hat):\n",
    "    p_hat = torch.nn.functional.softmax(p_hat, dim=1)\n",
    "    p_hat = p_hat[:,1,:] # select class 0\n",
    "    return p_hat\n",
    "\n",
    "def individual_dice(p_hat, y_true):\n",
    "    p_hat = two_class_prob(p_hat)\n",
    "    s0 = p_hat.shape[0]\n",
    "    p_hat = p_hat.view(s0,-1)\n",
    "    y_true = y_true.view(s0,-1)\n",
    "    numerator = torch.sum(2. * p_hat * y_true, dim=1) + 1.\n",
    "    denominator = torch.sum(y_true + p_hat, dim=1) + 1.\n",
    "    combined = 1. - (numerator/denominator)\n",
    "    return combined\n",
    "    \n",
    "def dice_loss(p_hat, y_true):\n",
    "    combined = individual_dice(p_hat, y_true)\n",
    "    \n",
    "    # is empties\n",
    "    locs = torch.sum(y_true, dim=(-2, -1)) == 0\n",
    "    wheres = torch.where(locs)[0]\n",
    "    #print(wheres.shape)\n",
    "    # print(wheres)\n",
    "    #print(combined)\n",
    "    r = 0.5\n",
    "    combined[wheres] *= r\n",
    "    #print(combined)\n",
    "    \n",
    "    return torch.sum(combined) / ((y_true.shape[0] - wheres.shape[0]) + (wheres.shape[0] * r))\n",
    "\n",
    "def dice_loss_old(p_hat, y_true):\n",
    "    combined = individual_dice(p_hat, y_true)\n",
    "    return torch.mean(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19dbba03-1ff2-496f-8748-f89f7e827f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from trustworthai.models.uq_models.drop_UNet import normalization_layer\n",
    "import torch.nn.functional as F\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_deterministic import HyperMapp3r\n",
    "import torch.distributions as td\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed16236e-0bc8-4ea5-9ec5-fc7f90c70833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_func(dims, transpose=False):\n",
    "    # determine convolution func\n",
    "        if dims == 2:\n",
    "            if transpose:\n",
    "                return nn.ConvTranspose2d\n",
    "            else:\n",
    "                return nn.Conv2d\n",
    "        elif dims == 3:\n",
    "            if transpose:\n",
    "                return nn.ConvTranspose3d\n",
    "            else:\n",
    "                return nn.Conv3d\n",
    "        else:\n",
    "            raise ValueError(f\"values of dims of 2 or 3 (2D or 2D conv) are supported only, not {dims}\")\n",
    "            \n",
    "def get_dropout_func(dims):\n",
    "    if dims == 2:\n",
    "        return nn.Dropout2d\n",
    "    if dims == 3:\n",
    "        return nn.Dropout3d\n",
    "    else:\n",
    "        return nn.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ba02fe-dea7-4740-a035-d3a1e543c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapedDistribution(td.Distribution):\n",
    "    def __init__(self, base_distribution: td.Distribution, new_event_shape: Tuple[int, ...]):\n",
    "        super().__init__(batch_shape=base_distribution.batch_shape, event_shape=new_event_shape, validate_args=False)\n",
    "        self.base_distribution = base_distribution\n",
    "        self.new_shape = base_distribution.batch_shape + new_event_shape\n",
    "        \n",
    "        #print(\"base distribution: \", self.base_distribution)\n",
    "\n",
    "    @property\n",
    "    def support(self):\n",
    "        return self.base_distribution.support\n",
    "\n",
    "    @property\n",
    "    def arg_constraints(self):\n",
    "        return self.base_distribution.arg_constraints()\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.base_distribution.mean.view(self.new_shape)\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.base_distribution.variance.view(self.new_shape)\n",
    "\n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        return self.base_distribution.rsample(sample_shape).view(sample_shape + self.new_shape)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        return self.base_distribution.log_prob(value.view(self.batch_shape + (-1,)))\n",
    "\n",
    "    def entropy(self):\n",
    "        return self.base_distribution.entropy()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "311dd1f5-bc15-4b09-a7d9-1172a0ff422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from torch.distributions.multivariate_normal import _batch_mahalanobis, _batch_mv\n",
    "from torch.distributions.utils import _standard_normal, lazy_property\n",
    "from pyro.distributions.torch_distribution import TorchDistribution\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "from torch.distributions.utils import lazy_property\n",
    "\n",
    "from pyro.distributions.torch import Chi2\n",
    "from pyro.distributions.torch_distribution import TorchDistribution\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "\n",
    "def _batch_capacitance_tril(W, D):\n",
    "    r\"\"\"\n",
    "    Computes Cholesky of :math:`I + W.T @ inv(D) @ W` for a batch of matrices :math:`W`\n",
    "    and a batch of vectors :math:`D`.\n",
    "    \"\"\"\n",
    "    m = W.size(-1)\n",
    "    Wt_Dinv = W.mT / D.unsqueeze(-2)\n",
    "    K = torch.matmul(Wt_Dinv, W).contiguous()\n",
    "    K.view(-1, m * m)[:, ::m + 1] += 1  # add identity matrix to K\n",
    "    return torch.linalg.cholesky(K)\n",
    "\n",
    "\n",
    "def _batch_lowrank_logdet(W, D, capacitance_tril):\n",
    "    r\"\"\"\n",
    "    Uses \"matrix determinant lemma\"::\n",
    "        log|W @ W.T + D| = log|C| + log|D|,\n",
    "    where :math:`C` is the capacitance matrix :math:`I + W.T @ inv(D) @ W`, to compute\n",
    "    the log determinant.\n",
    "    \"\"\"\n",
    "    return 2 * capacitance_tril.diagonal(dim1=-2, dim2=-1).log().sum(-1) + D.log().sum(-1)\n",
    "\n",
    "\n",
    "def _batch_lowrank_mahalanobis(W, D, x, capacitance_tril):\n",
    "    r\"\"\"\n",
    "    Uses \"Woodbury matrix identity\"::\n",
    "        inv(W @ W.T + D) = inv(D) - inv(D) @ W @ inv(C) @ W.T @ inv(D),\n",
    "    where :math:`C` is the capacitance matrix :math:`I + W.T @ inv(D) @ W`, to compute the squared\n",
    "    Mahalanobis distance :math:`x.T @ inv(W @ W.T + D) @ x`.\n",
    "    \"\"\"\n",
    "    Wt_Dinv = W.mT / D.unsqueeze(-2)\n",
    "    Wt_Dinv_x = _batch_mv(Wt_Dinv, x)\n",
    "    mahalanobis_term1 = (x.pow(2) / D).sum(-1)\n",
    "    mahalanobis_term2 = _batch_mahalanobis(capacitance_tril, Wt_Dinv_x)\n",
    "    return mahalanobis_term1 - mahalanobis_term2\n",
    "\n",
    "class LowRankMultivariateStudentT_V3(TorchDistribution):\n",
    "    \"\"\"\n",
    "    Creates a multivariate t distribution with covariance matrix having a low-rank\n",
    "    form parameterized by :attr:`cov_factor` and :attr:`cov_diag`::\n",
    "        covariance_matrix = cov_factor @ cov_factor.T + cov_diag\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    df (Tensor): degrees of freedom of the distribution\n",
    "    loc (Tensor): mean of the distribution with shape `batch_shape + event_shape`\n",
    "    cov_factor (Tensor): factor part of low-rank form of covariance matrix with shape\n",
    "        `batch_shape + event_shape + (rank,)`\n",
    "    cov_diag (Tensor): diagonal part of low-rank form of covariance matrix with shape\n",
    "        `batch_shape + event_shape`\n",
    "\n",
    "    Note:\n",
    "        The computation for determinant and inverse of covariance matrix is avoided when\n",
    "        `cov_factor.shape[1] << cov_factor.shape[0]` thanks to `Woodbury matrix identity\n",
    "        <https://en.wikipedia.org/wiki/Woodbury_matrix_identity>`_ and\n",
    "        `matrix determinant lemma <https://en.wikipedia.org/wiki/Matrix_determinant_lemma>`_.\n",
    "        Thanks to these formulas, we just need to compute the determinant and inverse of\n",
    "        the small size \"capacitance\" matrix::\n",
    "\n",
    "            capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor\n",
    "    \"\"\"\n",
    "    \n",
    "    arg_constraints = {\"df\": constraints.positive,\n",
    "                       \"loc\": constraints.real_vector,\n",
    "                       \"cov_factor\": constraints.independent(constraints.real, 2),\n",
    "                       \"cov_diag\": constraints.independent(constraints.positive, 1)}\n",
    "    \n",
    "    support = constraints.real_vector\n",
    "    has_rsample = True\n",
    "    \n",
    "    def __init__(self, df, loc, cov_factor, cov_diag, validate_args=None):\n",
    "        if loc.dim() < 1:\n",
    "            raise ValueError(\"loc must be at least one-dimensional.\")\n",
    "        event_shape = loc.shape[-1:]\n",
    "        if cov_factor.dim() < 2:\n",
    "            raise ValueError(\"cov_factor must be at least two_dimensional\")\n",
    "        if cov_factor.shape[-2:-1] != event_shape:\n",
    "            raise ValueError(\"cov_factor must be a batch of matrices with shape {} x m\".format(event_shape[0]))\n",
    "        if cov_diag.shape[-1:] != event_shape:\n",
    "            raise ValueError(\"cov_diag must be a batch of vectors with shape {}\".format(event_shape))\n",
    "            \n",
    "        if not isinstance(df, torch.Tensor):\n",
    "            df = loc.new_tensor(df)\n",
    "            \n",
    "        loc_ = loc.unsqueeze(-1)\n",
    "        cov_diag_ = cov_diag.unsqueeze(-1)\n",
    "        try:\n",
    "            loc_, self.cov_factor, cov_diag_ = torch.broadcast_tensors(loc_, cov_factor, cov_diag_)\n",
    "        except RuntimeError as e:\n",
    "            raise ValueError(\"Incompatible batch shapes: loc {}, cov_factor {}, cov_diag {}\"\n",
    "                             .format(loc.shape, cov_factor.shape, cov_diag.shape)) from e\n",
    "        \n",
    "        self.loc = loc_[..., 0]\n",
    "        self.cov_diag = cov_diag_[..., 0]\n",
    "        batch_shape = self.loc.shape[:-1]\n",
    "        self.df = df.expand(batch_shape)\n",
    "\n",
    "        self._unbroadcasted_cov_factor = cov_factor\n",
    "        self._unbroadcasted_cov_diag = cov_diag\n",
    "        self._capacitance_tril = _batch_capacitance_tril(cov_factor, cov_diag)\n",
    "        \n",
    "        self._chi2 = Chi2(self.df)\n",
    "        \n",
    "        super().__init__(batch_shape, event_shape, validate_args=validate_args)\n",
    "        \n",
    "    def expand(self, batch_shape, _instance=None):\n",
    "        new = self._get_checked_instance(LowRankMultivariateNormal, _instance)\n",
    "        batch_shape = torch.Size(batch_shape)\n",
    "        loc_shape = batch_shape + self.event_shape\n",
    "        new.df = self.df = df.expand(loc_shape)\n",
    "        new.loc = self.loc.expand(loc_shape)\n",
    "        new._chi2 = self._chi2.expand(loc_shape)\n",
    "        new.cov_diag = self.cov_diag.expand(loc_shape)\n",
    "        new.cov_factor = self.cov_factor.expand(loc_shape + self.cov_factor.shape[-1:])\n",
    "        new._unbroadcasted_cov_factor = self._unbroadcasted_cov_factor\n",
    "        new._unbroadcasted_cov_diag = self._unbroadcasted_cov_diag\n",
    "        new._capacitance_tril = self._capacitance_tril\n",
    "        super(LowRankMultivariateStudentT_V2, new).__init__(batch_shape,\n",
    "                                                       self.event_shape,\n",
    "                                                       validate_args=False)\n",
    "        new._validate_args = self._validate_args\n",
    "        return new\n",
    "    \n",
    "    @lazy_property\n",
    "    def scale_tril(self):\n",
    "        # The following identity is used to increase the numerically computation stability\n",
    "        # for Cholesky decomposition (see http://www.gaussianprocess.org/gpml/, Section 3.4.3):\n",
    "        #     W @ W.T + D = D1/2 @ (I + D-1/2 @ W @ W.T @ D-1/2) @ D1/2\n",
    "        # The matrix \"I + D-1/2 @ W @ W.T @ D-1/2\" has eigenvalues bounded from below by 1,\n",
    "        # hence it is well-conditioned and safe to take Cholesky decomposition.\n",
    "        n = self._event_shape[0]\n",
    "        cov_diag_sqrt_unsqueeze = self._unbroadcasted_cov_diag.sqrt().unsqueeze(-1)\n",
    "        Dinvsqrt_W = self._unbroadcasted_cov_factor / cov_diag_sqrt_unsqueeze\n",
    "        K = torch.matmul(Dinvsqrt_W, Dinvsqrt_W.mT).contiguous()\n",
    "        K.view(-1, n * n)[:, ::n + 1] += 1  # add identity matrix to K\n",
    "        scale_tril = cov_diag_sqrt_unsqueeze * torch.linalg.cholesky(K)\n",
    "        return scale_tril.expand(self._batch_shape + self._event_shape + self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def covariance_matrix(self):\n",
    "        # NB: this is not covariance of this distribution;\n",
    "        # the actual covariance is df / (df - 2) * covariance_matrix\n",
    "        covariance_matrix = (torch.matmul(self._unbroadcasted_cov_factor,\n",
    "                                          self._unbroadcasted_cov_factor.mT)\n",
    "                             + torch.diag_embed(self._unbroadcasted_cov_diag))\n",
    "        return covariance_matrix.expand(self._batch_shape + self._event_shape +\n",
    "                                        self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def precision_matrix(self):\n",
    "        # We use \"Woodbury matrix identity\" to take advantage of low rank form::\n",
    "        #     inv(W @ W.T + D) = inv(D) - inv(D) @ W @ inv(C) @ W.T @ inv(D)\n",
    "        # where :math:`C` is the capacitance matrix.\n",
    "        Wt_Dinv = (self._unbroadcasted_cov_factor.mT\n",
    "                   / self._unbroadcasted_cov_diag.unsqueeze(-2))\n",
    "        A = torch.linalg.solve_triangular(self._capacitance_tril, Wt_Dinv, upper=False)\n",
    "        precision_matrix = torch.diag_embed(self._unbroadcasted_cov_diag.reciprocal()) - A.mT @ A\n",
    "        return precision_matrix.expand(self._batch_shape + self._event_shape +\n",
    "                                       self._event_shape)\n",
    "    \n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        shape = self._extended_shape(sample_shape)\n",
    "        #X = torch.empty(shape, dtype=self.df.dtype, device=self.df.device).normal_()\n",
    "        Z = self._chi2.rsample(sample_shape)\n",
    "        #Y = X * torch.rsqrt(Z / self.df).unsqueeze(-1)\n",
    "        #return self.loc + self.scale_tril.matmul(Y.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        W_shape = shape[:-1] + self.cov_factor.shape[-1:]\n",
    "        eps_W = _standard_normal(W_shape, dtype=self.loc.dtype, device=self.loc.device)\n",
    "        eps_D = _standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)\n",
    "        \n",
    "        frac = torch.rsqrt(Z / self.df).unsqueeze(-1)\n",
    "        Yeps_W = eps_W * frac\n",
    "        Yeps_D = eps_D * frac\n",
    "        return (self.loc + _batch_mv(self._unbroadcasted_cov_factor, Yeps_W)\n",
    "                + self._unbroadcasted_cov_diag.sqrt() * Yeps_D)\n",
    "        \n",
    "\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        n = self.loc.size(-1)\n",
    "        diff = (value - self.loc)\n",
    "        y = _batch_lowrank_mahalanobis(self._unbroadcasted_cov_factor,\n",
    "                                       self._unbroadcasted_cov_diag,\n",
    "                                       diff,\n",
    "                                       self._capacitance_tril)\n",
    "        \n",
    "        log_det = _batch_lowrank_logdet(self._unbroadcasted_cov_factor,\n",
    "                                        self._unbroadcasted_cov_diag,\n",
    "                                        self._capacitance_tril)\n",
    "        Z = (\n",
    "            log_det * 0.5\n",
    "            + 0.5 * n * self.df.log()\n",
    "            + 0.5 * n * math.log(math.pi)\n",
    "            + torch.lgamma(0.5 * self.df)\n",
    "            - torch.lgamma(0.5 * (self.df + n))\n",
    "        )\n",
    "        return -0.5 * (self.df + n) * torch.log1p(y / self.df) - Z\n",
    "\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        m = self.loc.clone()\n",
    "        m[self.df <= 1, :] = float(\"nan\")\n",
    "        return m\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        m = self.scale_tril.pow(2).sum(-1) * (self.df / (self.df - 2)).unsqueeze(-1)\n",
    "        m[(self.df <= 2) & (self.df > 1), :] = float(\"inf\")\n",
    "        m[self.df <= 1, :] = float(\"nan\")\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed1c4c5b-46f6-4d7b-a3b4-74a10ff07804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as transforms\n",
    "\n",
    "class HmResBlock(nn.Module):\n",
    "    def __init__(self, channels, p):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=7, stride=1, dilation=2, padding='same')\n",
    "        self.dropout1 = nn.Dropout2d(p)\n",
    "        self.norm1 = nn.InstanceNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, dilation=2, padding='same')\n",
    "        self.norm2 = nn.InstanceNorm2d(channels)\n",
    "        self.activ = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.activ(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.activ(out)\n",
    "        \n",
    "        out = out + identity\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, ins, outs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ins, outs, kernel_size=3, stride=2, dilation=1, padding=1)\n",
    "        self.norm = nn.InstanceNorm2d(outs)\n",
    "        self.activ = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.activ(self.norm(self.conv(x)))\n",
    "\n",
    "class HmUpsampBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(channels*2, channels, kernel_size=3, stride=1, dilation=1, padding='same')\n",
    "        self.norm = nn.InstanceNorm2d(channels)\n",
    "        self.activ = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        return self.activ(self.norm(self.conv(out)))\n",
    "        \n",
    "\n",
    "class HmFeatureBlock(nn.Module):\n",
    "    def __init__(self, ins):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(ins, ins//2, kernel_size=3, stride=1, dilation=2, padding='same')\n",
    "        self.activ = nn.ReLU()\n",
    "        self.norm1 = nn.InstanceNorm2d(ins)\n",
    "        self.conv2 = nn.Conv2d(ins//2, ins//2, kernel_size=1, stride=1, dilation=1)\n",
    "        self.norm2 = nn.InstanceNorm2d(ins)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.activ(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.activ(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class HyperMapREDO(nn.Module):\n",
    "    def __init__(self,dropout_p = 0., encoder_sizes=[16,32,64,128,256], inchannels=3, outchannels=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        # input layer\n",
    "        self.conv_first = nn.Conv2d(inchannels, encoder_sizes[0], kernel_size=5, stride=1, dilation=1, padding='same')\n",
    "        self.activ = nn.ReLU()\n",
    "        \n",
    "        # encoder section\n",
    "        l = len(encoder_sizes) - 1\n",
    "        self.down_blocks = nn.ModuleList([\n",
    "            DownBlock(encoder_sizes[i], encoder_sizes[i+1]) for i in range(0, l)\n",
    "        ])\n",
    "        \n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            HmResBlock(c, dropout_p) for c in encoder_sizes\n",
    "        ])\n",
    "        \n",
    "        # decoder section\n",
    "        self.upsample_blocks = nn.ModuleList([\n",
    "            HmUpsampBlock(c) for c in encoder_sizes[:-1][::-1]\n",
    "        ])\n",
    "        \n",
    "        self.feature_blocks = nn.ModuleList([\n",
    "            HmFeatureBlock(encoder_sizes[l - i]) for i in range(l-1)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        # multi-scale feature section\n",
    "        self.ms_feature_layers = nn.ModuleList([\n",
    "            nn.Conv2d(encoder_sizes[2], encoder_sizes[1], 3, padding='same'),\n",
    "            nn.Conv2d(encoder_sizes[1], encoder_sizes[1], 3, padding='same'),\n",
    "            nn.Conv2d(encoder_sizes[1], encoder_sizes[1], 3, padding='same')\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        # output layer\n",
    "        self.last_1 = nn.Conv2d(encoder_sizes[1], encoder_sizes[1], 3, padding='same')\n",
    "        self.last_2 = nn.Conv2d(encoder_sizes[1]*3, encoder_sizes[1], 1)\n",
    "        self.last_3 = nn.Conv2d(encoder_sizes[1], outchannels, 1)\n",
    "        self.last_norm = nn.InstanceNorm2d(encoder_sizes[1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input layer\n",
    "        out = self.activ(self.conv_first(x))\n",
    "        # print(out.shape)\n",
    "        \n",
    "        skips = []\n",
    "        \n",
    "        # encoder section\n",
    "        out = self.res_blocks[0](out)\n",
    "        # print(out.shape)\n",
    "        skips.append(out)\n",
    "        for i in range(len(self.res_blocks) - 1):\n",
    "            out = self.down_blocks[i](out)\n",
    "            out = self.res_blocks[i+1](out)\n",
    "            # print(\"loop: \", out.shape)\n",
    "            skips.append(out)\n",
    "        \n",
    "        # decoder section\n",
    "        ml_features = []\n",
    "        out = skips.pop()\n",
    "        for i in range(len(self.upsample_blocks)):\n",
    "            # print(\"dec\")\n",
    "            if i > 0:\n",
    "                sk = skips.pop()\n",
    "                sk = transforms.center_crop(sk, out.shape[-2:])\n",
    "                out = torch.cat([out, sk], dim=1)\n",
    "                out = self.feature_blocks[i-1](out)\n",
    "            \n",
    "            if i > 1:\n",
    "                ml_features.append(self.ms_feature_layers[i-2](out))\n",
    "                \n",
    "            out = self.upsample_blocks[i](out)\n",
    "        \n",
    "        # final layers\n",
    "        sk = skips.pop()\n",
    "        sk = transforms.center_crop(sk, out.shape[-2:])\n",
    "        out = torch.cat([out, sk], dim=1)\n",
    "        out = self.last_norm(self.activ(self.last_1(out)))\n",
    "        \n",
    "        # multiscale feature section\n",
    "        ml_features = [out] + ml_features\n",
    "        ml_features = [F.interpolate(mf, size=x.shape[-2:], mode='bilinear') for mf in ml_features]\n",
    "        combined_features = torch.cat(ml_features, dim=1)\n",
    "        \n",
    "        out = self.activ(self.last_2(combined_features))\n",
    "        out = self.last_3(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff6c4e17-4d4b-4406-bfa1-6a488d8347d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowRankMultivariateNormalCustom(td.Distribution):\n",
    "    r\"\"\"\n",
    "    Creates a multivariate normal distribution with covariance matrix having a low-rank form\n",
    "    parameterized by :attr:`cov_factor` and :attr:`cov_diag`::\n",
    "\n",
    "        covariance_matrix = cov_factor @ cov_factor.T + cov_diag\n",
    "\n",
    "    Example:\n",
    "        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LAPACK)\n",
    "        >>> # xdoctest: +IGNORE_WANT(\"non-determenistic\")\n",
    "        >>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([[1.], [0.]]), torch.ones(2))\n",
    "        >>> m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[[1],[0]]`, cov_diag=`[1,1]`\n",
    "        tensor([-0.2102, -0.5429])\n",
    "\n",
    "    Args:\n",
    "        loc (Tensor): mean of the distribution with shape `batch_shape + event_shape`\n",
    "        cov_factor (Tensor): factor part of low-rank form of covariance matrix with shape\n",
    "            `batch_shape + event_shape + (rank,)`\n",
    "        cov_diag (Tensor): diagonal part of low-rank form of covariance matrix with shape\n",
    "            `batch_shape + event_shape`\n",
    "\n",
    "    Note:\n",
    "        The computation for determinant and inverse of covariance matrix is avoided when\n",
    "        `cov_factor.shape[1] << cov_factor.shape[0]` thanks to `Woodbury matrix identity\n",
    "        <https://en.wikipedia.org/wiki/Woodbury_matrix_identity>`_ and\n",
    "        `matrix determinant lemma <https://en.wikipedia.org/wiki/Matrix_determinant_lemma>`_.\n",
    "        Thanks to these formulas, we just need to compute the determinant and inverse of\n",
    "        the small size \"capacitance\" matrix::\n",
    "\n",
    "            capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor\n",
    "    \"\"\"\n",
    "    arg_constraints = {\"loc\": constraints.real_vector,\n",
    "                       \"cov_factor\": constraints.independent(constraints.real, 2),\n",
    "                       \"cov_diag\": constraints.independent(constraints.positive, 1)}\n",
    "    support = constraints.real_vector\n",
    "    has_rsample = True\n",
    "\n",
    "    def __init__(self, loc, cov_factor, cov_diag, validate_args=None):\n",
    "        if loc.dim() < 1:\n",
    "            raise ValueError(\"loc must be at least one-dimensional.\")\n",
    "        event_shape = loc.shape[-1:]\n",
    "        if cov_factor.dim() < 2:\n",
    "            raise ValueError(\"cov_factor must be at least two-dimensional, \"\n",
    "                             \"with optional leading batch dimensions\")\n",
    "        if cov_factor.shape[-2:-1] != event_shape:\n",
    "            raise ValueError(\"cov_factor must be a batch of matrices with shape {} x m\"\n",
    "                             .format(event_shape[0]))\n",
    "        if cov_diag.shape[-1:] != event_shape:\n",
    "            raise ValueError(\"cov_diag must be a batch of vectors with shape {}\".format(event_shape))\n",
    "\n",
    "        loc_ = loc.unsqueeze(-1)\n",
    "        cov_diag_ = cov_diag.unsqueeze(-1)\n",
    "        try:\n",
    "            loc_, self.cov_factor, cov_diag_ = torch.broadcast_tensors(loc_, cov_factor, cov_diag_)\n",
    "        except RuntimeError as e:\n",
    "            raise ValueError(\"Incompatible batch shapes: loc {}, cov_factor {}, cov_diag {}\"\n",
    "                             .format(loc.shape, cov_factor.shape, cov_diag.shape)) from e\n",
    "        self.loc = loc_[..., 0]\n",
    "        self.cov_diag = cov_diag_[..., 0]\n",
    "        batch_shape = self.loc.shape[:-1]\n",
    "\n",
    "        self._unbroadcasted_cov_factor = cov_factor\n",
    "        self._unbroadcasted_cov_diag = cov_diag\n",
    "        #self._capacitance_tril = _batch_capacitance_tril(cov_factor, cov_diag)\n",
    "        super().__init__(batch_shape, event_shape,\n",
    "                                                        validate_args=validate_args)\n",
    "\n",
    "    def expand(self, batch_shape, _instance=None):\n",
    "        new = self._get_checked_instance(LowRankMultivariateNormal, _instance)\n",
    "        batch_shape = torch.Size(batch_shape)\n",
    "        loc_shape = batch_shape + self.event_shape\n",
    "        new.loc = self.loc.expand(loc_shape)\n",
    "        new.cov_diag = self.cov_diag.expand(loc_shape)\n",
    "        new.cov_factor = self.cov_factor.expand(loc_shape + self.cov_factor.shape[-1:])\n",
    "        new._unbroadcasted_cov_factor = self._unbroadcasted_cov_factor\n",
    "        new._unbroadcasted_cov_diag = self._unbroadcasted_cov_diag\n",
    "        new._capacitance_tril = self._capacitance_tril\n",
    "        super(LowRankMultivariateNormal, new).__init__(batch_shape,\n",
    "                                                       self.event_shape,\n",
    "                                                       validate_args=False)\n",
    "        new._validate_args = self._validate_args\n",
    "        return new\n",
    "\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.loc\n",
    "\n",
    "    @property\n",
    "    def mode(self):\n",
    "        return self.loc\n",
    "\n",
    "    @lazy_property\n",
    "    def variance(self):\n",
    "        return (self._unbroadcasted_cov_factor.pow(2).sum(-1)\n",
    "                + self._unbroadcasted_cov_diag).expand(self._batch_shape + self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def scale_tril(self):\n",
    "        # The following identity is used to increase the numerically computation stability\n",
    "        # for Cholesky decomposition (see http://www.gaussianprocess.org/gpml/, Section 3.4.3):\n",
    "        #     W @ W.T + D = D1/2 @ (I + D-1/2 @ W @ W.T @ D-1/2) @ D1/2\n",
    "        # The matrix \"I + D-1/2 @ W @ W.T @ D-1/2\" has eigenvalues bounded from below by 1,\n",
    "        # hence it is well-conditioned and safe to take Cholesky decomposition.\n",
    "        n = self._event_shape[0]\n",
    "        cov_diag_sqrt_unsqueeze = self._unbroadcasted_cov_diag.sqrt().unsqueeze(-1)\n",
    "        Dinvsqrt_W = self._unbroadcasted_cov_factor / cov_diag_sqrt_unsqueeze\n",
    "        K = torch.matmul(Dinvsqrt_W, Dinvsqrt_W.mT).contiguous()\n",
    "        K.view(-1, n * n)[:, ::n + 1] += 1  # add identity matrix to K\n",
    "        scale_tril = cov_diag_sqrt_unsqueeze * torch.linalg.cholesky(K)\n",
    "        return scale_tril.expand(self._batch_shape + self._event_shape + self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def covariance_matrix(self):\n",
    "        covariance_matrix = (torch.matmul(self._unbroadcasted_cov_factor,\n",
    "                                          self._unbroadcasted_cov_factor.mT)\n",
    "                             + torch.diag_embed(self._unbroadcasted_cov_diag))\n",
    "        return covariance_matrix.expand(self._batch_shape + self._event_shape +\n",
    "                                        self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def precision_matrix(self):\n",
    "        # We use \"Woodbury matrix identity\" to take advantage of low rank form::\n",
    "        #     inv(W @ W.T + D) = inv(D) - inv(D) @ W @ inv(C) @ W.T @ inv(D)\n",
    "        # where :math:`C` is the capacitance matrix.\n",
    "        Wt_Dinv = (self._unbroadcasted_cov_factor.mT\n",
    "                   / self._unbroadcasted_cov_diag.unsqueeze(-2))\n",
    "        A = torch.linalg.solve_triangular(self._capacitance_tril, Wt_Dinv, upper=False)\n",
    "        precision_matrix = torch.diag_embed(self._unbroadcasted_cov_diag.reciprocal()) - A.mT @ A\n",
    "        return precision_matrix.expand(self._batch_shape + self._event_shape +\n",
    "                                       self._event_shape)\n",
    "\n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        shape = self._extended_shape(sample_shape)\n",
    "        W_shape = shape[:-1] + self.cov_factor.shape[-1:]\n",
    "        eps_W = _standard_normal(W_shape, dtype=self.loc.dtype, device=self.loc.device)\n",
    "        eps_D = _standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)\n",
    "        return (self.loc + _batch_mv(self._unbroadcasted_cov_factor, eps_W)\n",
    "                + self._unbroadcasted_cov_diag.sqrt() * eps_D)\n",
    "\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        diff = value - self.loc\n",
    "        M = _batch_lowrank_mahalanobis(self._unbroadcasted_cov_factor,\n",
    "                                       self._unbroadcasted_cov_diag,\n",
    "                                       diff,\n",
    "                                       self._capacitance_tril)\n",
    "        log_det = _batch_lowrank_logdet(self._unbroadcasted_cov_factor,\n",
    "                                        self._unbroadcasted_cov_diag,\n",
    "                                        self._capacitance_tril)\n",
    "        return -0.5 * (self._event_shape[0] * math.log(2 * math.pi) + log_det + M)\n",
    "\n",
    "\n",
    "    def entropy(self):\n",
    "        log_det = _batch_lowrank_logdet(self._unbroadcasted_cov_factor,\n",
    "                                        self._unbroadcasted_cov_diag,\n",
    "                                        self._capacitance_tril)\n",
    "        H = 0.5 * (self._event_shape[0] * (1.0 + math.log(2 * math.pi)) + log_det)\n",
    "        if len(self._batch_shape) == 0:\n",
    "            return H\n",
    "        else:\n",
    "            return H.expand(self._batch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8bfda25-a820-4c48-82bd-29a97206c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperMapp3rSSN2(HyperMapREDO):\n",
    "    def __init__(self,\n",
    "                 dropout_p = 0., encoder_sizes=[16,32,64,128,256], inchannels=3, out_channels=2,\n",
    "                 ssn_rank = 10,\n",
    "                 ssn_epsilon=1e-5,\n",
    "                 ssn_diagonal=False,\n",
    "                 dims=2\n",
    "                ):\n",
    "        super().__init__(dropout_p, encoder_sizes, inchannels, outchannels=encoder_sizes[0]) # last layer of just keeps number of nodes fixed this time)\n",
    "        \n",
    "        print(\"WARNING: this model assumes that the input to the model contains the brain mask in the first channel!\")\n",
    "        conv_func = get_conv_func(dims, transpose=False)\n",
    "        self.ssn_rank = ssn_rank\n",
    "        self.ssn_diagonal = ssn_diagonal\n",
    "        self.ssn_epsilon = ssn_epsilon\n",
    "        self.ssn_num_classes = out_channels\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(0.01)\n",
    "        \n",
    "        self.mean_l = conv_func(encoder_sizes[0], out_channels, kernel_size = (1,) *  dims, padding='same')\n",
    "        self.log_cov_diag_l = conv_func(encoder_sizes[0], out_channels, kernel_size = (1,) * dims, padding='same')\n",
    "        self.cov_factor_l = conv_func(encoder_sizes[0], out_channels * ssn_rank, kernel_size = (1,) * dims, padding='same')\n",
    "        #self.vk_l = conv_func(encoder_sizes[0], 2, kernel_size=7, padding='same')\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.lrelu(super().forward(x))\n",
    "\n",
    "        if torch.sum(torch.isnan(logits)) > 0:\n",
    "            print(\"NAN 1\", torch.sum(torch.isnan(logits)))\n",
    "        batch_size = logits.shape[0]\n",
    "        event_shape = (self.ssn_num_classes,) + logits.shape[2:]\n",
    "        \n",
    "        mean = self.mean_l(logits)\n",
    "        mean = mean.view((batch_size, -1))\n",
    "        \n",
    "        cov_diag = self.log_cov_diag_l(logits).exp() + self.ssn_epsilon\n",
    "        cov_diag = cov_diag.view((batch_size, -1))\n",
    "        \n",
    "        cov_factor = self.cov_factor_l(logits)\n",
    "        cov_factor = cov_factor.view((batch_size, self.ssn_rank, self.ssn_num_classes, -1))\n",
    "        cov_factor = cov_factor.flatten(2,3)\n",
    "        cov_factor = cov_factor.transpose(1,2)\n",
    "        if torch.sum(torch.isnan(mean)) > 0:\n",
    "            print(\"NAN 2\")\n",
    "        if torch.sum(torch.isnan(cov_diag)) > 0:\n",
    "            print(\"NAN 3\")\n",
    "        if torch.sum(torch.isnan(cov_factor)) > 0:\n",
    "            print(\"NAN 4\")\n",
    "            \n",
    "            \n",
    "        #vk = self.vk_l(logits).exp()\n",
    "        # print(vk.shape)\n",
    "        #vk = vk.mean(dim=(-1, -2)) # mean along each axis except for channel, yielding two values\n",
    "        #D = mean.shape[1]\n",
    "        #v = vk[:,0]\n",
    "        #k = vk[:,1]\n",
    "        #evidence_scale = (k+1) / (k*v)\n",
    "        \n",
    "        # print(\"vk shapes\")\n",
    "        # print(v.shape)\n",
    "        # print(k.shape)\n",
    "        # print(v, k, evidence_scale)\n",
    "        \n",
    "        # covariance tends to blow up to infinity, hence set to 0 outside the ROI\n",
    "        mask = x[:,1]\n",
    "        mask = mask.unsqueeze(1).expand((batch_size, self.ssn_num_classes) + mask.shape[1:]).reshape(batch_size, -1)\n",
    "        cov_factor = cov_factor * mask.unsqueeze(-1)\n",
    "        cov_diag = cov_diag * mask + self.ssn_epsilon\n",
    "        \n",
    "        if torch.sum(torch.isnan(cov_diag)) > 0:\n",
    "            print(\"NAN 3\")\n",
    "        if torch.sum(torch.isnan(cov_factor)) > 0:\n",
    "            print(\"NAN 4\")\n",
    "        \n",
    "        # print(evidence_scale.shape, (evidence_scale**0.5).shape)\n",
    "        # print(cov_diag.shape, cov_factor.shape)\n",
    "#         cov_diag *= evidence_scale.unsqueeze(-1)\n",
    "#         cov_factor *= (evidence_scale**0.5).unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        if torch.sum(torch.isnan(mask)) > 0:\n",
    "            print(\"NAN 5\")\n",
    "        if torch.sum(torch.isnan(cov_factor)) > 0:\n",
    "            print(\"NAN 6\")\n",
    "        if torch.sum(torch.isnan(cov_diag)) > 0:\n",
    "            print(\"NAN 7\")\n",
    "            \n",
    "        # print(cov_diag)\n",
    "        \n",
    "        if self.ssn_diagonal:\n",
    "            base_distribution = td.Independent(td.Normal(loc=mean, scale=torch.sqrt(cov_diag)), 1)\n",
    "        else:\n",
    "            try:\n",
    "                base_distribution = LowRankMultivariateNormalCustom(loc=mean, cov_factor=cov_factor, cov_diag=cov_diag)\n",
    "                #base_distribution = LowRankMultivariateStudentT_V3(df=v, loc=mean, cov_factor=cov_factor, cov_diag=cov_diag)\n",
    "                #print(\"using multivariate normal!\")\n",
    "            except Exception as e:\n",
    "                print(\"was thrown: \", e)\n",
    "                print('hmm: Covariance became non invertible using independent normals for this batch!')\n",
    "                print(\"cov diag okay: \", torch.sum(cov_diag <=0))\n",
    "                print(\"sqrt cov diag okay: \", torch.sum(torch.sqrt(cov_diag) <=0))\n",
    "                \n",
    "                try:\n",
    "                    base_distribution = td.Independent(td.Normal(loc=mean, scale=torch.sqrt(cov_diag)),1)\n",
    "                except Exception as e:\n",
    "                    print(\"second fail: \", e)\n",
    "                    print(torch.min(torch.sqrt(cov_diag), torch.max(torch.sqrt(cov_diag))))\n",
    "        \n",
    "        distribution = ReshapedDistribution(base_distribution, event_shape)\n",
    "        \n",
    "        shape = (batch_size,) + event_shape\n",
    "        logit_mean_view = mean.view(shape).detach()\n",
    "        cov_diag_view = cov_diag.view(shape).detach()\n",
    "        cov_factor_view = cov_factor.transpose(2,1).view((batch_size, self.ssn_num_classes * self.ssn_rank) + event_shape[1:]).detach()\n",
    "        \n",
    "        # compute the diagonal of the precision matrix for the evidence regularizer\n",
    "#         U = cov_factor\n",
    "#         D_inv = 1./cov_diag\n",
    "#         # print(\"shapes for regularizer\")\n",
    "#         # print(\"U, U.mt\", U.shape, U.mT.shape)\n",
    "#         # print(\"D\", D_inv.shape)\n",
    "        \n",
    "#         D_inv_mult = D_inv.unsqueeze(-1).expand(U.shape)\n",
    "#         # print(\"D inv mult\", D_inv_mult.shape)\n",
    "        \n",
    "#         F = torch.eye(self.ssn_rank).to(U.device) + U.mT.bmm(D_inv_mult * U)\n",
    "#         # print(\"F\", F.shape)\n",
    "        \n",
    "#         RRT = torch.cholesky_inverse(F)\n",
    "#         R = torch.cholesky(RRT)\n",
    "        \n",
    "#         # print(\"R\", R.shape)\n",
    "#         V = (D_inv_mult * U).bmm(R)\n",
    "#         # print(\"V\", V.shape)\n",
    "        \n",
    "#         # print(\"diag v\", torch.diagonal(V, dim1=1, dim2=2).shape, V.shape)\n",
    "        \n",
    "#         pres_diag = D_inv - torch.sum(V * V, dim=2) # get the diagonal of the V@V.T matrix without computing it\n",
    "             \n",
    "        \n",
    "        output_dict = {\n",
    "            # 'v':v,\n",
    "            # 'k':k,\n",
    "            'logit_mean':logit_mean_view,\n",
    "            'cov_diag':cov_diag_view,\n",
    "            'cov_factor':cov_factor_view,\n",
    "            'distribution':distribution,\n",
    "            # 'pres_diag':pres_diag,\n",
    "        }\n",
    "        \n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483e7c56-d9c2-4f5e-a39e-1d649bd73de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_raw = HyperMapp3rSSN2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62bd7fea-d22e-4bb6-81fd-f03c190910cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = StandardLitModelWrapper.load_from_checkpoint('/disk/scratch_big/s2208943/results/new_tests/epoch=15-step=2192.ckpt', model=model_raw, loss=loss, \n",
    "#                                 logging_metric=SsnDiceMetricWrapper,\n",
    "#                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e971150-0e58-4135-96de-2bf162be1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_re_parametrization_trick(dist, num_samples):\n",
    "    assert num_samples % 2 == 0\n",
    "    samples = dist.rsample((num_samples // 2,))\n",
    "    mean = dist.mean.unsqueeze(0)\n",
    "    samples = samples - mean\n",
    "    return torch.cat([samples, -samples]) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2341321d-a70f-48f4-bfb6-859799b1213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist = model_raw(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2b82b19-ca8e-42ae-aef5-3a2f4945e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l = loss(dist, y.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3dd1e8-0c1e-439e-8f81-cb75c724bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss(dist, y.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ec5ca75-f0aa-4db4-bbf4-3be98658ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction_loss(dist, target):\n",
    "    y = target\n",
    "    m = dist['logit_mean']\n",
    "    v = torch.nn.functional.softmax(m, dim=1)\n",
    "    \n",
    "    shape = [*y.unsqueeze(1).shape]\n",
    "    shape[1] = 2 # 2 classes\n",
    "    bs = shape[0]\n",
    "    \n",
    "    a = torch.zeros(shape)\n",
    "    \n",
    "    a[:,1] = y\n",
    "    a[:,0] = 1-y\n",
    "    pair_y = a.to(v.device)\n",
    "    \n",
    "    diff = (v.view(bs, -1) - pair_y.reshape(bs, -1)).abs().view(bs, -1) * 0.5\n",
    "    \n",
    "    correction = dist['v'].view(-1, 1).expand(diff.shape) + dist['k'].view(-1, 1).expand(diff.shape) * dist['pres_diag']\n",
    "    \n",
    "    closs = (correction * diff).mean()\n",
    "    \n",
    "    closs = closs.clip(0,1000)\n",
    "    \n",
    "    return closs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "479b1d2b-ee5b-4ceb-ba32-cda0d413d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticSegmentationNetworkLossMCIntegral(nn.Module):\n",
    "    def __init__(self, num_mc_samples: int = 1):\n",
    "        super().__init__()\n",
    "        self.num_mc_samples = num_mc_samples\n",
    "\n",
    "    @staticmethod\n",
    "    def fixed_re_parametrization_trick(dist, num_samples):\n",
    "        assert num_samples % 2 == 0\n",
    "        samples = dist.rsample((num_samples // 2,))\n",
    "        mean = dist.mean.unsqueeze(0)\n",
    "        samples = samples - mean\n",
    "        return torch.cat([samples, -samples]) + mean\n",
    "\n",
    "    def forward(self, result_dict, target, **kwargs):\n",
    "        logits = result_dict['logit_mean']\n",
    "        distribution = result_dict['distribution']\n",
    "        \n",
    "        batch_size = logits.shape[0]\n",
    "        num_classes = logits.shape[1]\n",
    "        assert num_classes >= 2  # not implemented for binary case with implied background\n",
    "        # logit_sample = distribution.rsample((self.num_mc_samples,))\n",
    "        logit_sample = self.fixed_re_parametrization_trick(distribution, self.num_mc_samples)\n",
    "        target = target.unsqueeze(1)\n",
    "        target = target.expand((self.num_mc_samples,) + target.shape)\n",
    "\n",
    "        flat_size = self.num_mc_samples * batch_size\n",
    "        logit_sample = logit_sample.view((flat_size, num_classes, -1))\n",
    "        target = target.reshape((flat_size, -1))\n",
    "\n",
    "        log_prob = -F.cross_entropy(logit_sample, target, reduction='none').view((self.num_mc_samples, batch_size, -1))\n",
    "        loglikelihood = torch.mean(torch.logsumexp(torch.sum(log_prob, dim=-1), dim=0) - math.log(self.num_mc_samples))\n",
    "        loss = -loglikelihood\n",
    "        return loss\n",
    "    \n",
    "def fixed_re_parametrization_trick(dist, num_samples):\n",
    "        assert num_samples % 2 == 0\n",
    "        samples = dist.rsample((num_samples // 2,))\n",
    "        mean = dist.mean.unsqueeze(0)\n",
    "        samples = samples - mean\n",
    "        return torch.cat([samples, -samples]) + mean\n",
    "\n",
    "\n",
    "class SsnNetworkMeanLossWrapper(nn.Module):\n",
    "    def __init__(self, loss_func):\n",
    "        super().__init__()\n",
    "        self.loss = loss_func\n",
    "    def forward(self, result_dict, target):\n",
    "        mean = result_dict['logit_mean']\n",
    "        return self.loss(mean, target)\n",
    "    \n",
    "class SsnNetworkSampleLossWrapper(nn.Module):\n",
    "    def __init__(self, loss_func, samples=10):\n",
    "        super().__init__()\n",
    "        self.loss = loss_func\n",
    "        self.samples = samples\n",
    "    def forward(self, result_dict, target):\n",
    "        samples = fixed_re_parametrization_trick(result_dict['distribution'], self.samples).to(target.device)\n",
    "        loss = 0\n",
    "        for s in samples:\n",
    "            loss += self.loss(s, target)\n",
    "        return loss / self.samples\n",
    "    \n",
    "def avd(logits, target):\n",
    "    preds = torch.nn.functional.softmax(logits, dim=1)[:,1]\n",
    "    bs = preds.shape[0]\n",
    "    preds = preds.view(bs, -1)\n",
    "    target = target.view(bs, -1)\n",
    "\n",
    "    vd = torch.sum(target, dim=1) - torch.sum(preds, dim=1)\n",
    "    avd = vd.abs()\n",
    "    l = avd.sum()\n",
    "    return l\n",
    "    \n",
    "    \n",
    "class SsnNetworkMuAndSamplesLossWrapper(nn.Module):\n",
    "    def __init__(self, loss_func, samples=10):\n",
    "        super().__init__()\n",
    "        self.loss = loss_func\n",
    "        self.samples = samples\n",
    "    def forward(self, result_dict, target):\n",
    "        s = result_dict['distribution'].mean # samples[0]\n",
    "        #print(s.shape, result_dict['distribution'].mean.shape)\n",
    "        dice = self.loss(s, target)\n",
    "        samples = fixed_re_parametrization_trick(result_dict['distribution'], self.samples).to(target.device)\n",
    "        loss = 0\n",
    "        for s in samples:\n",
    "            loss += self.loss(s, target)\n",
    "        \n",
    "        return dice + ((0.1*loss) / self.samples)\n",
    "    \n",
    "class SsnDiceMetricWrapper(DiceLossMetric):\n",
    "\n",
    "    def update(self, preds_dict, target: torch.Tensor):\n",
    "        super().update(preds_dict['logit_mean'], target)\n",
    "\n",
    "    def compute(self):\n",
    "        return super().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e073d7b4-5572-4cb1-b768-f4473f7cd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssn_diceloss = SsnNetworkMuAndSamplesLossWrapper(dice_loss)# SsnNetworkMeanLossWrapper(dice_loss)\n",
    "mc_loss = StochasticSegmentationNetworkLossMCIntegral(num_mc_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afe2e23f-7689-4545-b989-7c03b6d77b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardLitModelWrapper(pl.LightningModule):\n",
    "        def __init__(self, model, loss=F.cross_entropy, logging_metric=None, optimizer_params={\"lr\":1e-3}, lr_scheduler_params={\"step_size\":30, \"gamma\":0.1}, is_uq_model=False,\n",
    "                    optimizer_constructor=None, lr_scheduler_constructor=None):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.loss = loss\n",
    "            self.logging_metric_train = logging_metric()\n",
    "            self.logging_metric_val = logging_metric()\n",
    "            self.optim_params = optimizer_params\n",
    "            self.lr_scheduler_params = lr_scheduler_params\n",
    "            self.is_uq_model = False\n",
    "            self.optimizer_constructor = optimizer_constructor\n",
    "            self.lr_scheduler_constructor = lr_scheduler_constructor\n",
    "\n",
    "\n",
    "        def forward(self, x, **kwargs):\n",
    "            return self.model(x, **kwargs)\n",
    "\n",
    "        def configure_optimizers(self):\n",
    "            # optimizer and schedulers go in the configure optimizers hook\n",
    "            if self.optimizer_constructor:\n",
    "                optimizer = self.optimizer_constructor(self.parameters(), **self.optim_params)\n",
    "            else:\n",
    "                optimizer = torch.optim.Adam(self.parameters(), **self.optim_params)\n",
    "\n",
    "            if self.lr_scheduler_constructor:\n",
    "                lr_scheduler = self.lr_scheduler_constructor(optimizer, **self.lr_scheduler_params)\n",
    "            else:\n",
    "                lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, **self.lr_scheduler_params)\n",
    "\n",
    "            return [optimizer], [lr_scheduler]\n",
    "\n",
    "        def training_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            lightning automates the training loop, \n",
    "            does epoch, back_tracking, optimizers and schedulers,\n",
    "            and metric reduction.\n",
    "            we just define how we want to process a single batch. \n",
    "            we can optionally pass optimizer_idx if we want to define multiple optimizers within the configure_optimizers\n",
    "            hook, and I presume we can add our own parameters also to functions?\n",
    "            \"\"\"\n",
    "\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(True)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            loss = self.loss(y_hat, y)\n",
    "\n",
    "            # metrics \n",
    "            if self.logging_metric_train:\n",
    "                self.logging_metric_train(y_hat, y)\n",
    "                self.log(f\"train_metric\", self.logging_metric_train, on_step=True, on_epoch=False, prog_bar=True)\n",
    "            self.log(\"train_loss\", loss)\n",
    "\n",
    "            return loss\n",
    "\n",
    "    #     def training_epoch_end(self, outs):\n",
    "    #         self.log('train_metric_epoch', self.logging_metric_train.compute())\n",
    "\n",
    "    #     def validation_epoch_end(self, outs):\n",
    "    #         self.log('val_metric_epoch', self.logging_metric_val.compute())\n",
    "\n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            note: call trainer.validate() automatically loads the best checkpoint if checkpointing was enabled during fitting\n",
    "            well yes I want to enable checkpointing but will deal with that later.\n",
    "            also it does stuff like model.eval() and torch.no_grad() automatically which is nice.\n",
    "            I will need a custom eval thing to do my dropout estimation but can solve that later too.\n",
    "            \"\"\"\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(False)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            val_loss = self.loss(y_hat, y)\n",
    "\n",
    "            if self.logging_metric_val:\n",
    "                self.logging_metric_val(y_hat, y)\n",
    "                self.log(f\"val_metric\", self.logging_metric_val, on_step=True, on_epoch=True, prog_bar=True)\n",
    "            self.log(\"val_loss\", val_loss)\n",
    "\n",
    "        def test_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            we would need to directly call this function using the trainer\n",
    "            \"\"\"\n",
    "\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(False)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            test_loss = self.loss(y_hat, y)\n",
    "            self.log(\"test_loss\", test_loss)\n",
    "\n",
    "        def predict_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            just for making predictions as opposed to collecting metrics etc\n",
    "            note to use this, we just call .predict(dataloader) and it then automates the look\n",
    "            these functions are for a single batch. Nice.\n",
    "            \"\"\"\n",
    "            X, y = batch\n",
    "            pred = self(X)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff11de79-4d1b-4c96-92c2-b093599bc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_factor = 5\n",
    "#avd_factor = 0.001\n",
    "    \n",
    "def double_loss(outs, target):\n",
    "    dice = ssn_diceloss(outs, target)\n",
    "    return dice * dice_factor + mc_loss(outs, target) * 0.01\n",
    "\n",
    "def triple_loss(outs, target):\n",
    "    main_loss = ssn_diceloss(outs, target) * dice_factor + mc_loss(outs, target) * 0.01\n",
    "    \n",
    "    if main_loss < 60:\n",
    "        main_loss += correction_loss(outs, target) * 0.1\n",
    "    return main_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ce785ac-cd1c-4f55-ac12-16f9dc23d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = double_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "994cd790-25b4-451a-8970-3c3436f3918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_raw = HyperMapp3rSSN2(ssn_rank=15).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3168152-1d99-4d7d-ad6f-fdb0192f7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = double_loss\n",
    "#loss = triple_loss\n",
    "\n",
    "optimizer_params={\"lr\":2e-4}\n",
    "optimizer = torch.optim.Adam\n",
    "lr_scheduler_params={\"milestones\":[1000], \"gamma\":0.5}\n",
    "lr_scheduler_constructor = torch.optim.lr_scheduler.MultiStepLR\n",
    "\n",
    "trained_ckpt_dir = '/disk/scratch/s2208943/results/new_tests/evid_ssn/'\n",
    "trained_model = 'epoch=29-step=4110.ckpt'\n",
    "\n",
    "# model = StandardLitModelWrapper(model_raw, loss, \n",
    "#                                 logging_metric=SsnDiceMetricWrapper, # lambda : None,\n",
    "#                                 optimizer_params=optimizer_params,\n",
    "#                                 lr_scheduler_params=lr_scheduler_params,\n",
    "#                                 is_uq_model=False,\n",
    "#                                 optimizer_constructor=optimizer,\n",
    "#                                 lr_scheduler_constructor=lr_scheduler_constructor\n",
    "#                                )\n",
    "\n",
    "# model = StandardLitModelWrapper.load_from_checkpoint(trained_ckpt_dir + trained_model,\n",
    "#                                                      model_raw, loss, \n",
    "#                                 logging_metric=SsnDiceMetricWrapper, # lambda : None,\n",
    "#                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "182a6b0a-ae61-423d-b7b2-b662af38ea11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "accelerator=\"gpu\"\n",
    "devices=1\n",
    "max_epochs=1000\n",
    "precision = 32\n",
    "\n",
    "rootdir = \"/disk/scratch/s2208943/results/new_tests/evid_ssn\"\n",
    "final_dir = rootdir\n",
    "checkpoint_callback = ModelCheckpoint(final_dir, save_top_k=-1, monitor=\"val_loss\", every_n_epochs=5)\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=15, verbose=\"False\", mode=\"min\", check_finite=True)\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    max_epochs=max_epochs,\n",
    "    precision=precision,\n",
    "    default_root_dir=final_dir\n",
    ")\n",
    "\n",
    "#trainer.fit(model, train_dataloader, val_dataloader,)# ckpt_path='/disk/scratch_big/s2208943/results/new_tests/epoch=15-step=2192.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b961ff1f-35ba-4abd-9e54-744e1a060a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndigit(n, x):\n",
    "    s = str(x)\n",
    "    ns = \"0\" * (n - len(s))\n",
    "    return ns + s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57adac3-db4f-4af0-990f-6bc7d5772330",
   "metadata": {},
   "source": [
    "### generating the samples procedure, only do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee61edb3-1ecb-4080-ac5d-930b58ae9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a836942-bba5-408b-a42d-d814a1ec79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is test on the validation data!!! not cheating!\n",
    "xs3d = []\n",
    "ys3d = []\n",
    "for x, y in val_dataset_3d:\n",
    "    xs3d.append(x)\n",
    "    ys3d.append(y.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b98b4bc-f516-43a0-bc8f-57aa76ef9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(folders, cs, folder_index):\n",
    "    f = folders[folder_index]\n",
    "    c = cs[folder_index]\n",
    "    ckpt = f + c\n",
    "\n",
    "    model = StandardLitModelWrapper.load_from_checkpoint(f + c, model=model_raw, loss=loss, \n",
    "                                logging_metric=DiceLossMetric).cuda()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47eb87f1-0838-4946-a50f-e2a7e4c733d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_means(xs3dQ, ys3dQ, model, num_samples=20):\n",
    "    samples3d = []\n",
    "    model_means3d = []\n",
    "        \n",
    "    for j in tqdm(range(len(xs3dQ)), position=0, leave=True, ncols=150):\n",
    "        with torch.no_grad():\n",
    "            out = model(xs3dQ[j].swapaxes(0,1).cuda())\n",
    "            mean = out['distribution'].mean.cpu()\n",
    "            model_means3d.append(mean)\n",
    "                \n",
    "    return model_means3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10e76b5b-ec21-4aaa-a3dc-bc5fac9adecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root1 = \"/home/s2208943/ipdis/results/revamped_models/\"\n",
    "root2 = \"/home/s2208943/ipdis/results/final_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba3af8f9-f9d8-45d2-be25-5e42babaa9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_Xssn = [root2 + \"Xnew_ssn_ens\" + ndigit(2, x+1) + \"/\" for x in range(10)]\n",
    "folders_ssn = [root2 + \"new_ssn_ens\" + ndigit(2, x+11) + \"/\" for x in range(10)]\n",
    "folders_REDO_ssn  = [root1 + fi + \"/\" for fi in os.listdir(root1) if \"REDO_ssn\" in fi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a613da3-be67-48bc-8384-6e36b2f92792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: this model assumes that the input to the model contains the brain mask in the first channel!\n"
     ]
    }
   ],
   "source": [
    "model_raw = HyperMapp3rSSN2(ssn_rank=15).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "71360af3-b1ec-4857-bfff-abbc293dc6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class temp_param(nn.Module):\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.t = torch.nn.Parameter(torch.randn((1,)) * 0.25 + 0.25)\n",
    "        self.factor = factor\n",
    "        \n",
    "    def forward(self, x, from_pred=False):\n",
    "        if not from_pred:\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)['logit_mean']\n",
    "        else:\n",
    "            pred = x\n",
    "        \n",
    "        t = self.t\n",
    "        t = torch.sigmoid(t) * self.factor\n",
    "        return pred/t\n",
    "    \n",
    "    def get_t(self):\n",
    "        return torch.sigmoid(self.t).item() * self.factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ca5cecc5-17c1-40f2-a4b3-ea76acae30b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "accelerator=\"gpu\"\n",
    "devices=1\n",
    "max_epochs=12\n",
    "precision = 32\n",
    "rootdir = \"/disk/scratch/s2208943/results/new_tests/blarg\"\n",
    "final_dir = rootdir\n",
    "\n",
    "temp_trainer = pl.Trainer(\n",
    "    callbacks=None,\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    max_epochs=max_epochs,\n",
    "    precision=precision,\n",
    "    default_root_dir=final_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0389d928-4b3a-4297-9fce-40d7ee75278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "989c7747-98da-433d-907d-2ff735d361a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens01/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5160c6907046a5a0be336e966288ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens01/ 1.6515244245529175\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens02/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090757bd4540453782f9af1744a1ee85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens02/ 1.5358566641807556\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens03/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cadf5bad0384b6bac02eacc5f6b188e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens03/ 1.9485957026481628\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens04/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cd3bd653404a089ccc7186f79ef883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens04/ 1.7483945488929749\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens05/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3a621539b545a996a7d7444db4880d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens05/ 1.6329590678215027\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens06/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f0c07417e9444db3e4277139f466f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens06/ 1.53331857919693\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens07/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfd976ad934483fb14061df7b7764e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens07/ 1.6683434844017029\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens08/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f530d3e0719c4f8a80237a78f7194c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | temp_param       | 1     \n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "1         Trainable params\n",
      "0         Non-trainable params\n",
      "1         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens08/ 1.7123401165008545\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens09/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a3824862e4427db710e79184e0d334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens09/ 1.6098804473876953\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens10/\n",
      "/home/s2208943/ipdis/results/final_models/Xnew_ssn_ens10/ 1.5844781398773193\n"
     ]
    }
   ],
   "source": [
    "folders = folders_Xssn\n",
    "\n",
    "\n",
    "cs = []\n",
    "for f in folders:\n",
    "    ckpts = sorted([c for c in os.listdir(f) if \"epoch\" in c])\n",
    "    c = ckpts[-2] # the second from last seems to be the 'best' checkpoint\n",
    "    cs.append(c)\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    print(folders[i])\n",
    "    rank = folders[i][12:14]\n",
    "    model = load_model(folders, cs, i)\n",
    "    #means3d = gen_samples(xs3d, ys3d, model, num_samples=34)\n",
    "    \n",
    "    temp = temp_param(3)\n",
    "    \n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    temp_model = StandardLitModelWrapper(temp, loss=loss, \n",
    "                                    logging_metric=lambda : None,\n",
    "                                    optimizer_params=optimizer_params,\n",
    "                                    lr_scheduler_params=lr_scheduler_params,\n",
    "                                    is_uq_model=False,\n",
    "                                    optimizer_constructor=optimizer,\n",
    "                                    lr_scheduler_constructor=lr_scheduler_constructor\n",
    "                                   )\n",
    "    temp_trainer = pl.Trainer(\n",
    "        callbacks=None,\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=max_epochs,\n",
    "        precision=precision,\n",
    "        default_root_dir=final_dir\n",
    "    )\n",
    "    temp_trainer.fit(temp_model, val_dataloader)\n",
    "    \n",
    "    print(folders[i], temp_model.model.get_t())\n",
    "    ts.append((folders[i], temp_model.model.get_t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ca0e6-7201-4b12-849d-ba29e4068730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders = folders_Xssn\n",
    "\n",
    "\n",
    "# cs = []\n",
    "# for f in folders:\n",
    "#     ckpts = sorted([c for c in os.listdir(f) if \"epoch\" in c])\n",
    "#     c = ckpts[-2] # the second from last seems to be the 'best' checkpoint\n",
    "#     cs.append(c)\n",
    "\n",
    "# for i in range(len(folders)):\n",
    "#     print(folders[i])\n",
    "#     rank = folders[i][12:14]\n",
    "#     model = load_model(folders, cs, i)\n",
    "#     #means3d = gen_samples(xs3d, ys3d, model, num_samples=34)\n",
    "    \n",
    "#     temp = temp_param()\n",
    "    \n",
    "#     loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     temp_model = StandardLitModelWrapper(temp, loss=loss, \n",
    "#                                     logging_metric=lambda : None,\n",
    "#                                     optimizer_params=optimizer_params,\n",
    "#                                     lr_scheduler_params=lr_scheduler_params,\n",
    "#                                     is_uq_model=False,\n",
    "#                                     optimizer_constructor=optimizer,\n",
    "#                                     lr_scheduler_constructor=lr_scheduler_constructor\n",
    "#                                    )\n",
    "#     temp_trainer = pl.Trainer(\n",
    "#         callbacks=None,\n",
    "#         accelerator=accelerator,\n",
    "#         devices=devices,\n",
    "#         max_epochs=max_epochs,\n",
    "#         precision=precision,\n",
    "#         default_root_dir=final_dir\n",
    "#     )\n",
    "#     temp_trainer.fit(temp_model, val_dataloader)\n",
    "    \n",
    "#     print(folders[i], temp_model.model.get_t())\n",
    "#     ts.append((folders[i], temp_model.model.get_t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf45b5f-5432-4ad9-8b2b-49ef8e2dd851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders = folders_REDO_ssn\n",
    "\n",
    "\n",
    "# cs = []\n",
    "# for f in folders:\n",
    "#     ckpts = sorted([c for c in os.listdir(f) if \"epoch\" in c])\n",
    "#     c = ckpts[-2] # the second from last seems to be the 'best' checkpoint\n",
    "#     cs.append(c)\n",
    "\n",
    "#     curr_rank = -1\n",
    "# for i in range(len(folders)):\n",
    "#     print(folders[i])\n",
    "#     rank = folders[i][12:14]\n",
    "#     if rank != curr_rank:\n",
    "#         model_raw = HyperMapp3rSSN2(ssn_rank=int(rank)).cuda()\n",
    "#         curr_rank = rank\n",
    "#     model = load_model(folders, cs, i)\n",
    "#     #means3d = gen_samples(xs3d, ys3d, model, num_samples=34)\n",
    "    \n",
    "#     temp = temp_param()\n",
    "    \n",
    "#     loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     temp_model = StandardLitModelWrapper(temp, loss=loss, \n",
    "#                                     logging_metric=lambda : None,\n",
    "#                                     optimizer_params=optimizer_params,\n",
    "#                                     lr_scheduler_params=lr_scheduler_params,\n",
    "#                                     is_uq_model=False,\n",
    "#                                     optimizer_constructor=optimizer,\n",
    "#                                     lr_scheduler_constructor=lr_scheduler_constructor\n",
    "#                                    )\n",
    "#     temp_trainer = pl.Trainer(\n",
    "#         callbacks=None,\n",
    "#         accelerator=accelerator,\n",
    "#         devices=devices,\n",
    "#         max_epochs=max_epochs,\n",
    "#         precision=precision,\n",
    "#         default_root_dir=final_dir\n",
    "#     )\n",
    "#     temp_trainer.fit(temp_model, val_dataloader)\n",
    "    \n",
    "#     print(folders[i], temp_model.model.get_t())\n",
    "#     ts.append((folders[i], temp_model.model.get_t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c21a6-dd39-4e42-8dd4-982f6764ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders_ind_ssn  = ([root1 + fi + \"/\" for fi ['Xssn_independent_muonly03', 'Xssn_independent_muonly04']]\n",
    "#                     +[root2 + fi + \"/\" for fi ['Xssn_independent_muonly02', 'Xssn_independent_muonly01', 'Xssn_independent01', 'Xssn_independent02']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da1ac53d-4ca4-4582-b302-ab7b7f799697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_fr(folders, cs, folder_index, model_raw):\n",
    "    f = folders[folder_index]\n",
    "    c = cs[folder_index]\n",
    "    ckpt = f + c\n",
    "\n",
    "    model = StandardLitModelWrapper.load_from_checkpoint(f + c, model=model_raw, loss=loss, \n",
    "                                logging_metric=DiceLossMetric).cuda()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddfc4404-52e7-4bf7-82b7-82f1edbcd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_ind_ssn  = ([root1 + fi + \"/\" for fi in ['Xssn_independent_muonly03', 'Xssn_independent_muonly04']]\n",
    "                    +[root2 + fi + \"/\" for fi in ['Xssn_independent_muonly02', 'Xssn_independent_muonly01', 'Xssn_independent01', 'Xssn_independent02']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b8ba9b0-d181-45e3-ba13-a15f03062b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: this model assumes that the input to the model contains the brain mask in the first channel!\n"
     ]
    }
   ],
   "source": [
    "model_raw = HyperMapp3rSSN2(ssn_rank=1, ssn_diagonal=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e66c23ed-de6e-4aab-beaa-cc08aafe8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = folders_ind_ssn\n",
    "\n",
    "cs = []\n",
    "for f in folders:\n",
    "    ckpts = sorted([c for c in os.listdir(f) if \"epoch\" in c])\n",
    "    c = ckpts[-2] # the second from last seems to be the 'best' checkpoint\n",
    "    cs.append(c)\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    print(folders[i])\n",
    "    rank = folders[i][12:14]\n",
    "    model = load_model_fr(folders, cs, i, model_raw)\n",
    "    #means3d = gen_samples(xs3d, ys3d, model, num_samples=34)\n",
    "    \n",
    "    temp = temp_param(factor=3)\n",
    "    \n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    temp_model = StandardLitModelWrapper(temp, loss=loss, \n",
    "                                    logging_metric=lambda : None,\n",
    "                                    optimizer_params=optimizer_params,\n",
    "                                    lr_scheduler_params=lr_scheduler_params,\n",
    "                                    is_uq_model=False,\n",
    "                                    optimizer_constructor=optimizer,\n",
    "                                    lr_scheduler_constructor=lr_scheduler_constructor\n",
    "                                   )\n",
    "    temp_trainer = pl.Trainer(\n",
    "        callbacks=None,\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        max_epochs=max_epochs,\n",
    "        precision=precision,\n",
    "        default_root_dir=final_dir\n",
    "    )\n",
    "    temp_trainer.fit(temp_model, val_dataloader)\n",
    "    \n",
    "    print(folders[i], temp_model.model.get_t())\n",
    "    ts.append((folders[i], temp_model.model.get_t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d35fa850-decd-49ba-a7b4-a9b83d303b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samples2(xs3dQ, ys3dQ, model, num_samples=20):\n",
    "    samples3d = []\n",
    "    model_means3d = []\n",
    "        \n",
    "    for j in tqdm(range(len(xs3dQ)), position=0, leave=True, ncols=150):\n",
    "        with torch.no_grad():\n",
    "            out = model(xs3dQ[j].swapaxes(0,1).cuda())\n",
    "            samples = fixed_re_parametrization_trick(out['distribution'], num_samples).cpu()\n",
    "            samples3d.append(samples)\n",
    "            mean = out['distribution'].mean.cpu()\n",
    "            model_means3d.append(mean)\n",
    "                \n",
    "    return samples3d, model_means3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a9d06e50-e1d6-44d9-acaf-849b8f0b17b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: this model assumes that the input to the model contains the brain mask in the first channel!\n"
     ]
    }
   ],
   "source": [
    "model_raw = HyperMapp3rSSN2(ssn_rank=1, ssn_diagonal=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1312c931-61f0-4901-b224-9883df540431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_map_from_samples(samples):\n",
    "    \"samples is of shape samples, batch size, channels, image dims  [s, b, c *<dims>]\"\n",
    "    probs = torch.nn.functional.softmax(samples, dim=2)\n",
    "    pic = torch.mean(probs, dim=0)\n",
    "    ent_map = torch.sum(-pic * torch.log(pic+1e-30), dim=1)\n",
    "    \n",
    "    return ent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "11f1b5db-e259-45d3-9ab1-0083d00ed839",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def sUEO(ent, target):\n",
    "    numerator = 2 * torch.sum(ent * target)\n",
    "    denominator = torch.sum((target**2) + (ent**2))\n",
    "    return (numerator / denominator).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3f1aab5b-2eb7-4ef8-ab35-def7ca03a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncetainty_thresholds = torch.arange(0, 0.7, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0636894c-8198-4ca1-b856-aeadb0286966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: this model assumes that the input to the model contains the brain mask in the first channel!\n"
     ]
    }
   ],
   "source": [
    "model_raw = HyperMapp3rSSN2(ssn_rank=15).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b3b1cb2f-ed2e-4fc2-b9b0-0d2f8fd59d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ab74c87-724e-463f-904b-9cdc0c467063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:19<00:00,  1.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:09<00:00,  7.25it/s]\n"
     ]
    }
   ],
   "source": [
    "t = 1.\n",
    "folders = folders_Xssn\n",
    "\n",
    "cs = []\n",
    "for f in folders:\n",
    "    ckpts = sorted([c for c in os.listdir(f) if \"epoch\" in c])\n",
    "    c = ckpts[-2] # the second from last seems to be the 'best' checkpoint\n",
    "    cs.append(c)\n",
    "\n",
    "model = load_model_fr(folders, cs, i, model_raw)\n",
    "samples3d, means3d = gen_samples2(xs3d, ys3d, model, num_samples=34)\n",
    "ind_ent_maps = [entropy_map_from_samples(samples3d[k]/t) for k in range(len(ys3d))]\n",
    "\n",
    "ueos = []\n",
    "for t in tqdm(uncetainty_thresholds, position=0, leave=True):\n",
    "    t_ueos = []\n",
    "    for j in range(len(ys3d)):\n",
    "        t_ueos.append((sUEO((ind_ent_maps[j] > t).type(torch.float32), ys3d[j])))\n",
    "    ueos.append(torch.Tensor(t_ueos).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c1406c4-6417-4d6d-8058-faf705e144fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(uncetainty_thresholds, ueos)\n",
    "plt.xlabel(\"τ\")\n",
    "plt.ylabel(\"UEO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c87393ff-673c-482e-a8bc-3907b4f73559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(uncetainty_thresholds, ueos)\n",
    "plt.xlabel(\"τ\")\n",
    "plt.ylabel(\"UEO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67baca-107f-4446-beed-247eb472a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw = HyperMapp3rSSN2(ssn_rank=1, ssn_diagonal=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d886f34b-7faf-438f-a8ae-918956fc1d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:18<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:09<00:00,  7.13it/s]\n"
     ]
    }
   ],
   "source": [
    "t = 1.5\n",
    "\n",
    "model = load_model_fr(folders, cs, i, model_raw)\n",
    "samples3d, means3d = gen_samples2(xs3d, ys3d, model, num_samples=34)\n",
    "ind_ent_maps = [entropy_map_from_samples(samples3d[k]/t) for k in range(len(ys3d))]\n",
    "\n",
    "ueos = []\n",
    "for t in tqdm(uncetainty_thresholds, position=0, leave=True):\n",
    "    t_ueos = []\n",
    "    for j in range(len(ys3d)):\n",
    "        t_ueos.append((sUEO((ind_ent_maps[j] > t).type(torch.float32), ys3d[j])))\n",
    "    ueos.append(torch.Tensor(t_ueos).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d2731ee0-02e9-4823-a965-ecc9ce614640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(uncetainty_thresholds, ueos)\n",
    "plt.xlabel(\"τ\")\n",
    "plt.ylabel(\"UEO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2dd31adf-6cb1-4dda-a4f9-f3dfc103c5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(uncetainty_thresholds, ueos)\n",
    "plt.xlabel(\"τ\")\n",
    "plt.ylabel(\"UEO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eb1110bb-a357-4067-b8a1-ee46077c7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = [i[1] for i in ts[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68257936-327b-469f-891b-0432b7465cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1019186973571777,\n",
       " 1.0453717708587646,\n",
       " 1.1179646253585815,\n",
       " 1.2156492471694946,\n",
       " 1.1342394351959229,\n",
       " 1.1440774202346802,\n",
       " 1.0719108581542969,\n",
       " 1.2308355569839478,\n",
       " 1.157137393951416,\n",
       " 1.3379331827163696]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c6f3612-a03d-4e52-af01-1741481b388b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1557)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.Tensor(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045bd1d-44a6-4707-b19a-05530dfe4aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
