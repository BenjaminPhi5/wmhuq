{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66016330-97f9-49f0-8637-099c21ac5cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strawberry\n"
     ]
    }
   ],
   "source": [
    "print(\"strawberry\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# dataset\n",
    "from twaidata.torchdatasets.in_ram_ds import MRISegmentation2DDataset, MRISegmentation3DDataset\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "\n",
    "# model\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_deterministic import HyperMapp3r\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_DDU import HyperMapp3rDDU\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_SSN import HyperMapp3rSSN\n",
    "\n",
    "\n",
    "# augmentation and pretrain processing\n",
    "from trustworthai.utils.augmentation.standard_transforms import RandomFlip, GaussianBlur, GaussianNoise, \\\n",
    "                                                            RandomResizeCrop, RandomAffine, \\\n",
    "                                                            NormalizeImg, PairedCompose, LabelSelect, \\\n",
    "                                                            PairedCentreCrop, CropZDim\n",
    "# loss function\n",
    "from trustworthai.utils.losses_and_metrics.per_individual_losses import (\n",
    "    log_cosh_dice_loss,\n",
    "    TverskyLoss,\n",
    "    FocalTverskyLoss,\n",
    "    DiceLossMetric\n",
    ")\n",
    "from torch.nn import BCELoss, MSELoss, BCEWithLogitsLoss\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import argparse\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchmetrics import Metric\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46522f74-a209-4f46-abc4-7510d9c2fdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f423008e970>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a436e24b-e9e3-4bcf-a1a5-a51b8aa39c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    transforms = [\n",
    "        LabelSelect(label_id=1),\n",
    "        RandomFlip(p=0.5, orientation=\"horizontal\"),\n",
    "        # GaussianBlur(p=0.5, kernel_size=7, sigma=(.1, 1.5)),\n",
    "        # GaussianNoise(p=0.2, mean=0, sigma=0.2),\n",
    "        RandomAffine(p=0.2, shear=(-18,18)),\n",
    "        RandomAffine(p=0.2, degrees=15),\n",
    "        RandomAffine(p=0.2, translate=(-0.1,0.1)),\n",
    "        RandomAffine(p=0.2, scale=(0.9, 1.1)),\n",
    "#         #RandomResizeCrop(p=1., scale=(0.6, 1.), ratio=(3./4., 4./3.))\n",
    "\n",
    "#         #RandomResizeCrop(p=1., scale=(0.3, 0.5), ratio=(3./4., 4./3.)) # ssn\n",
    "            \n",
    "    ]\n",
    "    transforms.append(lambda x, y: (x, y.squeeze().type(torch.long)))\n",
    "    return PairedCompose(transforms)\n",
    "\n",
    "def none_transform():\n",
    "    transforms = [\n",
    "        LabelSelect(label_id=1),\n",
    "        lambda x, y: (x, y.squeeze().type(torch.long))\n",
    "    ]\n",
    "    return PairedCompose(transforms)\n",
    "\n",
    "def train_val_test_split(dataset, val_prop, test_prop, seed):\n",
    "        # I think the sklearn version might be prefereable for determinism and things\n",
    "        # but that involves fiddling with the dataset implementation I think....\n",
    "        size = len(dataset)\n",
    "        test_size = int(test_prop*size) \n",
    "        val_size = int(val_prop*size)\n",
    "        train_size = size - val_size - test_size\n",
    "        train, val, test = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(seed))\n",
    "        return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581552a2-11fb-4fbb-80f4-37e6d043aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from trustworthai.models.uq_models.drop_UNet import normalization_layer\n",
    "import torch.nn.functional as F\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_deterministic import HyperMapp3r\n",
    "import torch.distributions as td\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b480ad28-8e8d-4e4b-9305-d3024aaa1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = None\n",
    "is3D = False\n",
    "root_dir = \"/disk/scratch/s2208943/ipdis/preprep/out_data/collated/\"\n",
    "#root_dir = \"/media/benp/NVMEspare/datasets/preprocessing_attempts/local_results/collated/\"\n",
    "wmh_dir = root_dir + \"WMH_challenge_dataset/\"\n",
    "ed_dir = root_dir + \"EdData/\"\n",
    "\n",
    "domains = [ed_dir + d for d in [\"domainA\", \"domainB\", \"domainC\", \"domainD\"]]\n",
    "# domains = [ wmh_dir + d for d in ['Singapore', 'GE3T', 'Utrecht']]\n",
    "\n",
    "train_proportion = 0.7\n",
    "test_proportion = 0.15\n",
    "validation_proportion = 0.15\n",
    "seed = 3407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a3c6cf-84b5-4f1e-8c35-3f181101dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3d to 2d dataset\n",
    "class MRISegDataset2DFrom3D(Dataset):\n",
    "    def __init__(self, dataset3D, transforms=None):\n",
    "        # calculate total number of slices (note need to iterate through every item\n",
    "        # because each image may have a different number of slices\n",
    "        size = 0\n",
    "        for data in dataset3D:\n",
    "            x = data[0]\n",
    "            size += x.shape[1]\n",
    "            \n",
    "        self.size = size\n",
    "        self.dataset3D = dataset3D\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        idx_to_scan_index = []\n",
    "        scan_starting_index = []\n",
    "        \n",
    "        scan_count = 0\n",
    "        starting_index = 0\n",
    "        for (ind, _) in dataset3D:\n",
    "            d_size = ind.shape[1] # slices are the second dim of 3D scan\n",
    "            idx_to_scan_index.append(torch.ones(d_size) * scan_count)\n",
    "            scan_starting_index.append(starting_index)\n",
    "            \n",
    "            scan_count += 1\n",
    "            starting_index += d_size\n",
    "            \n",
    "        self.idx_to_scan = torch.cat(idx_to_scan_index, dim=0).type(torch.int32)\n",
    "        # print(self.idx_to_scan.shape)\n",
    "        self.scan_starting_index = scan_starting_index\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # find out which scan to use\n",
    "        scan_idx = self.idx_to_scan[idx]\n",
    "        # get that dataset\n",
    "        scan_img, scan_label = self.dataset3D[scan_idx]\n",
    "        # find out where the element is in that dataset\n",
    "        item_idx = idx - self.scan_starting_index[scan_idx]\n",
    "        \n",
    "        #print(scan_img.shape, scan_label.shape)\n",
    "        slice_x = scan_img[:, item_idx]\n",
    "        slice_y = scan_label[:, item_idx] # slices are the second dim of a 3D scan (its channels, z, x, y for 3D scans)\n",
    "        \n",
    "        if self.transforms:\n",
    "            slice_x, slice_y = self.transforms(slice_x, slice_y)\n",
    "        \n",
    "        return slice_x, slice_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb26101-3bae-4801-95db-81127d60a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "### empty slice splitting\n",
    "class FilteredEmptyElementsDataset(Dataset):\n",
    "    def __init__(self, dataset, seed, transforms=None, empty_proportion_retained=0.1):\n",
    "        # print(len(dataset))\n",
    "        self.base_dataset = dataset\n",
    "        self.transforms = transforms\n",
    "        empty_indices = []\n",
    "        self.non_empty_indices = []\n",
    "        count = 0\n",
    "        for i, (x, y) in enumerate(dataset):\n",
    "            if y.sum() == 0:\n",
    "                count += 1\n",
    "                empty_indices.append(i)\n",
    "            else:\n",
    "                self.non_empty_indices.append(i)\n",
    "           \n",
    "        # print(count)\n",
    "        # print(len(self.non_empty_indices))\n",
    "        #print(count * empty_proportion_retained)\n",
    "                \n",
    "        # extract only a limited proportion of empty slices (take a random selection)\n",
    "        shuffled_indices = torch.randperm(count, generator=torch.Generator().manual_seed(seed))\n",
    "        emtpy_indices = torch.Tensor(empty_indices)\n",
    "        self.retained_empty_indices = torch.Tensor(empty_indices)[shuffled_indices[0:int(count * empty_proportion_retained)]]\n",
    "        self.size = len(self.non_empty_indices) + len(self.retained_empty_indices)\n",
    "        self.non_empty_size = len(self.non_empty_indices)\n",
    "        \n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.non_empty_size:\n",
    "            # select an empty slice\n",
    "            new_idx = self.retained_empty_indices[idx - self.non_empty_size]\n",
    "        else:\n",
    "            # select a slice with label in it\n",
    "            new_idx = self.non_empty_indices[idx]\n",
    "        new_idx = int(new_idx)\n",
    "        \n",
    "        img, label = self.base_dataset[new_idx]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img, label = self.transforms(img, label)\n",
    "            \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b604dd-8578-4a41-b2c4-2cd5d3c86f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_domains = [MRISegmentation3DDataset(root_dir, domain, transforms=None) for domain in domains]\n",
    "\n",
    "# split into train, val test datasets\n",
    "datasets_3d = [train_val_test_split(dataset, validation_proportion, test_proportion, seed) for dataset in datasets_domains]\n",
    "\n",
    "# concat the train val test datsets\n",
    "train_dataset_3d = ConcatDataset([ds[0] for ds in datasets_3d])\n",
    "val_dataset_3d = ConcatDataset([ds[1] for ds in datasets_3d])\n",
    "test_dataset_3d = ConcatDataset([ds[2] for ds in datasets_3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b1953d-6c45-4cd9-8530-e9fe1b15e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_2d = [MRISegDataset2DFrom3D(ds, transforms=None) for ds in [train_dataset_3d, val_dataset_3d, test_dataset_3d]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27886bdf-2651-4824-b26e-55bd7bc9f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = [FilteredEmptyElementsDataset(ds, seed=seed, transforms=get_transforms()) for ds in datasets_2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d668d153-7de4-4e02-9e47-bff64f76aeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 160])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab944a5e-c663-4113-ad12-7abbc66df80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 30, shuffle=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d971987-cfae-404b-80bd-7a92a9c076f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_class_prob(p_hat):\n",
    "    p_hat = torch.nn.functional.softmax(p_hat, dim=1)\n",
    "    p_hat = p_hat[:,1,:] # select class 0\n",
    "    return p_hat\n",
    "\n",
    "def individual_dice(p_hat, y_true):\n",
    "    p_hat = two_class_prob(p_hat)\n",
    "    s0 = p_hat.shape[0]\n",
    "    p_hat = p_hat.view(s0,-1)\n",
    "    y_true = y_true.view(s0,-1)\n",
    "    numerator = torch.sum(2. * p_hat * y_true, dim=1) + 1.\n",
    "    denominator = torch.sum(y_true + p_hat, dim=1) + 1.\n",
    "    combined = 1. - (numerator/denominator)\n",
    "    return combined\n",
    "    \n",
    "def dice_loss(p_hat, y_true):\n",
    "    combined = individual_dice(p_hat, y_true)\n",
    "    \n",
    "    # is empties\n",
    "    locs = torch.sum(y_true, dim=(-2, -1)) == 0\n",
    "    wheres = torch.where(locs)[0]\n",
    "    #print(wheres.shape)\n",
    "    # print(wheres)\n",
    "    #print(combined)\n",
    "    r = 0.5\n",
    "    combined[wheres] *= r\n",
    "    #print(combined)\n",
    "    \n",
    "    return torch.sum(combined) / ((y_true.shape[0] - wheres.shape[0]) + (wheres.shape[0] * r))\n",
    "\n",
    "def dice_loss_old(p_hat, y_true):\n",
    "    combined = individual_dice(p_hat, y_true)\n",
    "    return torch.mean(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70620e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from trustworthai.models.uq_models.drop_UNet import normalization_layer\n",
    "import torch.nn.functional as F\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_deterministic import HyperMapp3r\n",
    "import torch.distributions as td\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e45c1f78-65e6-43b4-9403-88d655293f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_func(dims, transpose=False):\n",
    "    # determine convolution func\n",
    "        if dims == 2:\n",
    "            if transpose:\n",
    "                return nn.ConvTranspose2d\n",
    "            else:\n",
    "                return nn.Conv2d\n",
    "        elif dims == 3:\n",
    "            if transpose:\n",
    "                return nn.ConvTranspose3d\n",
    "            else:\n",
    "                return nn.Conv3d\n",
    "        else:\n",
    "            raise ValueError(f\"values of dims of 2 or 3 (2D or 2D conv) are supported only, not {dims}\")\n",
    "            \n",
    "def get_dropout_func(dims):\n",
    "    if dims == 2:\n",
    "        return nn.Dropout2d\n",
    "    if dims == 3:\n",
    "        return nn.Dropout3d\n",
    "    else:\n",
    "        return nn.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abad93bf-b8ac-4a2d-b8f5-7f8a6009617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapedDistribution(td.Distribution):\n",
    "    def __init__(self, base_distribution: td.Distribution, new_event_shape: Tuple[int, ...]):\n",
    "        super().__init__(batch_shape=base_distribution.batch_shape, event_shape=new_event_shape, validate_args=False)\n",
    "        self.base_distribution = base_distribution\n",
    "        self.new_shape = base_distribution.batch_shape + new_event_shape\n",
    "        \n",
    "        #print(\"base distribution: \", self.base_distribution)\n",
    "\n",
    "    @property\n",
    "    def support(self):\n",
    "        return self.base_distribution.support\n",
    "\n",
    "    @property\n",
    "    def arg_constraints(self):\n",
    "        return self.base_distribution.arg_constraints()\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.base_distribution.mean.view(self.new_shape)\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.base_distribution.variance.view(self.new_shape)\n",
    "\n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        return self.base_distribution.rsample(sample_shape).view(sample_shape + self.new_shape)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        return self.base_distribution.log_prob(value.view(self.batch_shape + (-1,)))\n",
    "\n",
    "    def entropy(self):\n",
    "        return self.base_distribution.entropy()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29df04d4-4c0e-4973-bc10-12d18de8c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from torch.distributions.multivariate_normal import _batch_mahalanobis, _batch_mv\n",
    "from torch.distributions.utils import _standard_normal, lazy_property\n",
    "from pyro.distributions.torch_distribution import TorchDistribution\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "from torch.distributions.utils import lazy_property\n",
    "\n",
    "from pyro.distributions.torch import Chi2\n",
    "from pyro.distributions.torch_distribution import TorchDistribution\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "\n",
    "def _batch_capacitance_tril(W, D):\n",
    "    r\"\"\"\n",
    "    Computes Cholesky of :math:`I + W.T @ inv(D) @ W` for a batch of matrices :math:`W`\n",
    "    and a batch of vectors :math:`D`.\n",
    "    \"\"\"\n",
    "    m = W.size(-1)\n",
    "    Wt_Dinv = W.mT / D.unsqueeze(-2)\n",
    "    K = torch.matmul(Wt_Dinv, W).contiguous()\n",
    "    K.view(-1, m * m)[:, ::m + 1] += 1  # add identity matrix to K\n",
    "    return torch.linalg.cholesky(K)\n",
    "\n",
    "\n",
    "def _batch_lowrank_logdet(W, D, capacitance_tril):\n",
    "    r\"\"\"\n",
    "    Uses \"matrix determinant lemma\"::\n",
    "        log|W @ W.T + D| = log|C| + log|D|,\n",
    "    where :math:`C` is the capacitance matrix :math:`I + W.T @ inv(D) @ W`, to compute\n",
    "    the log determinant.\n",
    "    \"\"\"\n",
    "    return 2 * capacitance_tril.diagonal(dim1=-2, dim2=-1).log().sum(-1) + D.log().sum(-1)\n",
    "\n",
    "\n",
    "def _batch_lowrank_mahalanobis(W, D, x, capacitance_tril):\n",
    "    r\"\"\"\n",
    "    Uses \"Woodbury matrix identity\"::\n",
    "        inv(W @ W.T + D) = inv(D) - inv(D) @ W @ inv(C) @ W.T @ inv(D),\n",
    "    where :math:`C` is the capacitance matrix :math:`I + W.T @ inv(D) @ W`, to compute the squared\n",
    "    Mahalanobis distance :math:`x.T @ inv(W @ W.T + D) @ x`.\n",
    "    \"\"\"\n",
    "    Wt_Dinv = W.mT / D.unsqueeze(-2)\n",
    "    Wt_Dinv_x = _batch_mv(Wt_Dinv, x)\n",
    "    mahalanobis_term1 = (x.pow(2) / D).sum(-1)\n",
    "    mahalanobis_term2 = _batch_mahalanobis(capacitance_tril, Wt_Dinv_x)\n",
    "    return mahalanobis_term1 - mahalanobis_term2\n",
    "\n",
    "class LowRankMultivariateStudentT_V3(TorchDistribution):\n",
    "    \"\"\"\n",
    "    Creates a multivariate t distribution with covariance matrix having a low-rank\n",
    "    form parameterized by :attr:`cov_factor` and :attr:`cov_diag`::\n",
    "        covariance_matrix = cov_factor @ cov_factor.T + cov_diag\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    df (Tensor): degrees of freedom of the distribution\n",
    "    loc (Tensor): mean of the distribution with shape `batch_shape + event_shape`\n",
    "    cov_factor (Tensor): factor part of low-rank form of covariance matrix with shape\n",
    "        `batch_shape + event_shape + (rank,)`\n",
    "    cov_diag (Tensor): diagonal part of low-rank form of covariance matrix with shape\n",
    "        `batch_shape + event_shape`\n",
    "\n",
    "    Note:\n",
    "        The computation for determinant and inverse of covariance matrix is avoided when\n",
    "        `cov_factor.shape[1] << cov_factor.shape[0]` thanks to `Woodbury matrix identity\n",
    "        <https://en.wikipedia.org/wiki/Woodbury_matrix_identity>`_ and\n",
    "        `matrix determinant lemma <https://en.wikipedia.org/wiki/Matrix_determinant_lemma>`_.\n",
    "        Thanks to these formulas, we just need to compute the determinant and inverse of\n",
    "        the small size \"capacitance\" matrix::\n",
    "\n",
    "            capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor\n",
    "    \"\"\"\n",
    "    \n",
    "    arg_constraints = {\"df\": constraints.positive,\n",
    "                       \"loc\": constraints.real_vector,\n",
    "                       \"cov_factor\": constraints.independent(constraints.real, 2),\n",
    "                       \"cov_diag\": constraints.independent(constraints.positive, 1)}\n",
    "    \n",
    "    support = constraints.real_vector\n",
    "    has_rsample = True\n",
    "    \n",
    "    def __init__(self, df, loc, cov_factor, cov_diag, validate_args=None):\n",
    "        if loc.dim() < 1:\n",
    "            raise ValueError(\"loc must be at least one-dimensional.\")\n",
    "        event_shape = loc.shape[-1:]\n",
    "        if cov_factor.dim() < 2:\n",
    "            raise ValueError(\"cov_factor must be at least two_dimensional\")\n",
    "        if cov_factor.shape[-2:-1] != event_shape:\n",
    "            raise ValueError(\"cov_factor must be a batch of matrices with shape {} x m\".format(event_shape[0]))\n",
    "        if cov_diag.shape[-1:] != event_shape:\n",
    "            raise ValueError(\"cov_diag must be a batch of vectors with shape {}\".format(event_shape))\n",
    "            \n",
    "        if not isinstance(df, torch.Tensor):\n",
    "            df = loc.new_tensor(df)\n",
    "            \n",
    "        loc_ = loc.unsqueeze(-1)\n",
    "        cov_diag_ = cov_diag.unsqueeze(-1)\n",
    "        try:\n",
    "            loc_, self.cov_factor, cov_diag_ = torch.broadcast_tensors(loc_, cov_factor, cov_diag_)\n",
    "        except RuntimeError as e:\n",
    "            raise ValueError(\"Incompatible batch shapes: loc {}, cov_factor {}, cov_diag {}\"\n",
    "                             .format(loc.shape, cov_factor.shape, cov_diag.shape)) from e\n",
    "        \n",
    "        self.loc = loc_[..., 0]\n",
    "        self.cov_diag = cov_diag_[..., 0]\n",
    "        batch_shape = self.loc.shape[:-1]\n",
    "        self.df = df.expand(batch_shape)\n",
    "\n",
    "        self._unbroadcasted_cov_factor = cov_factor\n",
    "        self._unbroadcasted_cov_diag = cov_diag\n",
    "        self._capacitance_tril = _batch_capacitance_tril(cov_factor, cov_diag)\n",
    "        \n",
    "        self._chi2 = Chi2(self.df)\n",
    "        \n",
    "        super().__init__(batch_shape, event_shape, validate_args=validate_args)\n",
    "        \n",
    "    def expand(self, batch_shape, _instance=None):\n",
    "        new = self._get_checked_instance(LowRankMultivariateNormal, _instance)\n",
    "        batch_shape = torch.Size(batch_shape)\n",
    "        loc_shape = batch_shape + self.event_shape\n",
    "        new.df = self.df = df.expand(loc_shape)\n",
    "        new.loc = self.loc.expand(loc_shape)\n",
    "        new._chi2 = self._chi2.expand(loc_shape)\n",
    "        new.cov_diag = self.cov_diag.expand(loc_shape)\n",
    "        new.cov_factor = self.cov_factor.expand(loc_shape + self.cov_factor.shape[-1:])\n",
    "        new._unbroadcasted_cov_factor = self._unbroadcasted_cov_factor\n",
    "        new._unbroadcasted_cov_diag = self._unbroadcasted_cov_diag\n",
    "        new._capacitance_tril = self._capacitance_tril\n",
    "        super(LowRankMultivariateStudentT_V2, new).__init__(batch_shape,\n",
    "                                                       self.event_shape,\n",
    "                                                       validate_args=False)\n",
    "        new._validate_args = self._validate_args\n",
    "        return new\n",
    "    \n",
    "    @lazy_property\n",
    "    def scale_tril(self):\n",
    "        # The following identity is used to increase the numerically computation stability\n",
    "        # for Cholesky decomposition (see http://www.gaussianprocess.org/gpml/, Section 3.4.3):\n",
    "        #     W @ W.T + D = D1/2 @ (I + D-1/2 @ W @ W.T @ D-1/2) @ D1/2\n",
    "        # The matrix \"I + D-1/2 @ W @ W.T @ D-1/2\" has eigenvalues bounded from below by 1,\n",
    "        # hence it is well-conditioned and safe to take Cholesky decomposition.\n",
    "        n = self._event_shape[0]\n",
    "        cov_diag_sqrt_unsqueeze = self._unbroadcasted_cov_diag.sqrt().unsqueeze(-1)\n",
    "        Dinvsqrt_W = self._unbroadcasted_cov_factor / cov_diag_sqrt_unsqueeze\n",
    "        K = torch.matmul(Dinvsqrt_W, Dinvsqrt_W.mT).contiguous()\n",
    "        K.view(-1, n * n)[:, ::n + 1] += 1  # add identity matrix to K\n",
    "        scale_tril = cov_diag_sqrt_unsqueeze * torch.linalg.cholesky(K)\n",
    "        return scale_tril.expand(self._batch_shape + self._event_shape + self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def covariance_matrix(self):\n",
    "        # NB: this is not covariance of this distribution;\n",
    "        # the actual covariance is df / (df - 2) * covariance_matrix\n",
    "        covariance_matrix = (torch.matmul(self._unbroadcasted_cov_factor,\n",
    "                                          self._unbroadcasted_cov_factor.mT)\n",
    "                             + torch.diag_embed(self._unbroadcasted_cov_diag))\n",
    "        return covariance_matrix.expand(self._batch_shape + self._event_shape +\n",
    "                                        self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def precision_matrix(self):\n",
    "        # We use \"Woodbury matrix identity\" to take advantage of low rank form::\n",
    "        #     inv(W @ W.T + D) = inv(D) - inv(D) @ W @ inv(C) @ W.T @ inv(D)\n",
    "        # where :math:`C` is the capacitance matrix.\n",
    "        Wt_Dinv = (self._unbroadcasted_cov_factor.mT\n",
    "                   / self._unbroadcasted_cov_diag.unsqueeze(-2))\n",
    "        A = torch.linalg.solve_triangular(self._capacitance_tril, Wt_Dinv, upper=False)\n",
    "        precision_matrix = torch.diag_embed(self._unbroadcasted_cov_diag.reciprocal()) - A.mT @ A\n",
    "        return precision_matrix.expand(self._batch_shape + self._event_shape +\n",
    "                                       self._event_shape)\n",
    "    \n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        shape = self._extended_shape(sample_shape)\n",
    "        #X = torch.empty(shape, dtype=self.df.dtype, device=self.df.device).normal_()\n",
    "        Z = self._chi2.rsample(sample_shape)\n",
    "        #Y = X * torch.rsqrt(Z / self.df).unsqueeze(-1)\n",
    "        #return self.loc + self.scale_tril.matmul(Y.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        W_shape = shape[:-1] + self.cov_factor.shape[-1:]\n",
    "        eps_W = _standard_normal(W_shape, dtype=self.loc.dtype, device=self.loc.device)\n",
    "        eps_D = _standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)\n",
    "        \n",
    "        frac = torch.rsqrt(Z / self.df).unsqueeze(-1)\n",
    "        Yeps_W = eps_W * frac\n",
    "        Yeps_D = eps_D * frac\n",
    "        return (self.loc + _batch_mv(self._unbroadcasted_cov_factor, Yeps_W)\n",
    "                + self._unbroadcasted_cov_diag.sqrt() * Yeps_D)\n",
    "        \n",
    "\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        n = self.loc.size(-1)\n",
    "        diff = (value - self.loc)\n",
    "        y = _batch_lowrank_mahalanobis(self._unbroadcasted_cov_factor,\n",
    "                                       self._unbroadcasted_cov_diag,\n",
    "                                       diff,\n",
    "                                       self._capacitance_tril)\n",
    "        \n",
    "        log_det = _batch_lowrank_logdet(self._unbroadcasted_cov_factor,\n",
    "                                        self._unbroadcasted_cov_diag,\n",
    "                                        self._capacitance_tril)\n",
    "        Z = (\n",
    "            log_det * 0.5\n",
    "            + 0.5 * n * self.df.log()\n",
    "            + 0.5 * n * math.log(math.pi)\n",
    "            + torch.lgamma(0.5 * self.df)\n",
    "            - torch.lgamma(0.5 * (self.df + n))\n",
    "        )\n",
    "        return -0.5 * (self.df + n) * torch.log1p(y / self.df) - Z\n",
    "\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        m = self.loc.clone()\n",
    "        m[self.df <= 1, :] = float(\"nan\")\n",
    "        return m\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        m = self.scale_tril.pow(2).sum(-1) * (self.df / (self.df - 2)).unsqueeze(-1)\n",
    "        m[(self.df <= 2) & (self.df > 1), :] = float(\"inf\")\n",
    "        m[self.df <= 1, :] = float(\"nan\")\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13875f43-101c-4d6d-9254-47cb7a5c1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as transforms\n",
    "\n",
    "class HmResBlock(nn.Module):\n",
    "    def __init__(self, channels, p):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=7, stride=1, dilation=2, padding='same')\n",
    "        self.dropout1 = nn.Dropout2d(p)\n",
    "        self.norm1 = nn.InstanceNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, dilation=2, padding='same')\n",
    "        self.norm2 = nn.InstanceNorm2d(channels)\n",
    "        self.activ = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.activ(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.activ(out)\n",
    "        \n",
    "        out = out + identity\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, ins, outs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ins, outs, kernel_size=3, stride=2, dilation=1, padding=1)\n",
    "        self.norm = nn.InstanceNorm2d(outs)\n",
    "        self.activ = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.activ(self.norm(self.conv(x)))\n",
    "\n",
    "class HmUpsampBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(channels*2, channels, kernel_size=3, stride=1, dilation=1, padding='same')\n",
    "        self.norm = nn.InstanceNorm2d(channels)\n",
    "        self.activ = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        return self.activ(self.norm(self.conv(out)))\n",
    "        \n",
    "\n",
    "class HmFeatureBlock(nn.Module):\n",
    "    def __init__(self, ins):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(ins, ins//2, kernel_size=3, stride=1, dilation=2, padding='same')\n",
    "        self.activ = nn.ReLU()\n",
    "        self.norm1 = nn.InstanceNorm2d(ins)\n",
    "        self.conv2 = nn.Conv2d(ins//2, ins//2, kernel_size=1, stride=1, dilation=1)\n",
    "        self.norm2 = nn.InstanceNorm2d(ins)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.activ(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.activ(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class HyperMapREDO(nn.Module):\n",
    "    def __init__(self,dropout_p = 0., encoder_sizes=[16,32,64,128,256], inchannels=3, outchannels=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        # input layer\n",
    "        self.conv_first = nn.Conv2d(inchannels, encoder_sizes[0], kernel_size=5, stride=1, dilation=1, padding='same')\n",
    "        self.activ = nn.ReLU()\n",
    "        \n",
    "        # encoder section\n",
    "        l = len(encoder_sizes) - 1\n",
    "        self.down_blocks = nn.ModuleList([\n",
    "            DownBlock(encoder_sizes[i], encoder_sizes[i+1]) for i in range(0, l)\n",
    "        ])\n",
    "        \n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            HmResBlock(c, dropout_p) for c in encoder_sizes\n",
    "        ])\n",
    "        \n",
    "        # decoder section\n",
    "        self.upsample_blocks = nn.ModuleList([\n",
    "            HmUpsampBlock(c) for c in encoder_sizes[:-1][::-1]\n",
    "        ])\n",
    "        \n",
    "        self.feature_blocks = nn.ModuleList([\n",
    "            HmFeatureBlock(encoder_sizes[l - i]) for i in range(l-1)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        # multi-scale feature section\n",
    "        self.ms_feature_layers = nn.ModuleList([\n",
    "            nn.Conv2d(encoder_sizes[2], encoder_sizes[1], 3, padding='same'),\n",
    "            nn.Conv2d(encoder_sizes[1], encoder_sizes[1], 3, padding='same'),\n",
    "            nn.Conv2d(encoder_sizes[1], encoder_sizes[1], 3, padding='same')\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        # output layer\n",
    "        self.last_1 = nn.Conv2d(encoder_sizes[1], encoder_sizes[1], 3, padding='same')\n",
    "        self.last_2 = nn.Conv2d(encoder_sizes[1]*3, encoder_sizes[1], 1)\n",
    "        self.last_3 = nn.Conv2d(encoder_sizes[1], outchannels, 1)\n",
    "        self.last_norm = nn.InstanceNorm2d(encoder_sizes[1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input layer\n",
    "        out = self.activ(self.conv_first(x))\n",
    "        # print(out.shape)\n",
    "        \n",
    "        skips = []\n",
    "        \n",
    "        # encoder section\n",
    "        out = self.res_blocks[0](out)\n",
    "        # print(out.shape)\n",
    "        skips.append(out)\n",
    "        for i in range(len(self.res_blocks) - 1):\n",
    "            out = self.down_blocks[i](out)\n",
    "            out = self.res_blocks[i+1](out)\n",
    "            # print(\"loop: \", out.shape)\n",
    "            skips.append(out)\n",
    "        \n",
    "        # decoder section\n",
    "        ml_features = []\n",
    "        out = skips.pop()\n",
    "        for i in range(len(self.upsample_blocks)):\n",
    "            # print(\"dec\")\n",
    "            if i > 0:\n",
    "                sk = skips.pop()\n",
    "                sk = transforms.center_crop(sk, out.shape[-2:])\n",
    "                out = torch.cat([out, sk], dim=1)\n",
    "                out = self.feature_blocks[i-1](out)\n",
    "            \n",
    "            if i > 1:\n",
    "                ml_features.append(self.ms_feature_layers[i-2](out))\n",
    "                \n",
    "            out = self.upsample_blocks[i](out)\n",
    "        \n",
    "        # final layers\n",
    "        sk = skips.pop()\n",
    "        sk = transforms.center_crop(sk, out.shape[-2:])\n",
    "        out = torch.cat([out, sk], dim=1)\n",
    "        out = self.last_norm(self.activ(self.last_1(out)))\n",
    "        \n",
    "        # multiscale feature section\n",
    "        ml_features = [out] + ml_features\n",
    "        ml_features = [F.interpolate(mf, size=x.shape[-2:], mode='bilinear') for mf in ml_features]\n",
    "        combined_features = torch.cat(ml_features, dim=1)\n",
    "        \n",
    "        out = self.activ(self.last_2(combined_features))\n",
    "        out = self.last_3(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cb08829-1f8b-4bad-a376-6982fa471bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowRankMultivariateNormalCustom(td.Distribution):\n",
    "    r\"\"\"\n",
    "    Creates a multivariate normal distribution with covariance matrix having a low-rank form\n",
    "    parameterized by :attr:`cov_factor` and :attr:`cov_diag`::\n",
    "\n",
    "        covariance_matrix = cov_factor @ cov_factor.T + cov_diag\n",
    "\n",
    "    Example:\n",
    "        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LAPACK)\n",
    "        >>> # xdoctest: +IGNORE_WANT(\"non-determenistic\")\n",
    "        >>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([[1.], [0.]]), torch.ones(2))\n",
    "        >>> m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[[1],[0]]`, cov_diag=`[1,1]`\n",
    "        tensor([-0.2102, -0.5429])\n",
    "\n",
    "    Args:\n",
    "        loc (Tensor): mean of the distribution with shape `batch_shape + event_shape`\n",
    "        cov_factor (Tensor): factor part of low-rank form of covariance matrix with shape\n",
    "            `batch_shape + event_shape + (rank,)`\n",
    "        cov_diag (Tensor): diagonal part of low-rank form of covariance matrix with shape\n",
    "            `batch_shape + event_shape`\n",
    "\n",
    "    Note:\n",
    "        The computation for determinant and inverse of covariance matrix is avoided when\n",
    "        `cov_factor.shape[1] << cov_factor.shape[0]` thanks to `Woodbury matrix identity\n",
    "        <https://en.wikipedia.org/wiki/Woodbury_matrix_identity>`_ and\n",
    "        `matrix determinant lemma <https://en.wikipedia.org/wiki/Matrix_determinant_lemma>`_.\n",
    "        Thanks to these formulas, we just need to compute the determinant and inverse of\n",
    "        the small size \"capacitance\" matrix::\n",
    "\n",
    "            capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor\n",
    "    \"\"\"\n",
    "    arg_constraints = {\"loc\": constraints.real_vector,\n",
    "                       \"cov_factor\": constraints.independent(constraints.real, 2),\n",
    "                       \"cov_diag\": constraints.independent(constraints.positive, 1)}\n",
    "    support = constraints.real_vector\n",
    "    has_rsample = True\n",
    "\n",
    "    def __init__(self, loc, cov_factor, cov_diag, validate_args=None):\n",
    "        if loc.dim() < 1:\n",
    "            raise ValueError(\"loc must be at least one-dimensional.\")\n",
    "        event_shape = loc.shape[-1:]\n",
    "        if cov_factor.dim() < 2:\n",
    "            raise ValueError(\"cov_factor must be at least two-dimensional, \"\n",
    "                             \"with optional leading batch dimensions\")\n",
    "        if cov_factor.shape[-2:-1] != event_shape:\n",
    "            raise ValueError(\"cov_factor must be a batch of matrices with shape {} x m\"\n",
    "                             .format(event_shape[0]))\n",
    "        if cov_diag.shape[-1:] != event_shape:\n",
    "            raise ValueError(\"cov_diag must be a batch of vectors with shape {}\".format(event_shape))\n",
    "\n",
    "        loc_ = loc.unsqueeze(-1)\n",
    "        cov_diag_ = cov_diag.unsqueeze(-1)\n",
    "        try:\n",
    "            loc_, self.cov_factor, cov_diag_ = torch.broadcast_tensors(loc_, cov_factor, cov_diag_)\n",
    "        except RuntimeError as e:\n",
    "            raise ValueError(\"Incompatible batch shapes: loc {}, cov_factor {}, cov_diag {}\"\n",
    "                             .format(loc.shape, cov_factor.shape, cov_diag.shape)) from e\n",
    "        self.loc = loc_[..., 0]\n",
    "        self.cov_diag = cov_diag_[..., 0]\n",
    "        batch_shape = self.loc.shape[:-1]\n",
    "\n",
    "        self._unbroadcasted_cov_factor = cov_factor\n",
    "        self._unbroadcasted_cov_diag = cov_diag\n",
    "        #self._capacitance_tril = _batch_capacitance_tril(cov_factor, cov_diag)\n",
    "        super().__init__(batch_shape, event_shape,\n",
    "                                                        validate_args=validate_args)\n",
    "\n",
    "    def expand(self, batch_shape, _instance=None):\n",
    "        new = self._get_checked_instance(LowRankMultivariateNormal, _instance)\n",
    "        batch_shape = torch.Size(batch_shape)\n",
    "        loc_shape = batch_shape + self.event_shape\n",
    "        new.loc = self.loc.expand(loc_shape)\n",
    "        new.cov_diag = self.cov_diag.expand(loc_shape)\n",
    "        new.cov_factor = self.cov_factor.expand(loc_shape + self.cov_factor.shape[-1:])\n",
    "        new._unbroadcasted_cov_factor = self._unbroadcasted_cov_factor\n",
    "        new._unbroadcasted_cov_diag = self._unbroadcasted_cov_diag\n",
    "        new._capacitance_tril = self._capacitance_tril\n",
    "        super(LowRankMultivariateNormal, new).__init__(batch_shape,\n",
    "                                                       self.event_shape,\n",
    "                                                       validate_args=False)\n",
    "        new._validate_args = self._validate_args\n",
    "        return new\n",
    "\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.loc\n",
    "\n",
    "    @property\n",
    "    def mode(self):\n",
    "        return self.loc\n",
    "\n",
    "    @lazy_property\n",
    "    def variance(self):\n",
    "        return (self._unbroadcasted_cov_factor.pow(2).sum(-1)\n",
    "                + self._unbroadcasted_cov_diag).expand(self._batch_shape + self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def scale_tril(self):\n",
    "        # The following identity is used to increase the numerically computation stability\n",
    "        # for Cholesky decomposition (see http://www.gaussianprocess.org/gpml/, Section 3.4.3):\n",
    "        #     W @ W.T + D = D1/2 @ (I + D-1/2 @ W @ W.T @ D-1/2) @ D1/2\n",
    "        # The matrix \"I + D-1/2 @ W @ W.T @ D-1/2\" has eigenvalues bounded from below by 1,\n",
    "        # hence it is well-conditioned and safe to take Cholesky decomposition.\n",
    "        n = self._event_shape[0]\n",
    "        cov_diag_sqrt_unsqueeze = self._unbroadcasted_cov_diag.sqrt().unsqueeze(-1)\n",
    "        Dinvsqrt_W = self._unbroadcasted_cov_factor / cov_diag_sqrt_unsqueeze\n",
    "        K = torch.matmul(Dinvsqrt_W, Dinvsqrt_W.mT).contiguous()\n",
    "        K.view(-1, n * n)[:, ::n + 1] += 1  # add identity matrix to K\n",
    "        scale_tril = cov_diag_sqrt_unsqueeze * torch.linalg.cholesky(K)\n",
    "        return scale_tril.expand(self._batch_shape + self._event_shape + self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def covariance_matrix(self):\n",
    "        covariance_matrix = (torch.matmul(self._unbroadcasted_cov_factor,\n",
    "                                          self._unbroadcasted_cov_factor.mT)\n",
    "                             + torch.diag_embed(self._unbroadcasted_cov_diag))\n",
    "        return covariance_matrix.expand(self._batch_shape + self._event_shape +\n",
    "                                        self._event_shape)\n",
    "\n",
    "    @lazy_property\n",
    "    def precision_matrix(self):\n",
    "        # We use \"Woodbury matrix identity\" to take advantage of low rank form::\n",
    "        #     inv(W @ W.T + D) = inv(D) - inv(D) @ W @ inv(C) @ W.T @ inv(D)\n",
    "        # where :math:`C` is the capacitance matrix.\n",
    "        Wt_Dinv = (self._unbroadcasted_cov_factor.mT\n",
    "                   / self._unbroadcasted_cov_diag.unsqueeze(-2))\n",
    "        A = torch.linalg.solve_triangular(self._capacitance_tril, Wt_Dinv, upper=False)\n",
    "        precision_matrix = torch.diag_embed(self._unbroadcasted_cov_diag.reciprocal()) - A.mT @ A\n",
    "        return precision_matrix.expand(self._batch_shape + self._event_shape +\n",
    "                                       self._event_shape)\n",
    "\n",
    "    def rsample(self, sample_shape=torch.Size()):\n",
    "        shape = self._extended_shape(sample_shape)\n",
    "        W_shape = shape[:-1] + self.cov_factor.shape[-1:]\n",
    "        eps_W = _standard_normal(W_shape, dtype=self.loc.dtype, device=self.loc.device)\n",
    "        eps_D = _standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)\n",
    "        return (self.loc + _batch_mv(self._unbroadcasted_cov_factor, eps_W)\n",
    "                + self._unbroadcasted_cov_diag.sqrt() * eps_D)\n",
    "\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        diff = value - self.loc\n",
    "        M = _batch_lowrank_mahalanobis(self._unbroadcasted_cov_factor,\n",
    "                                       self._unbroadcasted_cov_diag,\n",
    "                                       diff,\n",
    "                                       self._capacitance_tril)\n",
    "        log_det = _batch_lowrank_logdet(self._unbroadcasted_cov_factor,\n",
    "                                        self._unbroadcasted_cov_diag,\n",
    "                                        self._capacitance_tril)\n",
    "        return -0.5 * (self._event_shape[0] * math.log(2 * math.pi) + log_det + M)\n",
    "\n",
    "\n",
    "    def entropy(self):\n",
    "        log_det = _batch_lowrank_logdet(self._unbroadcasted_cov_factor,\n",
    "                                        self._unbroadcasted_cov_diag,\n",
    "                                        self._capacitance_tril)\n",
    "        H = 0.5 * (self._event_shape[0] * (1.0 + math.log(2 * math.pi)) + log_det)\n",
    "        if len(self._batch_shape) == 0:\n",
    "            return H\n",
    "        else:\n",
    "            return H.expand(self._batch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9c067ec-471a-49c0-8735-0b1650414882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperMapp3rSSN2(HyperMapREDO):\n",
    "    def __init__(self,\n",
    "                 dropout_p = 0., encoder_sizes=[16,32,64,128,256], inchannels=3, out_channels=2,\n",
    "                 ssn_rank = 10,\n",
    "                 ssn_epsilon=1e-5,\n",
    "                 ssn_diagonal=False,\n",
    "                 dims=2\n",
    "                ):\n",
    "        super().__init__(dropout_p, encoder_sizes, inchannels, outchannels=encoder_sizes[0]) # last layer of just keeps number of nodes fixed this time)\n",
    "        \n",
    "        print(\"WARNING: this model assumes that the input to the model contains the brain mask in the first channel!\")\n",
    "        conv_func = get_conv_func(dims, transpose=False)\n",
    "        self.ssn_rank = ssn_rank\n",
    "        self.ssn_diagonal = ssn_diagonal\n",
    "        self.ssn_epsilon = ssn_epsilon\n",
    "        self.ssn_num_classes = out_channels\n",
    "        \n",
    "        self.lrelu = nn.LeakyReLU(0.01)\n",
    "        \n",
    "        self.mean_l = conv_func(encoder_sizes[0], out_channels, kernel_size = (1,) *  dims, padding='same')\n",
    "        self.log_cov_diag_l = conv_func(encoder_sizes[0], out_channels, kernel_size = (1,) * dims, padding='same')\n",
    "        self.cov_factor_l = conv_func(encoder_sizes[0], out_channels * ssn_rank, kernel_size = (1,) * dims, padding='same')\n",
    "        #self.vk_l = conv_func(encoder_sizes[0], 2, kernel_size=7, padding='same')\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.lrelu(super().forward(x))\n",
    "\n",
    "        if torch.sum(torch.isnan(logits)) > 0:\n",
    "            print(\"NAN 1\", torch.sum(torch.isnan(logits)))\n",
    "        batch_size = logits.shape[0]\n",
    "        event_shape = (self.ssn_num_classes,) + logits.shape[2:]\n",
    "        \n",
    "        mean = self.mean_l(logits)\n",
    "        mean = mean.view((batch_size, -1))\n",
    "        \n",
    "        cov_diag = self.log_cov_diag_l(logits).exp() + self.ssn_epsilon\n",
    "        cov_diag = cov_diag.view((batch_size, -1))\n",
    "        \n",
    "        cov_factor = self.cov_factor_l(logits)\n",
    "        cov_factor = cov_factor.view((batch_size, self.ssn_rank, self.ssn_num_classes, -1))\n",
    "        cov_factor = cov_factor.flatten(2,3)\n",
    "        cov_factor = cov_factor.transpose(1,2)\n",
    "        if torch.sum(torch.isnan(mean)) > 0:\n",
    "            print(\"NAN 2\")\n",
    "        if torch.sum(torch.isnan(cov_diag)) > 0:\n",
    "            print(\"NAN 3\")\n",
    "        if torch.sum(torch.isnan(cov_factor)) > 0:\n",
    "            print(\"NAN 4\")\n",
    "            \n",
    "            \n",
    "        #vk = self.vk_l(logits).exp()\n",
    "        # print(vk.shape)\n",
    "        #vk = vk.mean(dim=(-1, -2)) # mean along each axis except for channel, yielding two values\n",
    "        #D = mean.shape[1]\n",
    "        #v = vk[:,0]\n",
    "        #k = vk[:,1]\n",
    "        #evidence_scale = (k+1) / (k*v)\n",
    "        \n",
    "        # print(\"vk shapes\")\n",
    "        # print(v.shape)\n",
    "        # print(k.shape)\n",
    "        # print(v, k, evidence_scale)\n",
    "        \n",
    "        # covariance tends to blow up to infinity, hence set to 0 outside the ROI\n",
    "        mask = x[:,1]\n",
    "        mask = mask.unsqueeze(1).expand((batch_size, self.ssn_num_classes) + mask.shape[1:]).reshape(batch_size, -1)\n",
    "        cov_factor = cov_factor * mask.unsqueeze(-1)\n",
    "        cov_diag = cov_diag * mask + self.ssn_epsilon\n",
    "        \n",
    "        if torch.sum(torch.isnan(cov_diag)) > 0:\n",
    "            print(\"NAN 3\")\n",
    "        if torch.sum(torch.isnan(cov_factor)) > 0:\n",
    "            print(\"NAN 4\")\n",
    "        \n",
    "        # print(evidence_scale.shape, (evidence_scale**0.5).shape)\n",
    "        # print(cov_diag.shape, cov_factor.shape)\n",
    "#         cov_diag *= evidence_scale.unsqueeze(-1)\n",
    "#         cov_factor *= (evidence_scale**0.5).unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        if torch.sum(torch.isnan(mask)) > 0:\n",
    "            print(\"NAN 5\")\n",
    "        if torch.sum(torch.isnan(cov_factor)) > 0:\n",
    "            print(\"NAN 6\")\n",
    "        if torch.sum(torch.isnan(cov_diag)) > 0:\n",
    "            print(\"NAN 7\")\n",
    "            \n",
    "        # print(cov_diag)\n",
    "        \n",
    "        if self.ssn_diagonal:\n",
    "            base_distribution = td.Independent(td.Normal(loc=mean, scale=torch.sqrt(cov_diag)), 1)\n",
    "        else:\n",
    "            try:\n",
    "                base_distribution = LowRankMultivariateNormalCustom(loc=mean, cov_factor=cov_factor, cov_diag=cov_diag)\n",
    "                #base_distribution = LowRankMultivariateStudentT_V3(df=v, loc=mean, cov_factor=cov_factor, cov_diag=cov_diag)\n",
    "                #print(\"using multivariate normal!\")\n",
    "            except Exception as e:\n",
    "                print(\"was thrown: \", e)\n",
    "                print('hmm: Covariance became non invertible using independent normals for this batch!')\n",
    "                print(\"cov diag okay: \", torch.sum(cov_diag <=0))\n",
    "                print(\"sqrt cov diag okay: \", torch.sum(torch.sqrt(cov_diag) <=0))\n",
    "                \n",
    "                try:\n",
    "                    base_distribution = td.Independent(td.Normal(loc=mean, scale=torch.sqrt(cov_diag)),1)\n",
    "                except Exception as e:\n",
    "                    print(\"second fail: \", e)\n",
    "                    print(torch.min(torch.sqrt(cov_diag), torch.max(torch.sqrt(cov_diag))))\n",
    "        \n",
    "        distribution = ReshapedDistribution(base_distribution, event_shape)\n",
    "        \n",
    "        shape = (batch_size,) + event_shape\n",
    "        logit_mean_view = mean.view(shape).detach()\n",
    "        cov_diag_view = cov_diag.view(shape).detach()\n",
    "        cov_factor_view = cov_factor.transpose(2,1).view((batch_size, self.ssn_num_classes * self.ssn_rank) + event_shape[1:]).detach()\n",
    "        \n",
    "        # compute the diagonal of the precision matrix for the evidence regularizer\n",
    "#         U = cov_factor\n",
    "#         D_inv = 1./cov_diag\n",
    "#         # print(\"shapes for regularizer\")\n",
    "#         # print(\"U, U.mt\", U.shape, U.mT.shape)\n",
    "#         # print(\"D\", D_inv.shape)\n",
    "        \n",
    "#         D_inv_mult = D_inv.unsqueeze(-1).expand(U.shape)\n",
    "#         # print(\"D inv mult\", D_inv_mult.shape)\n",
    "        \n",
    "#         F = torch.eye(self.ssn_rank).to(U.device) + U.mT.bmm(D_inv_mult * U)\n",
    "#         # print(\"F\", F.shape)\n",
    "        \n",
    "#         RRT = torch.cholesky_inverse(F)\n",
    "#         R = torch.cholesky(RRT)\n",
    "        \n",
    "#         # print(\"R\", R.shape)\n",
    "#         V = (D_inv_mult * U).bmm(R)\n",
    "#         # print(\"V\", V.shape)\n",
    "        \n",
    "#         # print(\"diag v\", torch.diagonal(V, dim1=1, dim2=2).shape, V.shape)\n",
    "        \n",
    "#         pres_diag = D_inv - torch.sum(V * V, dim=2) # get the diagonal of the V@V.T matrix without computing it\n",
    "             \n",
    "        \n",
    "        output_dict = {\n",
    "            # 'v':v,\n",
    "            # 'k':k,\n",
    "            'logit_mean':logit_mean_view,\n",
    "            'cov_diag':cov_diag_view,\n",
    "            'cov_factor':cov_factor_view,\n",
    "            'distribution':distribution,\n",
    "            # 'pres_diag':pres_diag,\n",
    "        }\n",
    "        \n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65e68de3-0454-44aa-893a-255cd3a1e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_raw = HyperMapp3rSSN2().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47444f31-f60a-406a-b98c-1f20b10fc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = StandardLitModelWrapper.load_from_checkpoint('/disk/scratch_big/s2208943/results/new_tests/epoch=15-step=2192.ckpt', model=model_raw, loss=loss, \n",
    "#                                 logging_metric=SsnDiceMetricWrapper,\n",
    "#                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a81ef93-d78b-4638-8b61-d82baa47e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_re_parametrization_trick(dist, num_samples):\n",
    "    assert num_samples % 2 == 0\n",
    "    samples = dist.rsample((num_samples // 2,))\n",
    "    mean = dist.mean.unsqueeze(0)\n",
    "    samples = samples - mean\n",
    "    return torch.cat([samples, -samples]) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "287a10f1-6cd1-4d91-bab6-2b22cce8ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist = model_raw(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0314ceed-3a03-4b2f-8b02-f23a686bef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l = loss(dist, y.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "464a2317-bad0-4f61-bf59-6de11b9fcfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss(dist, y.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42c9dc6b-382b-4a81-bc8e-71202a273ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction_loss(dist, target):\n",
    "    y = target\n",
    "    m = dist['logit_mean']\n",
    "    v = torch.nn.functional.softmax(m, dim=1)\n",
    "    \n",
    "    shape = [*y.unsqueeze(1).shape]\n",
    "    shape[1] = 2 # 2 classes\n",
    "    bs = shape[0]\n",
    "    \n",
    "    a = torch.zeros(shape)\n",
    "    \n",
    "    a[:,1] = y\n",
    "    a[:,0] = 1-y\n",
    "    pair_y = a.to(v.device)\n",
    "    \n",
    "    diff = (v.view(bs, -1) - pair_y.reshape(bs, -1)).abs().view(bs, -1) * 0.5\n",
    "    \n",
    "    correction = dist['v'].view(-1, 1).expand(diff.shape) + dist['k'].view(-1, 1).expand(diff.shape) * dist['pres_diag']\n",
    "    \n",
    "    closs = (correction * diff).mean()\n",
    "    \n",
    "    closs = closs.clip(0,1000)\n",
    "    \n",
    "    return closs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c2d279d-1657-4697-b570-64f88a189c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticSegmentationNetworkLossMCIntegral(nn.Module):\n",
    "    def __init__(self, num_mc_samples: int = 1):\n",
    "        super().__init__()\n",
    "        self.num_mc_samples = num_mc_samples\n",
    "\n",
    "    @staticmethod\n",
    "    def fixed_re_parametrization_trick(dist, num_samples):\n",
    "        assert num_samples % 2 == 0\n",
    "        samples = dist.rsample((num_samples // 2,))\n",
    "        mean = dist.mean.unsqueeze(0)\n",
    "        samples = samples - mean\n",
    "        return torch.cat([samples, -samples]) + mean\n",
    "\n",
    "    def forward(self, result_dict, target, **kwargs):\n",
    "        logits = result_dict['logit_mean']\n",
    "        distribution = result_dict['distribution']\n",
    "        \n",
    "        batch_size = logits.shape[0]\n",
    "        num_classes = logits.shape[1]\n",
    "        assert num_classes >= 2  # not implemented for binary case with implied background\n",
    "        # logit_sample = distribution.rsample((self.num_mc_samples,))\n",
    "        logit_sample = self.fixed_re_parametrization_trick(distribution, self.num_mc_samples)\n",
    "        target = target.unsqueeze(1)\n",
    "        target = target.expand((self.num_mc_samples,) + target.shape)\n",
    "\n",
    "        flat_size = self.num_mc_samples * batch_size\n",
    "        logit_sample = logit_sample.view((flat_size, num_classes, -1))\n",
    "        target = target.reshape((flat_size, -1))\n",
    "\n",
    "        log_prob = -F.cross_entropy(logit_sample, target, reduction='none').view((self.num_mc_samples, batch_size, -1))\n",
    "        loglikelihood = torch.mean(torch.logsumexp(torch.sum(log_prob, dim=-1), dim=0) - math.log(self.num_mc_samples))\n",
    "        loss = -loglikelihood\n",
    "        return loss\n",
    "    \n",
    "def fixed_re_parametrization_trick(dist, num_samples):\n",
    "        assert num_samples % 2 == 0\n",
    "        samples = dist.rsample((num_samples // 2,))\n",
    "        mean = dist.mean.unsqueeze(0)\n",
    "        samples = samples - mean\n",
    "        return torch.cat([samples, -samples]) + mean\n",
    "\n",
    "\n",
    "class SsnNetworkMeanLossWrapper(nn.Module):\n",
    "    def __init__(self, loss_func):\n",
    "        super().__init__()\n",
    "        self.loss = loss_func\n",
    "    def forward(self, result_dict, target):\n",
    "        mean = result_dict['logit_mean']\n",
    "        return self.loss(mean, target)\n",
    "    \n",
    "class SsnNetworkSampleLossWrapper(nn.Module):\n",
    "    def __init__(self, loss_func, samples=10):\n",
    "        super().__init__()\n",
    "        self.loss = loss_func\n",
    "        self.samples = samples\n",
    "    def forward(self, result_dict, target):\n",
    "        samples = fixed_re_parametrization_trick(result_dict['distribution'], self.samples).to(target.device)\n",
    "        loss = 0\n",
    "        for s in samples:\n",
    "            loss += self.loss(s, target)\n",
    "        return loss / self.samples\n",
    "    \n",
    "def avd(logits, target):\n",
    "    preds = torch.nn.functional.softmax(logits, dim=1)[:,1]\n",
    "    bs = preds.shape[0]\n",
    "    preds = preds.view(bs, -1)\n",
    "    target = target.view(bs, -1)\n",
    "\n",
    "    vd = torch.sum(target, dim=1) - torch.sum(preds, dim=1)\n",
    "    avd = vd.abs()\n",
    "    l = avd.sum()\n",
    "    return l\n",
    "    \n",
    "    \n",
    "class SsnNetworkMuAndSamplesLossWrapper(nn.Module):\n",
    "    def __init__(self, loss_func, samples=10):\n",
    "        super().__init__()\n",
    "        self.loss = loss_func\n",
    "        self.samples = samples\n",
    "    def forward(self, result_dict, target):\n",
    "        s = result_dict['distribution'].mean # samples[0]\n",
    "        #print(s.shape, result_dict['distribution'].mean.shape)\n",
    "        dice = self.loss(s, target)\n",
    "        samples = fixed_re_parametrization_trick(result_dict['distribution'], self.samples).to(target.device)\n",
    "        loss = 0\n",
    "        for s in samples:\n",
    "            loss += self.loss(s, target)\n",
    "        \n",
    "        return dice + ((0.1*loss) / self.samples)\n",
    "    \n",
    "class SsnDiceMetricWrapper(DiceLossMetric):\n",
    "\n",
    "    def update(self, preds_dict, target: torch.Tensor):\n",
    "        super().update(preds_dict['logit_mean'], target)\n",
    "\n",
    "    def compute(self):\n",
    "        return super().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ebe3449-7758-4791-819d-c77cf30b0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssn_diceloss = SsnNetworkMuAndSamplesLossWrapper(dice_loss)# SsnNetworkMeanLossWrapper(dice_loss)\n",
    "mc_loss = StochasticSegmentationNetworkLossMCIntegral(num_mc_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41481167-7b64-4b35-b1dc-5b67c7f3608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardLitModelWrapper(pl.LightningModule):\n",
    "        def __init__(self, model, loss=F.cross_entropy, logging_metric=None, optimizer_params={\"lr\":1e-3}, lr_scheduler_params={\"step_size\":30, \"gamma\":0.1}, is_uq_model=False,\n",
    "                    optimizer_constructor=None, lr_scheduler_constructor=None):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.loss = loss\n",
    "            self.logging_metric_train = logging_metric()\n",
    "            self.logging_metric_val = logging_metric()\n",
    "            self.optim_params = optimizer_params\n",
    "            self.lr_scheduler_params = lr_scheduler_params\n",
    "            self.is_uq_model = False\n",
    "            self.optimizer_constructor = optimizer_constructor\n",
    "            self.lr_scheduler_constructor = lr_scheduler_constructor\n",
    "\n",
    "\n",
    "        def forward(self, x, **kwargs):\n",
    "            return self.model(x, **kwargs)\n",
    "\n",
    "        def configure_optimizers(self):\n",
    "            # optimizer and schedulers go in the configure optimizers hook\n",
    "            if self.optimizer_constructor:\n",
    "                optimizer = self.optimizer_constructor(self.parameters(), **self.optim_params)\n",
    "            else:\n",
    "                optimizer = torch.optim.Adam(self.parameters(), **self.optim_params)\n",
    "\n",
    "            if self.lr_scheduler_constructor:\n",
    "                lr_scheduler = self.lr_scheduler_constructor(optimizer, **self.lr_scheduler_params)\n",
    "            else:\n",
    "                lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, **self.lr_scheduler_params)\n",
    "\n",
    "            return [optimizer], [lr_scheduler]\n",
    "\n",
    "        def training_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            lightning automates the training loop, \n",
    "            does epoch, back_tracking, optimizers and schedulers,\n",
    "            and metric reduction.\n",
    "            we just define how we want to process a single batch. \n",
    "            we can optionally pass optimizer_idx if we want to define multiple optimizers within the configure_optimizers\n",
    "            hook, and I presume we can add our own parameters also to functions?\n",
    "            \"\"\"\n",
    "\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(True)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            loss = self.loss(y_hat, y)\n",
    "\n",
    "            # metrics \n",
    "            if self.logging_metric_train:\n",
    "                self.logging_metric_train(y_hat, y)\n",
    "                self.log(f\"train_metric\", self.logging_metric_train, on_step=True, on_epoch=False, prog_bar=True)\n",
    "            self.log(\"train_loss\", loss)\n",
    "\n",
    "            return loss\n",
    "\n",
    "    #     def training_epoch_end(self, outs):\n",
    "    #         self.log('train_metric_epoch', self.logging_metric_train.compute())\n",
    "\n",
    "    #     def validation_epoch_end(self, outs):\n",
    "    #         self.log('val_metric_epoch', self.logging_metric_val.compute())\n",
    "\n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            note: call trainer.validate() automatically loads the best checkpoint if checkpointing was enabled during fitting\n",
    "            well yes I want to enable checkpointing but will deal with that later.\n",
    "            also it does stuff like model.eval() and torch.no_grad() automatically which is nice.\n",
    "            I will need a custom eval thing to do my dropout estimation but can solve that later too.\n",
    "            \"\"\"\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(False)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            val_loss = self.loss(y_hat, y)\n",
    "\n",
    "            if self.logging_metric_val:\n",
    "                self.logging_metric_val(y_hat, y)\n",
    "                self.log(f\"val_metric\", self.logging_metric_val, on_step=True, on_epoch=True, prog_bar=True)\n",
    "            self.log(\"val_loss\", val_loss)\n",
    "\n",
    "        def test_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            we would need to directly call this function using the trainer\n",
    "            \"\"\"\n",
    "\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(False)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            test_loss = self.loss(y_hat, y)\n",
    "            self.log(\"test_loss\", test_loss)\n",
    "\n",
    "        def predict_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            just for making predictions as opposed to collecting metrics etc\n",
    "            note to use this, we just call .predict(dataloader) and it then automates the look\n",
    "            these functions are for a single batch. Nice.\n",
    "            \"\"\"\n",
    "            X, y = batch\n",
    "            pred = self(X)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce3bf63c-6159-462a-bbba-2f562a8e7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_factor = 5\n",
    "#avd_factor = 0.001\n",
    "    \n",
    "def double_loss(outs, target):\n",
    "    dice = ssn_diceloss(outs, target)\n",
    "    return dice * dice_factor + mc_loss(outs, target) * 0.01\n",
    "\n",
    "def triple_loss(outs, target):\n",
    "    main_loss = ssn_diceloss(outs, target) * dice_factor + mc_loss(outs, target) * 0.01\n",
    "    \n",
    "    if main_loss < 60:\n",
    "        main_loss += correction_loss(outs, target) * 0.1\n",
    "    return main_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "542f4859-551e-4124-afd8-20b0e3a0a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = double_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8fb50c3-f3e3-452e-90ea-80f10f28c28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: this model assumes that the input to the model contains the brain mask in the first channel!\n"
     ]
    }
   ],
   "source": [
    "model_raw = HyperMapp3rSSN2(ssn_rank=15).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ea2ce0a-de52-4770-92f7-877ae360ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = double_loss\n",
    "#loss = triple_loss\n",
    "\n",
    "optimizer_params={\"lr\":2e-4}\n",
    "optimizer = torch.optim.Adam\n",
    "lr_scheduler_params={\"milestones\":[1000], \"gamma\":0.5}\n",
    "lr_scheduler_constructor = torch.optim.lr_scheduler.MultiStepLR\n",
    "\n",
    "trained_ckpt_dir = '/disk/scratch/s2208943/results/new_tests/evid_ssn/'\n",
    "trained_model = 'epoch=29-step=4110.ckpt'\n",
    "\n",
    "model = StandardLitModelWrapper(model_raw, loss, \n",
    "                                logging_metric=SsnDiceMetricWrapper, # lambda : None,\n",
    "                                optimizer_params=optimizer_params,\n",
    "                                lr_scheduler_params=lr_scheduler_params,\n",
    "                                is_uq_model=False,\n",
    "                                optimizer_constructor=optimizer,\n",
    "                                lr_scheduler_constructor=lr_scheduler_constructor\n",
    "                               )\n",
    "\n",
    "# model = StandardLitModelWrapper.load_from_checkpoint(trained_ckpt_dir + trained_model,\n",
    "#                                                      model_raw, loss, \n",
    "#                                 logging_metric=SsnDiceMetricWrapper, # lambda : None,\n",
    "#                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b91e26e5-55e9-485b-ad01-1c6c8dff58b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "accelerator=\"gpu\"\n",
    "devices=1\n",
    "max_epochs=1000\n",
    "precision = 32\n",
    "\n",
    "rootdir = \"/disk/scratch/s2208943/results/new_tests/evid_ssn\"\n",
    "final_dir = rootdir\n",
    "checkpoint_callback = ModelCheckpoint(final_dir, save_top_k=-1, monitor=\"val_loss\", every_n_epochs=5)\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=15, verbose=\"False\", mode=\"min\", check_finite=True)\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    max_epochs=max_epochs,\n",
    "    precision=precision,\n",
    "    default_root_dir=final_dir\n",
    ")\n",
    "\n",
    "#trainer.fit(model, train_dataloader, val_dataloader,)# ckpt_path='/disk/scratch_big/s2208943/results/new_tests/epoch=15-step=2192.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a5bcbeb-0f4e-43d8-b3d7-62978559e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndigit(n, x):\n",
    "    s = str(x)\n",
    "    ns = \"0\" * (n - len(s))\n",
    "    return ns + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a67df927-c65c-4a0a-be52-edfb493e8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/s2208943/ipdis/results/final_models/\"\n",
    "folders = [\"Xnew_ssn_ens\" + ndigit(2, x+1) + \"/\" for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52a633ae-c5b0-49c0-8db1-a585335e35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = []\n",
    "for f in folders:\n",
    "    ckpts = sorted([c for c in os.listdir(root+f) if \"epoch\" in c])\n",
    "    c = ckpts[-2] # the second from last seems to be the 'best' checkpoint\n",
    "    cs.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14bc1205-8176-4575-8d66-4796ea7ab333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(folders)):\n",
    "#         f = folders[i]\n",
    "#         c = cs[i]\n",
    "#         ckpt = root + f + c\n",
    "\n",
    "#         model = StandardLitModelWrapper.load_from_checkpoint(root + f + c, model=model_raw, loss=loss, \n",
    "#                                     logging_metric=SsnDiceMetricWrapper).cuda()\n",
    "#         print(\"checkpoint: \", root + f + c)\n",
    "#         trainer.validate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fcece1f-ce4f-49ed-b118-e2def5365aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.validate(model, test_dataloader)#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d796c-8f63-423e-bbdf-b6e63158a164",
   "metadata": {},
   "source": [
    "### Loading the dataset in 3D for analysis\n",
    "now each sample from the 3D dataset we can treat as a batch, and is a single image sample. Note that each batch may not be the same size now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4eefcd38-7925-42b1-9098-5fd31bc4bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load datasets\n",
    "# # this step is quite slow, all the data is being loaded into memory\n",
    "# # BIG NOTE\n",
    "# # during evaluating the modle, we set is_3d false here to avoid doing the z cropping (which can cause nans)\n",
    "# # and instead we run the whole brain scan through and it gives us a good prediction over all. Nice.\n",
    "# datasets_domains_3d = [MRISegmentation3DDataset(root_dir, domain, transforms=get_transforms(is_3D=False)) for domain in domains]\n",
    "\n",
    "\n",
    "# # split into train, val test datasets\n",
    "# datasets_3d = [train_val_test_split(dataset, validation_proportion, test_proportion, seed) for dataset in datasets_domains_3d]\n",
    "\n",
    "# # concat the train val test datsets\n",
    "# train_dataset_3d = ConcatDataset([ds[0] for ds in datasets_3d])\n",
    "# val_dataset_3d = ConcatDataset([ds[1] for ds in datasets_3d])\n",
    "# test_dataset_3d = ConcatDataset([ds[2] for ds in datasets_3d])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a36507a-6704-40a3-8acb-0ae57e78b1a7",
   "metadata": {},
   "source": [
    "### generating the samples procedure, only do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54c73cc7-377b-4f39-894c-08f838b1fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60c27a99-98ba-419c-9d75-2aaf7a8a28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs3d = []\n",
    "ys3d = []\n",
    "for x, y in test_dataset_3d:\n",
    "    xs3d.append(x)\n",
    "    ys3d.append(y.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfd78cc3-7af4-41c7-bf7e-300a309d37c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 224, 160])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs3d[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97dec448-7cad-4269-aa51-63b40f466ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samples(xs3dQ, ys3dQ):\n",
    "    samples3d = [[] for i in range(len(ys3dQ))]\n",
    "    model_means3d = [[] for i in range(len(ys3dQ))]\n",
    "    for i in range(len(folders)):\n",
    "        f = folders[i]\n",
    "        c = cs[i]\n",
    "        ckpt = root + f + c\n",
    "\n",
    "        model = StandardLitModelWrapper.load_from_checkpoint(root + f + c, model=model_raw, loss=loss, \n",
    "                                    logging_metric=DiceLossMetric).cuda()\n",
    "        \n",
    "        temp = 1.8\n",
    "\n",
    "        for j in tqdm(range(len(xs3dQ)), position=0, leave=True, ncols=150):\n",
    "            x3d = xs3dQ[j]\n",
    "            y3d = ys3dQ[j]\n",
    "            with torch.no_grad():\n",
    "                out = model(xs3dQ[j].swapaxes(0,1).cuda())\n",
    "                samples = fixed_re_parametrization_trick(out['distribution'], 2).cpu() / temp\n",
    "                samples3d[j].append(samples[0])\n",
    "                samples3d[j].append(samples[1])\n",
    "                mean = out['distribution'].mean.cpu() / temp\n",
    "                model_means3d[j].append(mean)\n",
    "                \n",
    "    return [torch.stack(ss) for ss in samples3d], [torch.stack(mus) for mus in model_means3d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "baa1d305-7f4f-4569-ae74-ad9e5be12b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_samples(xs3dQ, ys3dQ, model=model):\n",
    "#     samples3d = []\n",
    "#     model = model.cuda()\n",
    "#     for i in tqdm(range(len(ys3dQ)), position=0, leave=True, ncols=150):\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             out = model(xs3dQ[i].swapaxes(0,1).cuda())\n",
    "#             samples = fixed_re_parametrization_trick(out['distribution'], 20).cpu()\n",
    "#             samples3d.append(samples)\n",
    "            \n",
    "#     return samples3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fdc0b039-8ed3-4c64-9a63-955309e8e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:09<00:00,  3.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:09<00:00,  3.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:09<00:00,  3.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:10<00:00,  3.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:10<00:00,  3.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:10<00:00,  3.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:10<00:00,  3.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:10<00:00,  3.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:10<00:00,  3.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:10<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "samples3d, means3d = gen_samples(xs3d, ys3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8885d7b4-0d67-4131-9555-1a7204d25f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#means3d = [torch.mean(samples3d[i], dim=0) for i in range(len(samples3d))]\n",
    "means3d = [torch.mean(m, dim=0) for m in means3d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f29b4068-3816-49dc-937e-4cc0f417a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute majority vote on mean, see which is better actually. - maybe majority vote is better? but then what to do for samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba3a335a-d65d-44e4-ad49-54f903fed7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 40, 2, 224, 160]), torch.Size([40, 2, 224, 160]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples3d[0].shape, means3d[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b0420ccd-f4a6-4cfb-9a54-29d2bfe9dae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 35)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples3d), len(means3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e9b97-2c36-4483-97d9-33e8a1dbfb5b",
   "metadata": {},
   "source": [
    "### fixed compute section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68765d44-e637-4bc0-ba76-6e45999008e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ssn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a77217f7-8e76-4b23-ac24-9b56719c99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir(\"results/\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7f0b1ebb-9168-44fc-a132-60896304c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(fname):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/\"+model_name + \"/\" + fname, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4fa530-0ae6-4036-8a31-f1e4692d55ae",
   "metadata": {},
   "source": [
    "### Generating uncertainty maps for a batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6ad86065-5963-4453-b9c9-31a589732672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_map_from_samples(samples):\n",
    "    \"samples is of shape samples, batch size, channels, image dims  [s, b, c *<dims>]\"\n",
    "    probs = torch.nn.functional.softmax(samples, dim=2)\n",
    "    pic = torch.mean(probs, dim=0)\n",
    "    ent_map = torch.sum(-pic * torch.log(pic+1e-30), dim=1)\n",
    "    \n",
    "    return ent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9be5da7b-0249-4a5a-bbc1-06a47b435118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,20))\n",
    "# ids = 5, 20, 58, 37, 62, 49, 50, 23, 30, 48\n",
    "# count = 0\n",
    "# for i in range(64):\n",
    "#     if torch.sum(ys[0][i]) > 0:\n",
    "#         plt.subplot(6, 12, count+1)\n",
    "#         plt.imshow(ys[0][i], cmap='gray')\n",
    "#         plt.title(i)\n",
    "#         plt.axis('off')\n",
    "#         plt.subplot(6, 12, count+2)\n",
    "#         plt.imshow(ent2dbatch[i], vmin=0, vmax=0.7)\n",
    "#         plt.title(i)\n",
    "#         plt.axis('off')\n",
    "#         count += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3c923430-edcb-4c7c-9217-40475bb5d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good scans: 0, 1, 3, 27 (low dice), -1 (very interesting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b4e47f-93c7-4486-8535-cfc1be3f5bad",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1701ad5b-f173-4e04-b623-07c335e6a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_in_bin(value):\n",
    "    return torch.round(value, decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "470dcd3f-8163-4e90-8935-d639ff57a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(value, n, G):\n",
    "    return value / n + ((n-1) / n) * G\n",
    "\n",
    "def batch_rolling_average(values, n, G):\n",
    "    \"\"\"\n",
    "    assumes all batches but the last batch are the same size\n",
    "    \"\"\"\n",
    "    return values.sum() / (values.shape[0]*n) + ((n-1) / n) * G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15cb7d42-4ea5-40d5-94a1-fd76e121c3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8af3e50c-5e83-47be-a8da-ecd1b7d2123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:51<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# assess bin counts of p y = 1\n",
    "bins = 10 + 1 # for the 0 bin\n",
    "bin_batch_accuracies = [[] for b in range(bins)]\n",
    "bin_batch_confidences = [[] for b in range(bins)]\n",
    "bin_batch_sizes = [[] for b in range(bins)]\n",
    "bin_counts = [0 for b in range(bins)]\n",
    "for batch_idx in tqdm(range(len(ys3d)), ncols=150, position=0, leave=True): # skip the last batch with a different shape\n",
    "    batch_t = ys3d[batch_idx].squeeze()\n",
    "    batch_samples = samples3d[batch_idx]\n",
    "    \n",
    "    if batch_t.shape[0] < 10:\n",
    "        continue # skip last batch if it is very small.\n",
    "    \n",
    "    # get probabilities\n",
    "    probs = torch.nn.functional.softmax(batch_samples, dim=2)\n",
    "    p1s = probs[:,:,1]\n",
    "    \n",
    "    # split into bins\n",
    "    bin_ids = place_in_bin(p1s)\n",
    "    \n",
    "    # compute counts\n",
    "    for i in range(bins):\n",
    "        is_in_bin = (bin_ids == (i / 10))\n",
    "        # print(is_in_bin.shape)\n",
    "        # print(batch_t.shape)\n",
    "        \n",
    "        # number of elements in each bin\n",
    "        num_elem = torch.sum(is_in_bin).item()\n",
    "        if num_elem == 0:\n",
    "            print(\"zero\")\n",
    "        \n",
    "        # number of predictions = to class 1\n",
    "        c1_acc = batch_t.expand(p1s.shape)[is_in_bin].sum() / num_elem\n",
    "        \n",
    "        if torch.isnan(c1_acc):\n",
    "            print(\"acc_nan\")\n",
    "        \n",
    "        # average confidence of values in that bin\n",
    "        c1_conf = p1s[is_in_bin].mean()\n",
    "        \n",
    "        if torch.isnan(c1_conf):\n",
    "            print(\"conf_nan\")\n",
    "        \n",
    "        bin_batch_accuracies[i].append(c1_acc)\n",
    "        bin_batch_confidences[i].append(c1_conf)\n",
    "        bin_batch_sizes[i].append(num_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "94f4675f-380c-4467-8584-dffec3119aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_sizes = [torch.Tensor(bbs).sum() for bbs in bin_batch_sizes]\n",
    "bin_accuracies = [torch.Tensor([bin_batch_accuracies[i][j] * bin_batch_sizes[i][j] / bin_sizes[i] for j in range(len(bin_batch_accuracies[i]))]).sum().item() for i in range(len(bin_sizes))]\n",
    "bin_confidences = [torch.Tensor([bin_batch_confidences[i][j] * bin_batch_sizes[i][j] / bin_sizes[i] for j in range(len(bin_batch_confidences[i]))]).sum().item() for i in range(len(bin_sizes))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f698135c-d73e-49fe-bff8-88bce783078e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0002065286971628666,\n",
       " 0.03306491672992706,\n",
       " 0.09905378520488739,\n",
       " 0.1800549030303955,\n",
       " 0.2756529152393341,\n",
       " 0.38828280568122864,\n",
       " 0.5088671445846558,\n",
       " 0.6410566568374634,\n",
       " 0.7738470435142517,\n",
       " 0.8935558795928955,\n",
       " 0.9540783166885376]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "47a2dc9d-ee42-4c74-9aae-38f56b2df65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0007909931009635329,\n",
       " 0.08625375479459763,\n",
       " 0.19354259967803955,\n",
       " 0.2962942123413086,\n",
       " 0.39757853746414185,\n",
       " 0.49855902791023254,\n",
       " 0.599435031414032,\n",
       " 0.700727105140686,\n",
       " 0.8024573922157288,\n",
       " 0.9060750007629395,\n",
       " 0.9774553179740906]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "048fdf88-f01f-4802-a919-2789a680da4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPECTED CALIBRATION ERROR: note we skip the first bin due to its size tensor(0.0644)\n"
     ]
    }
   ],
   "source": [
    "total_size = torch.sum(torch.Tensor(bin_sizes)[1:])\n",
    "ece = torch.sum( (torch.Tensor(bin_sizes)[1:]/ total_size) * (torch.abs(torch.Tensor(bin_accuracies)[1:] - torch.Tensor(bin_confidences)[1:])))\n",
    "print(\"EXPECTED CALIBRATION ERROR: note we skip the first bin due to its size\", ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "29b5dfce-f25a-4ebf-8cc2-17af56bfd0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(bin_confidences, bin_accuracies)\n",
    "plt.plot([0,1],[0,1]);\n",
    "plt.xlabel(\"Confidence\")\n",
    "plt.ylabel(\"Accuracy\");\n",
    "save(\"calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da0e65fc-6c4d-4cbe-9f5d-10b2d5958796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPECTED CALIBRATION ERROR: note we skip the first bin due to its size tensor(0.0710)\n"
     ]
    }
   ],
   "source": [
    "total_size = torch.sum(torch.Tensor(bin_sizes)[1:])\n",
    "ece = torch.sum( (torch.Tensor(bin_sizes)[1:]/ total_size) * (torch.abs(torch.Tensor(bin_accuracies)[1:] - torch.Tensor(bin_confidences)[1:])))\n",
    "print(\"EXPECTED CALIBRATION ERROR: note we skip the first bin due to its size\", ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46137c04-4841-4de5-89e0-1262049d1dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlooking at just the class one calibration is useful due to the extreme lack of class 1 in the image, this gives us a better idea of how the model is doing\\nand when optimizing calibration I should be optimizing this.\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "looking at just the class one calibration is useful due to the extreme lack of class 1 in the image, this gives us a better idea of how the model is doing\n",
    "and when optimizing calibration I should be optimizing this.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f64da5cb-c64d-4515-a9f6-55d38ba4bdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3LElEQVR4nO3dd3wU1f7/8dcnIRBa6KEm9N4hNFG6ghS510JVr9i7WODqz96u9XJBRQUVFaRb6UiTJiWh9xZSKQkEAklI3fP7Y+L9Bi6QJWR3djef5+PBg53ZycyHIdl3Zs6Zc8QYg1JKKeVp/OwuQCmllLocDSillFIeSQNKKaWUR9KAUkop5ZE0oJRSSnmkYnYXcK0qV65s6tSpY3cZSimlCsmWLVtOGWOqXLre6wKqTp06RERE2F2GUkqpQiIi0Zdbr7f4lFJKeSQNKKWUUh5JA0oppZRH0oBSSinlkTSglFJKeSQNKKWUUh7JZQElIlNEJEFEdl/hfRGRT0TksIjsFJF2rqpFKaWU93HlFdR3QL+rvH8r0DD3z8PAFy6sRSmllJdxWUAZY9YASVfZZDAw1Vg2AuVFpLqr6lFKKVWIzkTBzOGQeNBlh7CzDaomEJtnOS533f8QkYdFJEJEIhITE91SnFJKqcvIyYb1n8DEzhC5GhL3u+xQXjHUkTFmMjAZICwsTKcAVkopO8RvgfnPwIld0OhW6P8RlA9x2eHsDKh4IO+/rFbuOqWUUp4k4zysfBc2T4LSwTBkKjS9DURcelg7A2oe8KSIzAI6AcnGmOM21qOUUupS+xfBojFwLh46PAC9X4PAcm45tMsCSkRmAj2AyiISB7wOBAAYY74EFgH9gcNAGjDKVbUopZS6RueOw+KxsG8eBDeDu76FkI5uLcFlAWWMGZ7P+wZ4wlXHV0opVQAOB2yZAsvfhOwM64qpy1NQrLjbS/GKThJKKaXc4OReqxNE3Gao2x0G/gcq1betHA0opZQq6rIuwJqPYP0EKBEEf58ErYa6vBNEfjSglFKqKIv8AxY8C0mR0HoE3PIOlK5kd1WABpRSShVNqadg6cuwcxZUrAf3/gb1ethd1UU0oJRSqigxBnbMtMIp4xzc9AJ0ewECStpd2f/QgFJKqaLi9BFYMBqOroGQTjBwPFRtZndVV6QBpZRSvi47E/78BFZ/CMVKwIBx0H4U+Hn2lIAaUEop5ctiNlldxxP3QbPB0O8DCPKOiSM0oJRSyhddOAsr3oSIKRBUC4bPgsa32l3VNdGAUkopX2IM7P0NFv8TUhOg8+PQ82UoUcbuyq6ZBpRSSvmKs7Gw6AU4uASqtYLhM6Fmu0LZtTGG5+bsoEOdiozoFFoo+8yPBpRSSnk7Rw5smgQr3wGM9bBtp8fAv/A+4qduiOaXbfE0qlq20PaZHw0opZTyZsd3wLyn4fh2aHAzDPg3VKhdqIfYEXuWdxbupVeTYB7pVq9Q9301GlBKKeWNMlNh1b9g4+dQqjLcOQWa317o4+clp2Xx+PStBJcN5N93tcbPz33j82lAKaWUtzn4Oyx8HpJjoP190OcNKFmh0A9jjOH5uTtIOJ/OnEe6UKG0e6fc0IBSSilvcf4kLHkR9vwMlRvDqCVQu4vLDvf12qMs33eS1wY2o21o4QdgfjSglFLK0zkcsPV7WP66NTVGz5eh6zPWqBAuEhGVxPtL9tOveTVGda3jsuNcjQaUUkp5ssQD1kgQMRug9o0waDxUbujSQ55OyeDJGduoWb4kH97VCrFpXigNKKWU8kRZ6bBuHKwdB8VLw22fQdu7XT6JoMNheHbODpJSM/n58RsICgxw6fGuRgNKKaU8zdG11qjjpw9DyyHQ919QpopbDv35H4dZczCRd/7WghY1y7nlmFeiAaWUUp4iLQmWvQrbfoDyteHun6FBb7cdfsOR04xbdpDbWtdgpJtGi7gaDSillLKbMbBrLix5CS6cga6jofs/oXgpt5WQcD6dp2dto07l0vzr9pa2tTvlpQGllFJ2SjoKC5+DIyuhZnu491eo1tKtJeQ4DM/M3M759CymPdCRMiU8Ixo8owqllCpqcrJgw2fwxwfgVwxu/Qg6PAB+/m4vZcLyg2yIPM2Hd7aiSbUgtx//SjSglFLK3eK2wPyn4eRuaDIQbv0QytW0pZQ1BxP5dNVh7mxfiyFhIbbUcCUaUEop5S7p56wRxzdPhrLVYeh0aDrQtnJOJKczevZ2GgWX5e3BLWyr40o0oJRSyh32LYBFY+D8cej4EPR6FQLtu52WlePgqZlbSc/KYeLIdpQs7v5bi/nRgFJKKVdKjofFY2H/AghuDkOnQa0wu6vi498PEB51hgnD2tAg2DNn29WAUkopV3DkQPg3sOItcGRbI453eRL87RuZ4S/L955k0upIRnYKZXAbe9q+nKEBpZRShe3Ebmv8vPgIqN8LBoyDinXtrgqAuDNpPD93B81rBPHqwGZ2l3NVGlBKKVVYMtNg9QdW9/HA8nD7V9DyLpePn+eszGwHT8zYhsNhmDiiHYEBntfulJcGlFJKFYbDK6wHbs9EWYO63vw2lKpod1UXeW/xPnbEnuWLke2oU7m03eXkSwNKKaWuR0oiLP1/sGsOVGoA/1gAdW+yu6r/sXjXcb5dH8WornW4tWV1u8txigaUUkoVhDGwfTr8/gpkpEC3sXDT8xAQaHdl/yPqVCpjf9xJ65DyvHRrU7vLcZqfK3cuIv1E5ICIHBaRFy/zfqiIrBKRbSKyU0T6u7IepZQqFKcOw/eD4LcnoEoTeHQd9HrZI8MpPSuHx6dvxc9PmDiiLcWLufRjv1C57ApKRPyBicDNQBwQLiLzjDF782z2CjDHGPOFiDQDFgF1XFWTUkpdl+wMWDce1n4MxUrCoAnQ9l7w89wP/bcX7GXv8XN8848walVw3+johcGVt/g6AoeNMZEAIjILGAzkDSgD/PUodTngmAvrUUqpgoveYHUdP3UAmt8O/d6HslXtruqqftsez/RNMTzSvR69m3p2rZfjyoCqCcTmWY4DOl2yzRvA7yLyFFAa6HO5HYnIw8DDAKGh9k+ipZQqQi6cgeVvwJbvoFwojJgLjW6xu6p8HU5I4aWfd9GhTgVeuKWx3eUUiN3XpcOB74wxtYD+wDQR+Z+ajDGTjTFhxpiwKlXcM+2xUqqIMwZ2/wSfdYStU61RIJ7Y6BXhdCEzh8enbyEwwJ9Ph7cjwN/uj/qCceUVVDyQd+z2Wrnr8noA6AdgjNkgIoFAZSDBhXUppdTVnY2Bhc/Dod+hehsYORdqtLG7Kqe9+ttuDiWk8P2ojlQr53kdN5zlyoAKBxqKSF2sYBoGjLhkmxigN/CdiDQFAoFEF9aklFJXlpMNm76AVf8CBPq+Bx0fBn/veSJnTkQsP26J4+leDejWyLvvOLnsrBtjskXkSWAp4A9MMcbsEZG3gAhjzDzgeeArEXkWq8PEfcYY46qalFLqio5tg3lPw4md0Kgf9P8YynvWBH752X/iHK/9tpsu9SrxTJ9Gdpdz3Vz6a4ExZhFW1/G8617L83ov0NWVNSil1FVlpMCqd2HTl1A6GO76HpoN9pjx85yVkpHN49O3UjYwgAnD2+Dv5131X473XLcqpVRhO7AEFr0AybEQ9gD0eR0Cy9ld1TUzxvDSz7uIOpXK9Ac7E1zWe9ud8tKAUkoVPedPwOJ/wt5foUpTuP93CL30KRjvMX1TDPN3HGNM38Z0qV/J7nIKjQaUUqrocDhgy7ew/E3IToder8ANz0Cx4nZXVmC745N5a/5eujeqwmPd69tdTqHSgFJKFQ0J+6yRIGI3Qd1uMHA8VPLuD/Rz6Vk8Pn0rlcoU5z9D2+DnA+1OeWlAKaV8W1Y6rPkI1k+AEmXhb19C62Fe1wniUieS03lixlaOnb3A7Ec6U7G0914FXokGlFLKd0WuhgWjISkSWg+HW96F0t7fRrP2UCKjZ23nQlYO44e1oX1tz5oYsbBoQCmlfE/qaWueph0zoEJduOdXqN/T7qquW47D8MmKQ3yy8hANg8vw+ch2NAgua3dZLqMBpZTyHcbAztnWDLfpydYEgt3GQEBJuyu7bqdSMhg9azvrDp/i9nY1eedvLShV3Lc/wn37X6eUKjpOH4EFz8LR1VCrIwwaD1Wb211VoQiPSuLJGVs5m5bFB3e0ZEhYCOLlbWjO0IBSSnm3nCz48xNY/SH4F4cB/4b293v0JILOMsYweU0kHy49QEiFknz7eEea1QjK/wt9hAaUUsp7xW62uo4n7IWmt8GtH0JQdburKhTJaVk8P3c7y/clcGuLanxwZyuCAgPsLsutNKCUUt4nPRlWvAXh30BQDRg2E5r0t7uqQrMj9ixPzNjKyXPpvD6oGffdUKdI3NK7lAaUUsp7GAP75lnDFJ0/AZ0ehV4vW883+QBjDNM2RvPOgn1UKVuCOY90oW1oBbvLso0GlFLKOyTHwaIxcGARVGsJw6ZDzfZ2V1VoUjKyefGnnSzYeZyejaswbkgbKvjgw7fXQgNKKeXZHDmweTKsfAeMA25+Gzo/7lWTCOZn3/FzPDF9K1GnUxnbrzGPdqvvc8MWFYTv/A8rpXzP8Z1WJ4hjW6FBH6uHXoU6dldVqOZExPLqr7spVzKAGQ91pnM97x/porBoQCmlPE9mKvzxHmz4HEpVhDu+gRZ3eP34eXldyMzh1d928+OWOG6oX4kJw9pSpWwJu8vyKBpQSinPcmg5LHwWzsZAu3uhz5tWSPmQI4kpPDF9KwdOnufpXg14pk8jn5gBt7BpQCmlPENKAix5EXb/BJUbwajFUPsGu6sqdPN3HOPFn3ZSvJgf397XgR6Ng+0uyWNpQCml7OVwwLZpsOxVyLoAPV6CG5+FYr51uysjO4d3F+5j6oZo2teuwKfD21KjvPePEehKGlBKKfskHrSmw4heD7W7WpMIVmlkd1WFLjYpjSdmbGVnXDIP3VSXsf2aEODv/UMxuZoGlFLK/bIzYO04WDcOAkrBbZ9Cm7t9Yvy8Sy3be5Ln52zHAJPuaU/f5tXsLslraEAppdwrah3MHw2nD0HLu6Dvv6CM77XDZOU4+HjpASatiaRFzSA+H9Ge0Eql7C7Lq2hAKaXcIy0Jlr1mtTeVrw13/2Q92+SDTiSn89TMrYRHnWFkp1BeHdiMwAB/u8vyOhpQSinXMsbqmbfkRSukuj4D3V+E4r55NbH2UCLPzNpOelYOE4a1YXCbmnaX5LU0oJRSrnMmChY8B0dWQI12cPfPUL2V3VW5RFGbjt0dNKCUUoUvJws2fg6r3gM/f+j3AXR8yHrtg4ridOzuoGdQKVW44rfAvGfg5C5oPAD6fwjlatldlctsPprEUzOL3nTs7qABpZQqHBnnrRHHN02CstVg6A/QdJDdVbmMw2GYvDaSj4rodOzuoAGllLp++xfBohfg3DHo8CD0fhUCy9ldlcucTcvkhbk7WL4vgf4tq/HBHa0oW8SmY3cHDSilVMGdOwaLx8K++RDcDO76HkI62F2VS+2IPcvj07eScL5oT8fuDhpQSqlr58iBiCmw/E1wZEHv1+GGp8Dfd68iklIz+WzlYaZtjCK4bGCRn47dHTSglFLX5uQeaxLBuHCo1xMGjoOK9eyuymUuZOYwZf1RvvzjCKmZ2dzVPoQXb21S5KdjdweXBpSI9AMmAP7A18aY9y+zzRDgDcAAO4wxI1xZk1KqgLIuwOoP4c9PrPalv0+GVkN8ahLBvHIchp+2xDFu2UFOnEunT9Ng/tmvCQ2r6rNN7uKygBIRf2AicDMQB4SLyDxjzN482zQEXgK6GmPOiIjvDcillC84sgoWPAtnjkKbkXDLOz43ieBfjDGsOpDA+4v3c/BkCq1DyjNhWBs66VTsbufKK6iOwGFjTCSAiMwCBgN782zzEDDRGHMGwBiT4MJ6lFLXKvUULH0Zds6CivXh3nlQr7vdVbnM9tizvLdoH5uOJlGnUik+H9mOW1tU004QNnFlQNUEYvMsxwGdLtmmEYCIrMe6DfiGMWaJC2tSSjnDGNg+A35/xXq+qdsYuOkFCAi0uzKXiD6dyodLD7Bw53EqlS7OW4ObM7xjqM7ZZDO7O0kUAxoCPYBawBoRaWmMOZt3IxF5GHgYIDQ01M0lKlXEnDpsTSIYtRZCOsOgCRDcxO6qXOJUSgafrjjE9E0xBPj78XTvhjzcrR5lStj90ajAiYASkUHAQmOM4xr3HQ+E5FmulbsurzhgkzEmCzgqIgexAis870bGmMnAZICwsDBzjXUopZyRnQnrJ8Caj6BYIAz8D7S7zycnEUzLzOabtUeZtCaSC1k5DO0QwujeDQkO8s0rRG/lzK8JQ4HxIvITMMUYs9/JfYcDDUWkLlYwDQMu7aH3KzAc+FZEKmPd8ot0cv9KqcISs9HqOp64H5r/Hfq9bw1X5GOycxzM3RLHf5YdJOF8Brc0q8rYfk1oEFzG7tLUZeQbUMaYu0UkCCtIvhMRA3wLzDTGnL/K12WLyJPAUqz2pSnGmD0i8hYQYYyZl/veLSKyF8gBxhhjTl//P0sp5ZQLZ2H5G7DlWygXAiPmQKO+dldV6IwxLN+XwAdL9nM4IYV2oeX5fGQ7wur4Zk9EXyHGOHfHTEQqAfcAo4F9QAPgE2PMpy6r7jLCwsJMRESEOw+plO8xBvb+Cov/CamJ0Plx6PESlPC9K4mtMWd4b9E+wqPOUK9yacb2a0Lf5lW1Z54HEZEtxpiwS9c70wZ1GzAKK5CmAh2NMQkiUgqry7hbA0opdZ3OxsDCF+DQUqjeGkbMhhpt7a6q0EUmpvDR0gMs3n2CymVK8M7fWjC0Q4j2zPMizrRB3QH8xxizJu9KY0yaiDzgmrKUUoUuJxs2T4KV7wIG+v4LOj4C/r7VYy3xfAafrDjEjM0xlCjmx+g+DXnopnqU1p55XseZ/7E3gON/LYhISaCqMSbKGLPCVYUppQrRse0w/2k4vgMa9oUBH0N533pkIzUjm6/WRvLVmkgysh2M6BjK070bUqVsCbtLUwXkTEDNBW7Is5yTu863x9RXyhdkpMAf71nTr5euAnd+a/XS86H2l6wcB7PDYxm//BCnUjK4tUU1xvRtTL0qvteeVtQ4E1DFjDGZfy0YYzJFRIfxVcrTHVwKC5+H5FhoPwr6vAEly9tdVaExxrB0z0k+XLKfyFOpdKhTgUn3tKd9bZ0Cw1c4E1CJInJbbrdwRGQwcMq1ZSmlCuz8SVjyT9jzC1RpAqOWQO0udldVqCKiknhv8X62RJ+hQXAZvro3jD5Ng7Vnno9xJqAeBaaLyGeAYI2vd69Lq1JKXTuHA7Z+D8teh+x06PkKdH0GivnODY/DCSl8sGQ/y/aeJLhsCd67vSV3ta9FMe2Z55OceVD3CNBZRMrkLqe4vCql1LVJ2G+NBBG7EercBAPHQ+UGdldVaE6eS2f88kPMiYilZIA/L9zSiPtvrEup4tozz5c59b8rIgOA5kDgX5fQxpi3XFiXUsoZWemw9mNYN956yHbw59BmhM90gth77BzfrDvKvB3xGAP3dK7NU70aUKmM9swrCpx5UPdLoBTQE/gauBPY7OK6lFL5OboG5o+GpCPQahj0fRdKV7a7quvmcBhWH0zk63WRrD98mpIB/ozoGMoDN9YjtFIpu8tTbuTMFdQNxphWIrLTGPOmiPwbWOzqwpRSV5CWBL+/Ctt/gAp14J5foH4vu6u6bulZOfy8NZ5v1kVyJDGVakGB/LNfE0Z0DKVcqQC7y1M2cCag0nP/ThORGsBpoLrrSlJKXZYxsHMOLH0J0pPhxmeh21go7t1XFQnn05m2IZofNkZzJi2LFjWDmDCsDf1bVtdhiYo4ZwJqvoiUBz4CtgIG+MqVRSmlLpEUCQueg8hVUKuDNYlg1eZ2V3Vd9h3PbV/afowsh4M+Tavy4I116Vi3onYXV0A+ASUifsCK3BlufxKRBUCgMSbZHcUpVeTlZMGfn8LqD8AvAPp/DGH3g5+/3ZUViMNhWH0okW/WHmXd4VOUDPBnWMcQRnWtS93Kpe0uT3mYqwaUMcYhIhOBtrnLGUCGOwpTqsiLDbe6jifsgaaD4NYPIaiG3VUVSHpWDr9si+ebdUc5nJBC1aASjO3XmBEdQylfynee01KFy5lbfCtE5A7gZ+Ps5FFKqYJLPwcr3oLwr6FsdRg2A5oMsLuqAkk8n8G0jVb7UlJqJs1rBPGfoa0Z0LIGxYtp+5K6OmcC6hHgOSBbRNKxRpMwxpggl1amVFG0bz4sGgvnj0OnR6DXK1CirN1VXbMDJ87zzbpIft1mtS/1blKVB2+qSydtX1LXwJmRJLzvp0Mpb5McD4vGwIGFULUlDP0BarW3u6prYoz1/NI3646y9tApAgP8GNohhFFd6+jI4qpAnHlQt9vl1l86gaFSqgAcOdatvBVvWa9vfsuaft3fe577Sc/K4dfc9qVDCSkEly3BmL5W+1KF0tq+pArOmVt8Y/K8DgQ6AlsA738yUCk7ndhldYKI3wL1e8PAcdaDt17iVErGf59fOp2aSbPqQYwb0pqBrbR9SRUOZ27xDcq7LCIhwHhXFaSUz8tMg9Xvw5+fQckKcMc30OIOrxk/7+DJ83yz9ii/bI8nM9tBn6bB3H9jXbrUq6TtS6pQFWQo4DigaWEXolSRcHi59cDt2Whoe491S69URburypcxhrWHTvH1uqOsOZhIYIAfQ8JqMaprXepr+5JyEWfaoD7FGj0CwA9ogzWihFLKWSmJ1hBFu+ZCpYZw30Koc6PdVeUrPSuHeduP8fW6SA6eTKGKti8pN3LmCioiz+tsYKYxZr2L6lHKtxgD26ZZg7tmpUH3F+Gm56CYZ08XkXg+gx82RjN9UzSnUjJpWj2If9/VmoGtq1OimHeOYqG8jzMB9SOQbozJARARfxEpZYxJc21pSnm5U4es6TCi10HoDTBoPFRpbHdVV7XnWDJT1kUxf8cxMnMc9G5itS/dUF/bl5T7OTWSBNAH+Gsm3ZLA78ANripKKa+WnWFNILj2YwgoCYM+sdqb/DyzZ1uOw7B830mmrDvKpqNJlCruz/COIdyn4+MpmzkTUIF5p3k3xqSIiHeP76+Uq0T/aXUdP3XQ6pnX9z0oW9Xuqi7rfHoWcyPi+O7PKGKS0qhZviQv92/KkA4hlCvpPc9hKd/lTEClikg7Y8xWABFpD1xwbVlKeZkLZ2DZ67D1eygfCiN/goZ97K7qsmJOp/Hdn1HMiYglJSObsNoVePHWJtzSrCrFdP4l5UGcCajRwFwROYY1Dl81YKgri1LKaxgDu3+CJS9B2mm44Sno8RIU96xbY8YYNh9N4pt1R1m27yT+IgxsVZ1RXevSOqS83eUpdVnOPKgbLiJNgL9adw8YY7JcW5ZSXuBMNCx8Hg4vgxpt4e6foHoru6u6SEZ2Dgt2HGfK+qPsOXaOCqUCeKJHA+7pUpuqQYF2l6fUVTnzHNQTwHRjzO7c5QoiMtwY87nLq1PKE+Vkw8bP4Y/3AIF+70PHhz1qEsFTKRlM3xjDtI3RnErJoGFwGd67vSV/a1OTksU9p06lrsaZW3wPGWMm/rVgjDkjIg8BGlCq6InfanWCOLETGveH/h9BuVp2V/Vf+46fY8q6o/y24xiZ2Q56Nq7C/TfW5cYGlbWbuPI6zgSUv4jIX5MViog/oI+Qq6Il4zysfBc2T4LSwTBkmjXLrQd86DschpX7E5iy/ih/HjlNyQB/HYZI+QRnAmoJMFtEJuUuPwIsdl1JSnmYA4th4QtwLh46PAC9X4PAcnZXRUpGNj9GxPLdn1FEnU6jerlAXry1CcM6hOg06sonOBNQ/wQeBh7NXd6J1ZMvXyLSD5gA+ANfG2Pev8J2d2CNWNHBGBNxuW2Ucrtzx2HxWNg3D4KbwV3fQkhHu6siNimNqRuimBUey/n0bNqGlueFvo3p27waAdpNXPkQZ3rxOURkE1AfGAJUBn7K7+tybwVOBG7GGgE9XETmGWP2XrJdWeAZYNO1l6+UCzgcsGUKLH8TcjKtK6YuT0Ex+65KjDFERJ9hyrqjLN1zAhGhf8vqjOpah3ahFWyrSylXumJAiUgjYHjun1PAbABjTE8n990ROGyMiczd3yxgMLD3ku3eBj7g4okRlbLHyb2wYDTEboK63WHgf6BSfdvKycx2sHDXMaasi2JXfDLlSgbwSPf63NulNtXLlbStLqXc4WpXUPuBtcBAY8xhABF59hr2XROIzbMcB3TKu4GItANCjDELRUQDStkn6wKs+QjWT4ASQfD3SdBqqG2dIJJSM5mxKZqpG6JJOJ9B/SqleedvLbi9XU1KFS/ING5KeZ+rfaffDgwDVonIEmAW1kgShUJE/IBxwH1ObPswVjsYoaGhhVWCUpbIP2DBs5AUCa1HwC3vQOlKbi/DGMPWmDNM3xjDgl3Hycx20K1RFT68sw7dGlbBz8/+HoNKudMVA8oY8yvwq4iUxro1NxoIFpEvgF+MMb/ns+94ICTPcq3cdX8pC7QA/sh9PqMaME9Ebru0o4QxZjIwGSAsLMygVGFIPQ2/vww7ZkLFenDvb1Cvh9vLOJeexa/b4pmxKYb9J85TpkQxhoTV4h9d6tCwalm316OUp3Cmk0QqMAOYISIVgLuwevblF1DhQEMRqYsVTMOAEXn2m4zV4QIAEfkDeEF78SmXMwZ2zIKl/w8yzsFNL0C3F6ypMdxoZ9xZZmyK4bftx7iQlUOLmkG8d3tLbmtdg9Il9DaeUtf0U2CMOYN1JTPZiW2zReRJYClWN/Mpxpg9IvIWEGGMmVeQgpW6LqePWLfzjq6GkE4waAIEN3Xb4VMzspm/4xjTN8WwKz6ZkgH+3Na6BiM7h9KqVnm31aGUN3Dpr2nGmEXAokvWvXaFbXu4shZVxGVnwp+fwOoPrenWB4yD9qPcNongvuPnmLEphl+2xZOSkU3jqmV5a3Bz/ta2JkGBOveSUpej9xGU74vZZI2fl7gPmg2Gfh9AUHWXHzY9K4eFO48zfVM0W2POUryYHwNbVmdk51DahVbQsfGUyocGlPJd6cnWw7YRUyCoJgyfBY1vdflhDyekMHNzDD9uiSP5Qhb1KpfmlQFNuaNdLSqU1iGIlHKWBpTyPcZYwxMtGgupCdD5Mej5MpRw3cCpmdkOlu45wfRN0WyMTCLAX7ileTVGdgqlS71KerWkVAFoQCnfcjYWFo2Bg4uhWisYMcuaTNBFYk6nMWNzDHMjYjmdmkmtCiUZ268xd7UPoUrZEi47rlJFgQaU8g2OHNg0CVa+AxjrYdtOj4F/4X+LZ+U4WLEvgemboll76BT+fkLvJsGM7FybmxpU1gdqlSokGlDK+x3fYXWCOLYNGtwMA/4NFWoX+mHiz15g9uYYZoXHknA+g+rlAnm2TyOGdgihWjmdPl2pwqYBpbxXZiqs+hds/AJKVYI7p0Dz2wt1/Lwch2H1wQRmbIph5f4EDNC9URXe7VSbno2rUEynt1DKZTSglHc6tAwWPAfJMdD+PujzBpQsvGknEs6lMycilpmbY4k/e4HKZUrwWI/6DOsQSkjFUoV2HKXUlWlAKe9y/iQseRH2/AyVG8OoJVC7S6Hs2uEw/HnkNNM3RbNs70myHYauDSrx8oCm9GlaleLF9GpJKXfSgFLeweGAbVNh2WvW1Bg9X4auz1ijQlynk+fS+XFLHLPDY4lJSqNCqQDuv7EuwzuGUrdy6UIoXilVEBpQyvMlHrA6QcRsgNo3wqDxULnhde0yO8fBqgOJzA632pYcBrrUq8RzNzeiX4tqBAb4F07tSqkC04BSnisrHdaNg7XjoHhpGDwR2oy8rk4Q0adTmR0ey49b4kg4n0GVsiV4tHt9hoSFUEevlpTyKBpQyjNFrYP5o+H0IWg5BPr+C8pUKdCu0rNyWLrnBLM2x7Ih8jR+Aj0bBzO0Qwg9mwQToD3xlPJIGlDKs6QlwbJXYdsPUL423P0zNOhdoF3tP3GOWZtj+WVbPMkXsgipWJIXbmnEne31uSWlvIEGlPIMxsCuH60eehfOQNfR0P2fUPzaunSn5M63NCs8lh2xZynu70ffFtUY1iGELvUq6SgPSnkRDShlv6SjsPA5OLISaraHe3+Fai2d/nJjDFtjzjI7PIYFO4+TlplDo6pleHVgM25vW1NHEFfKS2lAKfvkZMGGifDH++BXDG79CDo8AH7O9aBLSs3kl23xzA6P4eDJFEoV92dQqxoM7RhC25DyOoK4Ul5OA0rZI24LzH8aTu6GJgPh1g+hXM18v+yvh2lnhcfw+56TZOY4aBNSnvdvb8nA1jUoU0K/pZXyFfrTrNwr/Zw14vjmyVC2OgydDk0H5vtlx5Mv8GNEHLMjYok7c4FyJQMY2TmUoR1CaFItyA2FK6XcTQNKuc++BdZcTeePQ8eHoNerEHjlcMnKcbBqfwKzwmP544D1MO0N9Ssxpm9j+jbXh2mV8nUaUMr1zh2zgmn/AqjaAoZOg1phV9z86KlU5kRYD9Mmns8guKw1UOuQsBBqV9KHaZUqKjSglOs4ciBiCix/ExzZ0OdN6PIE+Af8z6bpWTks2X2CWeExbIxMwt9P6Nk4mGEdQuih01ooVSRpQCnXOLHbGj8vPgLq94IB46Bi3f/Z7EhiCtM2RPPz1jjOpWcTWrEUY/o25s72tagapA/TKlWUaUCpwpWZBqs/gA2fQWB5uP0raHnXRePn5TgMK/cnMHVDFGsPnSLAX+jXojrDO4TQWR+mVUrl0oBShefISljwLJyJgrZ3w81vQ6mK/337TGomsyNimbYhmvizF6gWFMjzNzdiWMdQqpS9/mkzlFK+RQNKXb/UU7D0/8HO2VCpAfxjAdS96b9v74pL5vsNUczbcYzMbAed61XklQFN6dOsqg7UqpS6Ig0oVXDGwPbp8PsrkJFijZ1343MQEEhGdg6Ldh1n6oZotsWcpVRxf+5qX4t7u9ShcbWydleulPICGlCqYE4dhgWjIWothHaBgeMhuAnHzl5gxqYDzNwcw+nUTOpVLs3rg5pxR/taBAX+b+89pZS6Eg0odW2yM2H9eFjzMRQLhEETMG3vYcPRM0z7fQu/7z2Jwxh6N6nKvV1qc2ODytrpQSlVIBpQynnRG6yu46cOQPPbSev1Dj8dymbq+HUcSkihfKkAHrypLnd3qk1IxWubJkMppS6lAaXyd+EsLH8dtnwH5UI5PnAak47V56dPdnM+I5sWNYP46M5WDGpdQ4cfUkoVGg0odWXGwJ5fYMmLmNREohvdzzupg1n+YyoB/tEMaFmde2+oo1NbKKVcQgNKXd7ZGFj4PBz6nYSyTflnwBhW7axBtaAcXrilEUM76LNLSinX0oBSF8vJhk1f4lj5DlkO+DjnXqYk3kzHesF8Mag2NzerquPiKaXcwqUBJSL9gAmAP/C1Meb9S95/DngQyAYSgfuNMdGurEldWWbsFlJ/fJIKyXtZmdOW9+RBurRvzeIudWhUVZ9dUkq5l8sCSkT8gYnAzUAcEC4i84wxe/Nstg0IM8akichjwIfAUFfVpC7veMIp4n95hbbHZ5Npgnij5Fhq3zicX8JC9NklpZRtXHkF1RE4bIyJBBCRWcBg4L8BZYxZlWf7jcDdLqxH5WGMYWNkEluXz+Jvx8YRJqdYVfY2SvR7k9ea1tVnl5RStnNlQNUEYvMsxwGdrrL9A8Diy70hIg8DDwOEhoYWVn1FkjGG5fsS+GH5Ju5K/Iwn/DeRWKoeJwdOoWfz7naXp5RS/+URnSRE5G4gDLjsJ6QxZjIwGSAsLMy4sTSf4XAYlu45wWcrDtIm8Vc+C5hFqYBssm56mSo3jYZixe0uUSmlLuLKgIoHQvIs18pddxER6QO8DHQ3xmS4sJ4iKcdhWLTrOJ+uPIRJ2M9/Sk6hRcB+HHW64TdoPP6V6ttdolJKXZYrAyocaCgidbGCaRgwIu8GItIWmAT0M8YkuLCWIic7x8H8ncf4bOVh4hLP8GrQIkYE/oyUCIK+X+LXethFkwgqpZSncVlAGWOyReRJYClWN/Mpxpg9IvIWEGGMmQd8BJQB5uaORBBjjLnNVTUVBVk5Dn7dFs/EVYeJOp3G0EqRzKv8FaVToqH1cLjlXShdye4ylVIqXy5tgzLGLAIWXbLutTyv+7jy+EVJZraDn7bGMXHVYeLOXOCG6obpjX+kZvQvUKEu3PMr1O9pd5lKKeU0j+gkoQouPSuHuRGxfPHHEY4lp9O6VjkmtzpE010fILHJcNPz0G0MBJS0u1SllLomGlBeKj0rhxmbYpi05ggnz2XQvnYFxt9Sjg573kY2/QG1OsKgCVC1md2lKqVUgWhAeZm0zGymb4xh0ppITqVk0KluRcbf2ZzOJ2Ygiz8E/+Iw4N/Q/n7w0zHzlFLeSwPKS6RkZDN1QxRfrz1KUmomNzaozFO92tIpIBLm3wEJe6DpbXDrhxBU3e5ylVLqumlAebhz6Vl8vz6Kb9Yf5WxaFj0aV+GpXg1pX9UPVrwF4d9AUA0YNhOa9Le7XKWUKjQaUB7qbFomU9ZH8e36o5xPz6ZP02Ce6tWQ1rXKwb75MHEspJyETo9Cr5ehhI42rpTyLRpQHiYpNZOv10YydUM0KRnZ9GtejSd7NaBFzXKQHAezHoMDi6BaSxg2A2q2s7tkpZRyCQ0oD5F4PoOv10YybWM0F7Jy6N+yOk/1akCTakHgyIGNX8LKt8E44Oa3ofPj4K//fUop36WfcDY7eS6dSasjmbE5msxsB7e1rsGTvRrQIDj3lt3xnTD/GTi2FRr0sXroVahja81KKeUOGlA2OXb2Al+uPsKs8FhyHIa/t63JEz0bULdyaWuDzFT4433YMBFKVYQ7voEWd+j4eUqpIkMDys1ik9L4YvUR5kbEYgzc2b4Wj/doQGilUv+30aHlsPBZOBsD7e6FPm9aIaWUUkWIBpSbxJ+9wITlB/l5azx+IgztEMKj3etTq0KeYEpJgCUvwe4foXIjGLUYat9gX9FKKWUjDSg3+PPIKZ6YvpW0zBzu7lybR7rXo3q5PGPjGQPbpsHvr0JWGvR4CW58FoqVsK9opZSymQaUi03bEMUb8/dSt3Jpfr437P/amP6SeBAWjIbo9VC7KwwcD1Ua2VGqUkp5FA0oF8nMdvDG/D3M2BRDrybBjB/WhqDAgP/bIDsD1o6DdeMgoBTc9im0uVvHz1NKqVwaUC5wOiWDx37YyuaoJB7tXp8xfRvj75en913Ueuuq6dRBaHkX9H0PylSxrV6llPJEGlCFbO+xczw0NYJTKRlMGNaGwW1q/t+bF87Astdg61QoXxvu/sl6tkkppdT/0IAqRIt3Hee5OTsIKlmMOY90oXVIeesNY2D3T7DkRUhLgq7PQPcXoXipq+5PKaWKMg2oQuBwGCasOMSEFYdoE1Keyfe0Jzgo0HrzTBQsfB4OL4ca7eDun6F6K1vrVUopb6ABdZ1SM7J5fs4Oluw5wR3tavHu31sQGOAPOdmwcSKseg/8/K15mjo8aL1WSimVLw2o6xCblMZDUyM4ePI8rwxoygM31kVEIH6LNX7eiV3QeAD0/xDK1bK7XKWU8ioaUAW0MfI0j0/fSlaOg29HdaR7oyqQcR5WvgObJ0OZqjD0B2g6yO5SlVLKK2lAFcD0TdG8/tseQiuV4ut7w6hXpQzsXwSLXoBzx6xbeb1fhcBydpeqlFJeSwPqGmTlOHhz/h5+2BhD90ZV+GR4W8plJcLsR61ZboObw13fQ0gHu0tVSimvpwHlpKTUTB6fvoWNkUk80q0eY/s2wn/LFFj+JjiyoPfrcMNT4B+Q/86UUkrlSwPKCftPnOPB7yNIOJ/BuCGtub1mMnzbF+LCoV5PGDgOKtazu0yllPIpGlD5WLrnBM/O3k6ZEsWY+0BbWh+ZBAs+sdqX/j4ZWg3RSQSVUsoFNKCuwBjDpysPM27ZQVrXKsd33VOpMK8fnDkKbUbCLe/oJIJKKeVCGlCXkZaZzZi5O1m46zh3tyzNm4FT8f9pNlSsD/+YD3W72V2iUkr5PA2oS8SdSePhqVvYdyKZb9sepkfUBCTjPHQbCzc9DwGBdpeolFJFggZUHuFRSTw6bQvVsuPZGjKLCvs2QEhnGDQBgpvYXZ5SShUpGlC5Zm6O4e3ftvNc6SXcz4/4JQfCwP9Au/t0EkGllLJBkQ+orBwH7yzYy+6Nv/N7me+plRkFzf8O/d6HstXsLk8ppYqsIh1QZ1IzGfPDGnrEfs6bJVZgStWCAXOgUV+7S1NKqSLPpQElIv2ACYA/8LUx5v1L3i8BTAXaA6eBocaYKFfW9JeDJ87xw5RP+FfGV1Qpdg66PIn0eAlKlHHH4ZVSSuXDZQElIv7AROBmIA4IF5F5xpi9eTZ7ADhjjGkgIsOAD4ChrqrpL2vDt5Gz4Dnekq2kVW6B3PEZ1Gjr6sMqpZS6Bq68guoIHDbGRAKIyCxgMJA3oAYDb+S+/hH4TETEGGNcVdTaH96m3aFP8Rc41/1Ngro9Cf5F+k6nUkp5JFd2T6sJxOZZjstdd9ltjDHZQDJQ6dIdicjDIhIhIhGJiYnXVVTFC9FElWkLT24mqOdoDSellPJQXvHpbIyZDEwGCAsLu66rq2ajPge/Yoh2HVdKKY/myk/peCAkz3Kt3HWX3UZEigHlsDpLuIwUK67hpJRSXsCVn9ThQEMRqSsixYFhwLxLtpkH/CP39Z3ASle2PymllPIeLrvFZ4zJFpEngaVY3cynGGP2iMhbQIQxZh7wDTBNRA4DSVghppRSSrm2DcoYswhYdMm61/K8TgfucmUNSimlvJM2xiillPJIGlBKKaU8kgaUUkopj6QBpZRSyiNpQCmllPJI4m2PHYlIIhB9nbupDJwqhHJ8hZ6Pi+n5uJiej4vp+bhYYZyP2saYKpeu9LqAKgwiEmGMCbO7Dk+h5+Niej4upufjYno+LubK86G3+JRSSnkkDSillFIeqagG1GS7C/Awej4upufjYno+Lqbn42IuOx9Fsg1KKaWU5yuqV1BKKaU8nAaUUkopj+TTASUi/UTkgIgcFpEXL/N+CRGZnfv+JhGpY0OZbuPE+XhORPaKyE4RWSEite2o013yOx95trtDRIyI+GzXYmfOhYgMyf3+2CMiM9xdozs58bMSKiKrRGRb7s9LfzvqdBcRmSIiCSKy+wrvi4h8knu+dopIu0I5sDHGJ/9gzUF1BKgHFAd2AM0u2eZx4Mvc18OA2XbXbfP56AmUyn39WFE/H7nblQXWABuBMLvrtvF7oyGwDaiQuxxsd902n4/JwGO5r5sBUXbX7eJz0g1oB+y+wvv9gcWAAJ2BTYVxXF++guoIHDbGRBpjMoFZwOBLthkMfJ/7+kegt4iIG2t0p3zPhzFmlTEmLXdxI1DLzTW6kzPfHwBvAx8A6e4szs2cORcPARONMWcAjDEJbq7RnZw5HwYIyn1dDjjmxvrczhizBmtS2SsZDEw1lo1AeRGpfr3H9eWAqgnE5lmOy1132W2MMdlAMlDJLdW5nzPnI68HsH4j8lX5no/c2xQhxpiF7izMBs58bzQCGonIehHZKCL93Fad+zlzPt4A7haROKxJWZ9yT2ke61o/X5zi0hl1lXcSkbuBMKC73bXYRUT8gHHAfTaX4imKYd3m64F1Zb1GRFoaY87aWZSNhgPfGWP+LSJdgGki0sIY47C7MF/iy1dQ8UBInuVauesuu42IFMO6VD/tlurcz5nzgYj0AV4GbjPGZLipNjvkdz7KAi2AP0QkCuu++jwf7SjhzPdGHDDPGJNljDkKHMQKLF/kzPl4AJgDYIzZAARiDZpaVDn1+XKtfDmgwoGGIlJXRIpjdYKYd8k284B/5L6+E1hpclv8fFC+50NE2gKTsMLJl9sYIJ/zYYxJNsZUNsbUMcbUwWqTu80YE2FPuS7lzM/Kr1hXT4hIZaxbfpFurNGdnDkfMUBvABFpihVQiW6t0rPMA+7N7c3XGUg2xhy/3p367C0+Y0y2iDwJLMXqlTPFGLNHRN4CIowx84BvsC7ND2M1AA6zr2LXcvJ8fASUAebm9hWJMcbcZlvRLuTk+SgSnDwXS4FbRGQvkAOMMcb45N0GJ8/H88BXIvIsVoeJ+3z4l1tEZCbWLyiVc9vdXgcCAIwxX2K1w/UHDgNpwKhCOa4Pn1OllFJezJdv8SmllPJiGlBKKaU8kgaUUkopj6QBpZRSyiNpQCmllPJIGlBKXQMRqSYis0TkiIhsEZFFItKoAPu5KXdU8O0iUlNEfrzCdn/46MPBSuVLA0opJ+UOJPwL8Icxpr4xpj3wElC1ALsbCbxnjGljjIk3xtxZmLUq5Qs0oJRyXk8gK/fBRACMMTuAdSLykYjsFpFdIjIUQER65F4B/Sgi+0Vkeu6T9g8CQ4C3c9fV+WueHREpmXuFtk9EfgFK/nUsEblFRDaIyFYRmSsiZXLXR4nIm7nrd4lIk9z1ZUTk29x1O0XkjqvtRylPowGllPNaAFsus/52oA3QGugDfJRnqoG2wGisOYPqAV2NMV9jDQ0zxhgz8pJ9PQakGWOaYj2t3x7+O7zQK0AfY0w7IAJ4Ls/Xncpd/wXwQu66V7GGnGlpjGkFrHRiP0p5DJ8d6kgpN7oRmGmMyQFOishqoANwDthsjIkDEJHtQB1g3VX21Q34BMAYs1NEduau74wVcutzh6EqDmzI83U/5/69BSswwQrL/w7fZYw5IyID89mPUh5DA0op5+3BGlT4WuQdET6Hgv/MCbDMGDM8n+Pkd4z89qOUx9BbfEo5byVQQkQe/muFiLQCzgJDRcRfRKpgXQVtLuAx1gAjcvfdAmiVu34j0FVEGuS+V9qJ3oPLgCfy1FqhgPtRyhYaUEo5KXe06r8DfXK7me8B3gNmADuBHVghNtYYc6KAh/kCKCMi+4C3yG3zMsYkYk2eODP3tt8GoEk++3oHqJDbeWMH0LOA+1HKFjqauVJKKY+kV1BKKaU8kgaUUkopj6QBpZRSyiNpQCmllPJIGlBKKaU8kgaUUkopj6QBpZRSyiP9f49km2JGk13SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(bin_confidences, bin_accuracies)\n",
    "plt.plot([0,1],[0,1]);\n",
    "plt.xlabel(\"Confidence\")\n",
    "plt.ylabel(\"Accuracy\");\n",
    "save(\"calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e154e186-e5f1-49ad-8666-4c3f385ee16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sUEO(ent, target):\n",
    "    numerator = 2 * torch.sum(ent * target)\n",
    "    denominator = torch.sum((target**2) + (ent**2))\n",
    "    return (numerator / denominator).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8650af30-543d-4601-8bf6-a8b774e7833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_ent_maps = [entropy_map_from_samples(samples3d[i]) for i in range(len(ys3d))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4541fd41-f635-43ce-ae8a-da9f2987db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncetainty_thresholds = torch.arange(0, 0.7, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "876dfe6d-638d-4875-9242-d5f71646a4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sUEO\n",
      "0.4403700828552246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:09<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best tau for max UEO\n",
      "tensor(0.4100)\n",
      "max UEO\n",
      "0.4076596796512604\n",
      "UEO per tau\n",
      "tensor([0.0094, 0.0550, 0.0739, 0.0917, 0.1093, 0.1269, 0.1441, 0.1611, 0.1776,\n",
      "        0.1940, 0.2101, 0.2257, 0.2407, 0.2552, 0.2691, 0.2824, 0.2950, 0.3067,\n",
      "        0.3174, 0.3274, 0.3364, 0.3445, 0.3520, 0.3590, 0.3655, 0.3710, 0.3759,\n",
      "        0.3804, 0.3844, 0.3880, 0.3913, 0.3943, 0.3971, 0.3994, 0.4016, 0.4032,\n",
      "        0.4046, 0.4058, 0.4066, 0.4076, 0.4075, 0.4077, 0.4075, 0.4069, 0.4057,\n",
      "        0.4043, 0.4027, 0.4006, 0.3984, 0.3955, 0.3923, 0.3891, 0.3848, 0.3805,\n",
      "        0.3762, 0.3704, 0.3645, 0.3570, 0.3495, 0.3411, 0.3314, 0.3204, 0.3085,\n",
      "        0.2947, 0.2789, 0.2603, 0.2385, 0.2096, 0.1679, 0.0911])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sueo_s = []\n",
    "for i in range(len(ys3d)):\n",
    "    sueo_s.append(sUEO(ind_ent_maps[i], ys3d[i]))\n",
    "\n",
    "print(f\"sUEO\")\n",
    "print(torch.mean(torch.Tensor(sueo_s)).item())\n",
    "\n",
    "# UEO = sUEO but U is thresholded binary now. We can plot it over tau, increasing in 0.05 steps\n",
    "ueos = []\n",
    "for t in tqdm(uncetainty_thresholds, position=0, leave=True):\n",
    "    t_ueos = []\n",
    "    for i in range(len(ys3d)):\n",
    "        t_ueos.append((sUEO((ind_ent_maps[i] > t).type(torch.float32), ys3d[i])))\n",
    "    ueos.append(torch.Tensor(t_ueos).mean().item())\n",
    "\n",
    "best_index = torch.Tensor(ueos).argmax()\n",
    "print(f\"best tau for max UEO\")\n",
    "print(uncetainty_thresholds[best_index])\n",
    "print(\"max UEO\")\n",
    "print(ueos[best_index])\n",
    "\n",
    "print(f\"UEO per tau\")\n",
    "print(torch.Tensor(ueos))\n",
    "\n",
    "\n",
    "plt.plot(uncetainty_thresholds, ueos)\n",
    "plt.xlabel(\"τ\")\n",
    "plt.ylabel(\"UEO\")\n",
    "save(\"UEO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc4b792a-695a-41a4-88a3-14fef6530806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sUEO\n",
      "0.444214791059494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:10<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best tau for max UEO\n",
      "tensor(0.2600)\n",
      "max UEO\n",
      "0.40380603075027466\n",
      "UEO per tau\n",
      "tensor([0.0094, 0.1583, 0.2060, 0.2393, 0.2638, 0.2828, 0.2985, 0.3118, 0.3235,\n",
      "        0.3336, 0.3428, 0.3508, 0.3580, 0.3648, 0.3707, 0.3764, 0.3816, 0.3862,\n",
      "        0.3904, 0.3940, 0.3971, 0.3996, 0.4011, 0.4025, 0.4031, 0.4035, 0.4038,\n",
      "        0.4035, 0.4035, 0.4027, 0.4020, 0.4008, 0.3998, 0.3984, 0.3969, 0.3952,\n",
      "        0.3933, 0.3910, 0.3884, 0.3860, 0.3830, 0.3797, 0.3769, 0.3735, 0.3702,\n",
      "        0.3665, 0.3626, 0.3585, 0.3540, 0.3493, 0.3442, 0.3391, 0.3334, 0.3273,\n",
      "        0.3209, 0.3139, 0.3067, 0.2983, 0.2898, 0.2817, 0.2719, 0.2614, 0.2498,\n",
      "        0.2364, 0.2223, 0.2068, 0.1870, 0.1623, 0.1273, 0.0672])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sueo_s = []\n",
    "for i in range(len(ys3d)):\n",
    "    sueo_s.append(sUEO(ind_ent_maps[i], ys3d[i]))\n",
    "\n",
    "print(f\"sUEO\")\n",
    "print(torch.mean(torch.Tensor(sueo_s)).item())\n",
    "\n",
    "# UEO = sUEO but U is thresholded binary now. We can plot it over tau, increasing in 0.05 steps\n",
    "ueos = []\n",
    "for t in tqdm(uncetainty_thresholds, position=0, leave=True):\n",
    "    t_ueos = []\n",
    "    for i in range(len(ys3d)):\n",
    "        t_ueos.append((sUEO((ind_ent_maps[i] > t).type(torch.float32), ys3d[i])))\n",
    "    ueos.append(torch.Tensor(t_ueos).mean().item())\n",
    "\n",
    "best_index = torch.Tensor(ueos).argmax()\n",
    "print(f\"best tau for max UEO\")\n",
    "print(uncetainty_thresholds[best_index])\n",
    "print(\"max UEO\")\n",
    "print(ueos[best_index])\n",
    "\n",
    "print(f\"UEO per tau\")\n",
    "print(torch.Tensor(ueos))\n",
    "\n",
    "\n",
    "plt.plot(uncetainty_thresholds, ueos)\n",
    "plt.xlabel(\"τ\")\n",
    "plt.ylabel(\"UEO\")\n",
    "save(\"UEO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffdd75-835f-42f4-af7c-5943a291db9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
