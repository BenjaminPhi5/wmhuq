{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0010851e-e752-4981-80a8-fbf27459c1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strawberry\n"
     ]
    }
   ],
   "source": [
    "print(\"strawberry\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# dataset\n",
    "from twaidata.torchdatasets.in_ram_ds import MRISegmentation2DDataset, MRISegmentation3DDataset\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "\n",
    "# model\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_deterministic import HyperMapp3r\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_DDU import HyperMapp3rDDU\n",
    "from trustworthai.models.uq_models.initial_variants.HyperMapp3r_SSN import HyperMapp3rSSN\n",
    "\n",
    "\n",
    "# augmentation and pretrain processing\n",
    "from trustworthai.utils.augmentation.standard_transforms import RandomFlip, GaussianBlur, GaussianNoise, \\\n",
    "                                                            RandomResizeCrop, RandomAffine, \\\n",
    "                                                            NormalizeImg, PairedCompose, LabelSelect, \\\n",
    "                                                            PairedCentreCrop, CropZDim\n",
    "# loss function\n",
    "from trustworthai.utils.losses_and_metrics.per_individual_losses import (\n",
    "    log_cosh_dice_loss,\n",
    "    TverskyLoss,\n",
    "    FocalTverskyLoss,\n",
    "    DiceLossMetric\n",
    ")\n",
    "from torch.nn import BCELoss, MSELoss, BCEWithLogitsLoss\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import argparse\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchmetrics import Metric\n",
    "\n",
    "def two_class_prob(p_hat):\n",
    "    p_hat = torch.nn.functional.softmax(p_hat, dim=1)\n",
    "    p_hat = p_hat[:,1,:] # select class 0\n",
    "    return p_hat\n",
    "\n",
    "def individual_dice(p_hat, y_true):\n",
    "    p_hat = two_class_prob(p_hat)\n",
    "    s0 = p_hat.shape[0]\n",
    "    p_hat = p_hat.view(s0,-1)\n",
    "    y_true = y_true.view(s0,-1)\n",
    "    numerator = torch.sum(2. * p_hat * y_true, dim=1) + 1.\n",
    "    denominator = torch.sum(y_true + p_hat, dim=1) + 1.\n",
    "    combined = 1. - (numerator/denominator)\n",
    "    return combined\n",
    "    \n",
    "def dice_loss(p_hat, y_true):\n",
    "    combined = individual_dice(p_hat, y_true)\n",
    "    \n",
    "    # is empties\n",
    "    locs = torch.sum(y_true, dim=(-2, -1)) == 0\n",
    "    wheres = torch.where(locs)[0]\n",
    "    #print(wheres.shape)\n",
    "    # print(wheres)\n",
    "    #print(combined)\n",
    "    r = 0.5\n",
    "    combined[wheres] *= r\n",
    "    #print(combined)\n",
    "    \n",
    "    return torch.sum(combined) / ((y_true.shape[0] - wheres.shape[0]) + (wheres.shape[0] * r))\n",
    "\n",
    "def dice_loss_old(p_hat, y_true):\n",
    "    combined = individual_dice(p_hat, y_true)\n",
    "    return torch.mean(combined)\n",
    "\n",
    "def construct_parser():\n",
    "    parser = argparse.ArgumentParser(description = \"train models\")\n",
    "    \n",
    "    parser.add_argument('--ckpt_dir', default=None, type=str)\n",
    "    return parser\n",
    "\n",
    "def get_transforms(is_3D):\n",
    "        transforms = [\n",
    "            LabelSelect(label_id=1),\n",
    "            RandomFlip(p=0.5, orientation=\"horizontal\"),\n",
    "            # GaussianBlur(p=0.5, kernel_size=7, sigma=(.1, 1.5)),\n",
    "            # GaussianNoise(p=0.2, mean=0, sigma=0.2),\n",
    "            # RandomAffine(p=0.2, shear=(.1,3.)),\n",
    "            # RandomAffine(p=0.2, degrees=5),\n",
    "            #RandomResizeCrop(p=1., scale=(0.6, 1.), ratio=(3./4., 4./3.))\n",
    "\n",
    "\n",
    "            RandomResizeCrop(p=1., scale=(0.3, 0.5), ratio=(3./4., 4./3.)) # ssn\n",
    "        ]\n",
    "        if not is_3D:\n",
    "            transforms.append(lambda x, y: (x, y.squeeze().type(torch.long)))\n",
    "            return PairedCompose(transforms)\n",
    "        else:\n",
    "            transforms.append(CropZDim(size=32, minimum=0, maximum=-1))\n",
    "            transforms.append(lambda x, y: (x, y.squeeze().type(torch.long)))\n",
    "            return PairedCompose(transforms)\n",
    "        \n",
    "def train_val_test_split(dataset, val_prop, test_prop, seed):\n",
    "        # I think the sklearn version might be prefereable for determinism and things\n",
    "        # but that involves fiddling with the dataset implementation I think....\n",
    "        size = len(dataset)\n",
    "        test_size = int(test_prop*size) \n",
    "        val_size = int(val_prop*size)\n",
    "        train_size = size - val_size - test_size\n",
    "        train, val, test = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(seed))\n",
    "        return train, val, test\n",
    "    \n",
    "class StandardLitModelWrapper(pl.LightningModule):\n",
    "        def __init__(self, model, loss=F.cross_entropy, logging_metric=None, optimizer_params={\"lr\":1e-3}, lr_scheduler_params={\"step_size\":30, \"gamma\":0.1}, is_uq_model=False,\n",
    "                    optimizer_constructor=None, lr_scheduler_constructor=None):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.loss = loss\n",
    "            self.logging_metric_train = logging_metric()\n",
    "            self.logging_metric_val = logging_metric()\n",
    "            self.optim_params = optimizer_params\n",
    "            self.lr_scheduler_params = lr_scheduler_params\n",
    "            self.is_uq_model = False\n",
    "            self.optimizer_constructor = optimizer_constructor\n",
    "            self.lr_scheduler_constructor = lr_scheduler_constructor\n",
    "\n",
    "\n",
    "        def forward(self, x, **kwargs):\n",
    "            return self.model(x, **kwargs)\n",
    "\n",
    "        def configure_optimizers(self):\n",
    "            # optimizer and schedulers go in the configure optimizers hook\n",
    "            if self.optimizer_constructor:\n",
    "                optimizer = self.optimizer_constructor(self.parameters(), **self.optim_params)\n",
    "            else:\n",
    "                optimizer = torch.optim.Adam(self.parameters(), **self.optim_params)\n",
    "\n",
    "            if self.lr_scheduler_constructor:\n",
    "                lr_scheduler = self.lr_scheduler_constructor(optimizer, **self.lr_scheduler_params)\n",
    "            else:\n",
    "                lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, **self.lr_scheduler_params)\n",
    "\n",
    "            return [optimizer], [lr_scheduler]\n",
    "\n",
    "        def training_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            lightning automates the training loop, \n",
    "            does epoch, back_tracking, optimizers and schedulers,\n",
    "            and metric reduction.\n",
    "            we just define how we want to process a single batch. \n",
    "            we can optionally pass optimizer_idx if we want to define multiple optimizers within the configure_optimizers\n",
    "            hook, and I presume we can add our own parameters also to functions?\n",
    "            \"\"\"\n",
    "\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(True)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            loss = self.loss(y_hat, y)\n",
    "\n",
    "            # metrics \n",
    "            if self.logging_metric_train:\n",
    "                self.logging_metric_train(y_hat, y)\n",
    "                self.log(f\"train_metric\", self.logging_metric_train, on_step=True, on_epoch=False, prog_bar=True)\n",
    "            self.log(\"train_loss\", loss)\n",
    "\n",
    "            return loss\n",
    "\n",
    "    #     def training_epoch_end(self, outs):\n",
    "    #         self.log('train_metric_epoch', self.logging_metric_train.compute())\n",
    "\n",
    "    #     def validation_epoch_end(self, outs):\n",
    "    #         self.log('val_metric_epoch', self.logging_metric_val.compute())\n",
    "\n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            note: call trainer.validate() automatically loads the best checkpoint if checkpointing was enabled during fitting\n",
    "            well yes I want to enable checkpointing but will deal with that later.\n",
    "            also it does stuff like model.eval() and torch.no_grad() automatically which is nice.\n",
    "            I will need a custom eval thing to do my dropout estimation but can solve that later too.\n",
    "            \"\"\"\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(False)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            val_loss = self.loss(y_hat, y)\n",
    "\n",
    "            if self.logging_metric_val:\n",
    "                self.logging_metric_val(y_hat, y)\n",
    "                self.log(f\"val_metric\", self.logging_metric_val, on_step=True, on_epoch=True, prog_bar=True)\n",
    "            self.log(\"val_loss\", val_loss)\n",
    "\n",
    "        def test_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            we would need to directly call this function using the trainer\n",
    "            \"\"\"\n",
    "\n",
    "            if self.is_uq_model:\n",
    "                self.model.set_applyfunc(False)\n",
    "\n",
    "            X, y = batch\n",
    "            y_hat = self(X)\n",
    "            test_loss = self.loss(y_hat, y)\n",
    "            self.log(\"test_loss\", test_loss)\n",
    "\n",
    "        def predict_step(self, batch, batch_idx):\n",
    "            \"\"\"\n",
    "            just for making predictions as opposed to collecting metrics etc\n",
    "            note to use this, we just call .predict(dataloader) and it then automates the look\n",
    "            these functions are for a single batch. Nice.\n",
    "            \"\"\"\n",
    "            X, y = batch\n",
    "            pred = self(X)\n",
    "            return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90994a20-6f26-4b70-a5b3-aa98af570fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simpleblock(ins, outs, frac=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ins, 8//frac, 3, stride=2, padding=1),\n",
    "        nn.Conv2d(8//frac, 16//frac, 3, stride=2, padding=1),\n",
    "        nn.Conv2d(16//frac, 32//frac, 3, stride=2, padding=1),\n",
    "        nn.ConvTranspose2d(32//frac,16//frac,3, stride=2, output_padding=1, padding=1),\n",
    "        nn.ConvTranspose2d(16//frac,8//frac,3, stride=2, output_padding=1, padding=1),\n",
    "        nn.ConvTranspose2d(8//frac,outs, 3, stride=2, output_padding=1, padding=1)\n",
    "    )\n",
    "\n",
    "class ENN(nn.Module):\n",
    "    def __init__(self, base_model, ensembles=2, prior_mix_ratio = 0.5, alpha = 1., mc_samples=10):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        in_channels = 3\n",
    "        out_channels = 2\n",
    "        self.learnable = get_simpleblock(in_channels + (out_channels * 2), out_channels, frac=1)\n",
    "        self.prior_fixed = get_simpleblock(in_channels + (out_channels * 2), out_channels, frac=1)\n",
    "        self.prior_ensemble = nn.ModuleList([get_simpleblock(in_channels, out_channels, frac=2) for _ in range(ensembles)])\n",
    "        self.num_ensembles = ensembles\n",
    "        self.prior_mix_ratio = prior_mix_ratio\n",
    "        self.alpha = alpha\n",
    "        self.mc_samples = mc_samples\n",
    "        assert 0 <= prior_mix_ratio <= 1\n",
    "        \n",
    "        # set prior fixed and learnable to have same initialization\n",
    "        self.prior_fixed.load_state_dict(self.learnable.state_dict())\n",
    "        \n",
    "        # set all prior models to be non trainable\n",
    "        for p in self.prior_fixed.parameters():\n",
    "            p.requires_grad = False\n",
    "        for m in self.prior_ensemble:\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        \"\"\"\n",
    "        implement the stop gradient\n",
    "        implement the loss function\n",
    "        \"\"\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        original = self.base_model(x)\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        self.base_model.eval()\n",
    "        base_learnable = self.base_model(x)\n",
    "        self.base_model.train()\n",
    "        base = base_learnable.detach()\n",
    "        \n",
    "        outs = []\n",
    "        for _ in range(self.mc_samples):\n",
    "            z = torch.randn(base.shape).to(base.device) * 1.\n",
    "            epi_learnable_input = torch.cat([base, x, z], dim=1)\n",
    "\n",
    "            learnable_out = self.learnable(epi_learnable_input)\n",
    "            prior_fixed_out = self.prior_fixed(epi_learnable_input)\n",
    "\n",
    "            prior_ensemble_out = torch.zeros(base.shape).to(base.device)\n",
    "            for i, m in enumerate(self.prior_ensemble):\n",
    "                prior_ensemble_out += m(x) * z[:,i].unsqueeze(dim=1)\n",
    "\n",
    "            #combined_out = base_learnable + learnable_out + self.alpha * ((prior_ensemble_out * self.prior_mix_ratio) + (prior_fixed_out * (1-self.prior_mix_ratio)))\n",
    "            combined_out = base + 1. * (learnable_out + self.alpha * prior_fixed_out)\n",
    "            #combined_out = base_learnable + learnable_out + self.alpha * prior_ensemble_out\n",
    "            outs.append(combined_out)\n",
    "            \n",
    "        return outs\n",
    "    \n",
    "def enn_loss(outs, target):\n",
    "    loss_sum = torch.Tensor([0.]).to(target.device)\n",
    "    for o in outs:\n",
    "        loss_sum += dice_loss(o, target)\n",
    "    return (loss_sum / len(outs))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a966b1c3-0d60-486c-89bc-65e2509f1848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8743 2497 1248\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ckpt_dir = \"nana\"\n",
    "is3D = False\n",
    "root_dir = \"/disk/scratch/s2208943/ipdis/preprep/out_data/collated/\"\n",
    "#root_dir = \"/media/benp/NVMEspare/datasets/preprocessing_attempts/local_results/collated/\"\n",
    "wmh_dir = root_dir + \"WMH_challenge_dataset/\"\n",
    "ed_dir = root_dir + \"EdData/\"\n",
    "\n",
    "domains = [\n",
    "            ed_dir + d for d in [\"domainA\", \"domainB\", \"domainC\", \"domainD\"]\n",
    "          ]\n",
    "\n",
    "test_proportion = 0.1\n",
    "validation_proportion = 0.2\n",
    "seed = 3407\n",
    "\n",
    "# load datasets\n",
    "# this step is quite slow, all the data is being loaded into memory\n",
    "if is3D:\n",
    "    datasets_domains = [MRISegmentation3DDataset(root_dir, domain, transforms=get_transforms(is_3D=True)) for domain in domains]\n",
    "else:\n",
    "    datasets_domains = [MRISegmentation2DDataset(root_dir, domain, transforms=get_transforms(is_3D=False)) for domain in domains]\n",
    "\n",
    "# split into train, val test datasets\n",
    "datasets = [train_val_test_split(dataset, validation_proportion, test_proportion, seed) for dataset in datasets_domains]\n",
    "\n",
    "# concat the train val test datsets\n",
    "train_dataset = ConcatDataset([ds[0] for ds in datasets])\n",
    "val_dataset = ConcatDataset([ds[1] for ds in datasets])\n",
    "test_dataset = ConcatDataset([ds[2] for ds in datasets])\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "# define dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 16, shuffle=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfe9e71-97b7-4051-a15c-62b0ff3527b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw = HyperMapp3r(dims=2,\n",
    "                 in_channels=3,\n",
    "                 out_channels=2,\n",
    "                 encoder_features=[16, 32, 64, 128, 256],\n",
    "                 decoder_features=[128, 64, 32, 16],\n",
    "                 softmax=False,\n",
    "                 up_res_blocks=False,\n",
    "                 block_params={\n",
    "                     \"dropout_p\":0.1,\n",
    "                     \"norm_type\":\"in\", \n",
    "                     \"dropout_both_layers\":False,\n",
    "                 })\n",
    "\n",
    "enn = ENN(model_raw)\n",
    "\n",
    "loss = enn_loss\n",
    "\n",
    "optimizer_params={\"lr\":1e-3, \"weight_decay\":1e-4}\n",
    "optimizer = torch.optim.Adam\n",
    "lr_scheduler_params={\"milestones\":[50,80], \"gamma\":0.5}\n",
    "lr_scheduler_constructor = torch.optim.lr_scheduler.MultiStepLR\n",
    "\n",
    "model = StandardLitModelWrapper(enn, loss, \n",
    "                                logging_metric=lambda : None,\n",
    "                                optimizer_params=optimizer_params,\n",
    "                                lr_scheduler_params=lr_scheduler_params,\n",
    "                                is_uq_model=False,\n",
    "                                optimizer_constructor=optimizer,\n",
    "                                lr_scheduler_constructor=lr_scheduler_constructor\n",
    "                               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500a0293-40ba-4b02-a037-5595d43f9b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "accelerator=\"gpu\"\n",
    "devices=1\n",
    "max_epochs=100\n",
    "precision = 32\n",
    "\n",
    "rootdir = \"/disk/scratch/s2208943/results/final_models/\"\n",
    "final_dir = rootdir + ckpt_dir\n",
    "checkpoint_callback = ModelCheckpoint(final_dir, save_top_k=2, monitor=\"val_loss\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=15, verbose=\"False\", mode=\"min\", check_finite=True)\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    max_epochs=max_epochs,\n",
    "    precision=precision,\n",
    "    default_root_dir=final_dir\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bee12bf-3ae3-43b2-82d1-3cf15833ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2208943/miniconda3/envs/ip/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /disk/scratch/s2208943/results/final_models/nana exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | ENN  | 2.8 M \n",
      "-------------------------------\n",
      "2.8 M     Trainable params\n",
      "18.5 K    Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.220    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdeb2aa9d374f298230d17b334a62a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2208943/miniconda3/envs/ip/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84a544-e2ce-4a7e-9be9-744d8689947a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
