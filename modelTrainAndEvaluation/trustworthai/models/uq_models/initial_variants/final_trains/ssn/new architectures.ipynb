{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c31cc8e-4ccd-4a05-a78b-79670a65e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import torchvision.transforms.functional as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e5c77e48-0d2e-4f8f-bcc4-0487fbe4e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_func(dims, transpose=False):\n",
    "    # determine convolution func\n",
    "        if dims == 2:\n",
    "            if transpose:\n",
    "                return nn.ConvTranspose2d\n",
    "            else:\n",
    "                return nn.Conv2d\n",
    "        elif dims == 3:\n",
    "            if transpose:\n",
    "                return nn.ConvTranspose3d\n",
    "            else:\n",
    "                return nn.Conv3d\n",
    "        else:\n",
    "            raise ValueError(f\"values of dims of 2 or 3 (2D or 2D conv) are supported only, not {dims}\")\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, ins, outs, kernel_size, padding='same', transpose_conv=False, dims=2, downsample=False):\n",
    "        super().__init__()\n",
    "        # define funcs to build block\n",
    "        conv_func = get_conv_func(dims, transpose_conv)\n",
    "        if dims == 2:\n",
    "            norm_func = nn.InstanceNorm2d\n",
    "            self.downs = lambda i : F.max_pool2d(i, kernel_size=2)\n",
    "        else:\n",
    "            norm_func = nn.InstanceNorm3d\n",
    "            self.downs = lambda i : F.max_pool3d(i, kernel_size=2)\n",
    "\n",
    "        self.activ = nn.ReLU() \n",
    "        self.conv1 = conv_func(ins, outs, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm1 = norm_func(outs)\n",
    "        self.conv2 = conv_func(outs, outs, kernel_size=kernel_size, padding=padding)\n",
    "        self.norm2 = norm_func(outs)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.activ(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm1(out)\n",
    "\n",
    "        out = self.activ(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            out = self.downs(out)\n",
    "\n",
    "\n",
    "        return out\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, ins, outs, padding='same'):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(ins, outs, 3, padding=padding)\n",
    "        self.conv2 = nn.Conv2d(outs, outs, 3, padding=padding)\n",
    "        self.conv3 = nn.ConvTranspose2d(outs, outs, 2, stride=2)\n",
    "        self.activ = nn.ReLU()\n",
    "        self.norm1 = nn.InstanceNorm2d(outs)\n",
    "        self.norm2 = nn.InstanceNorm2d(outs)\n",
    "        self.norm3 = nn.InstanceNorm3d(outs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.activ(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.activ(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.norm3(out)\n",
    "        out = self.activ(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class SysuModel(nn.Module):\n",
    "    def __init__(self, encoder_sizes=[64, 96, 128, 256, 512], in_channels=3, out_channels=2):\n",
    "        super().__init__()\n",
    "        s = len(encoder_sizes) - 1\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [Block(in_channels, encoder_sizes[0], 5, downsample=True)] + [Block(encoder_sizes[i], encoder_sizes[i+1], 3, downsample=True) for i in range(0, s-1)]\n",
    "        )\n",
    "        # print(len(self.encoder_blocks))\n",
    "        \n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "            [UpBlock(encoder_sizes[-2], encoder_sizes[-1])]\n",
    "            + [UpBlock(encoder_sizes[s-i] + encoder_sizes[s-i-1], encoder_sizes[s-i-1]) for i in range(0, s-1)]\n",
    "        )\n",
    "        # print([(encoder_sizes[s-i] + encoder_sizes[s-i-1], encoder_sizes[s-i-1]) for i in range(0, s-1)])\n",
    "        \n",
    "        self.end_block = Block(encoder_sizes[0] + encoder_sizes[1], encoder_sizes[0], 3)\n",
    "        self.final = nn.Conv2d(encoder_sizes[0], out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_dim = x.shape[-2:]\n",
    "        \n",
    "        skips = []\n",
    "        out = x\n",
    "        for block in self.encoder_blocks:\n",
    "            # print(out.shape)\n",
    "            out = block(out)\n",
    "            skips.append(out)\n",
    "            \n",
    "        \n",
    "        for block in self.decoder_blocks:\n",
    "            # print(out.shape)\n",
    "            out = block(out)\n",
    "            sk = skips.pop()\n",
    "            sk = transforms.center_crop(sk, out.shape[-2:])\n",
    "            out = torch.cat([out, sk], dim=1)\n",
    "        \n",
    "        out = self.end_block(out)\n",
    "        \n",
    "        out_dim = out.shape[-2:]\n",
    "        padx = int((input_dim[0] - out_dim[0]) / 2)\n",
    "        pady = int((input_dim[1] - out_dim[1]) / 2)\n",
    "        \n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = F.pad(out, (padx, padx, pady, pady))\n",
    "        \n",
    "        out = self.final(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a6cf8efb-1871-4106-a64b-3accba41f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SysuModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1c4555ef-1a2d-41ae-b4ef-f04e35a44690",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(12, 3, 224, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "14ac1dfa-6432-462e-81b1-11b5601fad41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2, 224, 160])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7db514d8-5bd2-4b11-ab0e-b27a18e70fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SysuModel                                --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─Block: 2-1                        [12, 64, 112, 80]         --\n",
       "│    │    └─Conv2d: 3-1                  [12, 64, 224, 160]        4,864\n",
       "│    │    └─InstanceNorm2d: 3-2          [12, 64, 224, 160]        --\n",
       "│    │    └─ReLU: 3-3                    [12, 64, 224, 160]        --\n",
       "│    │    └─Conv2d: 3-4                  [12, 64, 224, 160]        102,464\n",
       "│    │    └─InstanceNorm2d: 3-5          [12, 64, 224, 160]        --\n",
       "│    │    └─ReLU: 3-6                    [12, 64, 224, 160]        --\n",
       "│    └─Block: 2-2                        [12, 96, 56, 40]          --\n",
       "│    │    └─Conv2d: 3-7                  [12, 96, 112, 80]         55,392\n",
       "│    │    └─InstanceNorm2d: 3-8          [12, 96, 112, 80]         --\n",
       "│    │    └─ReLU: 3-9                    [12, 96, 112, 80]         --\n",
       "│    │    └─Conv2d: 3-10                 [12, 96, 112, 80]         83,040\n",
       "│    │    └─InstanceNorm2d: 3-11         [12, 96, 112, 80]         --\n",
       "│    │    └─ReLU: 3-12                   [12, 96, 112, 80]         --\n",
       "│    └─Block: 2-3                        [12, 128, 28, 20]         --\n",
       "│    │    └─Conv2d: 3-13                 [12, 128, 56, 40]         110,720\n",
       "│    │    └─InstanceNorm2d: 3-14         [12, 128, 56, 40]         --\n",
       "│    │    └─ReLU: 3-15                   [12, 128, 56, 40]         --\n",
       "│    │    └─Conv2d: 3-16                 [12, 128, 56, 40]         147,584\n",
       "│    │    └─InstanceNorm2d: 3-17         [12, 128, 56, 40]         --\n",
       "│    │    └─ReLU: 3-18                   [12, 128, 56, 40]         --\n",
       "│    └─Block: 2-4                        [12, 256, 14, 10]         --\n",
       "│    │    └─Conv2d: 3-19                 [12, 256, 28, 20]         295,168\n",
       "│    │    └─InstanceNorm2d: 3-20         [12, 256, 28, 20]         --\n",
       "│    │    └─ReLU: 3-21                   [12, 256, 28, 20]         --\n",
       "│    │    └─Conv2d: 3-22                 [12, 256, 28, 20]         590,080\n",
       "│    │    └─InstanceNorm2d: 3-23         [12, 256, 28, 20]         --\n",
       "│    │    └─ReLU: 3-24                   [12, 256, 28, 20]         --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─UpBlock: 2-5                      [12, 512, 28, 20]         --\n",
       "│    │    └─Conv2d: 3-25                 [12, 512, 14, 10]         1,180,160\n",
       "│    │    └─InstanceNorm2d: 3-26         [12, 512, 14, 10]         --\n",
       "│    │    └─ReLU: 3-27                   [12, 512, 14, 10]         --\n",
       "│    │    └─Conv2d: 3-28                 [12, 512, 14, 10]         2,359,808\n",
       "│    │    └─InstanceNorm2d: 3-29         [12, 512, 14, 10]         --\n",
       "│    │    └─ReLU: 3-30                   [12, 512, 14, 10]         --\n",
       "│    │    └─ConvTranspose2d: 3-31        [12, 512, 28, 20]         1,049,088\n",
       "│    │    └─InstanceNorm3d: 3-32         [12, 512, 28, 20]         --\n",
       "│    │    └─ReLU: 3-33                   [12, 512, 28, 20]         --\n",
       "│    └─UpBlock: 2-6                      [12, 256, 56, 40]         --\n",
       "│    │    └─Conv2d: 3-34                 [12, 256, 28, 20]         1,769,728\n",
       "│    │    └─InstanceNorm2d: 3-35         [12, 256, 28, 20]         --\n",
       "│    │    └─ReLU: 3-36                   [12, 256, 28, 20]         --\n",
       "│    │    └─Conv2d: 3-37                 [12, 256, 28, 20]         590,080\n",
       "│    │    └─InstanceNorm2d: 3-38         [12, 256, 28, 20]         --\n",
       "│    │    └─ReLU: 3-39                   [12, 256, 28, 20]         --\n",
       "│    │    └─ConvTranspose2d: 3-40        [12, 256, 56, 40]         262,400\n",
       "│    │    └─InstanceNorm3d: 3-41         [12, 256, 56, 40]         --\n",
       "│    │    └─ReLU: 3-42                   [12, 256, 56, 40]         --\n",
       "│    └─UpBlock: 2-7                      [12, 128, 112, 80]        --\n",
       "│    │    └─Conv2d: 3-43                 [12, 128, 56, 40]         442,496\n",
       "│    │    └─InstanceNorm2d: 3-44         [12, 128, 56, 40]         --\n",
       "│    │    └─ReLU: 3-45                   [12, 128, 56, 40]         --\n",
       "│    │    └─Conv2d: 3-46                 [12, 128, 56, 40]         147,584\n",
       "│    │    └─InstanceNorm2d: 3-47         [12, 128, 56, 40]         --\n",
       "│    │    └─ReLU: 3-48                   [12, 128, 56, 40]         --\n",
       "│    │    └─ConvTranspose2d: 3-49        [12, 128, 112, 80]        65,664\n",
       "│    │    └─InstanceNorm3d: 3-50         [12, 128, 112, 80]        --\n",
       "│    │    └─ReLU: 3-51                   [12, 128, 112, 80]        --\n",
       "│    └─UpBlock: 2-8                      [12, 96, 224, 160]        --\n",
       "│    │    └─Conv2d: 3-52                 [12, 96, 112, 80]         193,632\n",
       "│    │    └─InstanceNorm2d: 3-53         [12, 96, 112, 80]         --\n",
       "│    │    └─ReLU: 3-54                   [12, 96, 112, 80]         --\n",
       "│    │    └─Conv2d: 3-55                 [12, 96, 112, 80]         83,040\n",
       "│    │    └─InstanceNorm2d: 3-56         [12, 96, 112, 80]         --\n",
       "│    │    └─ReLU: 3-57                   [12, 96, 112, 80]         --\n",
       "│    │    └─ConvTranspose2d: 3-58        [12, 96, 224, 160]        36,960\n",
       "│    │    └─InstanceNorm3d: 3-59         [12, 96, 224, 160]        --\n",
       "│    │    └─ReLU: 3-60                   [12, 96, 224, 160]        --\n",
       "├─Block: 1-3                             [12, 64, 224, 160]        --\n",
       "│    └─Conv2d: 2-9                       [12, 64, 224, 160]        92,224\n",
       "│    └─InstanceNorm2d: 2-10              [12, 64, 224, 160]        --\n",
       "│    └─ReLU: 2-11                        [12, 64, 224, 160]        --\n",
       "│    └─Conv2d: 2-12                      [12, 64, 224, 160]        36,928\n",
       "│    └─InstanceNorm2d: 2-13              [12, 64, 224, 160]        --\n",
       "│    └─ReLU: 2-14                        [12, 64, 224, 160]        --\n",
       "├─Conv2d: 1-4                            [12, 2, 224, 160]         130\n",
       "==========================================================================================\n",
       "Total params: 9,699,234\n",
       "Trainable params: 9,699,234\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 234.01\n",
       "==========================================================================================\n",
       "Input size (MB): 5.16\n",
       "Forward/backward pass size (MB): 1919.88\n",
       "Params size (MB): 38.80\n",
       "Estimated Total Size (MB): 1963.84\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(m, (12, 3, 224,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba019d-3973-42cc-9754-8f0483d4e26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
