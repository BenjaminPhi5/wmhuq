{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102bb967-4625-4412-9db3-655617eed515",
   "metadata": {},
   "source": [
    "### plotting cc statistics and other misc issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4981f041-4b5e-4980-b7bc-de44e5850a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7800530d-4781-4f63-813f-f08de795fa32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99954e98-4574-47b5-8e73-c5ac497cd991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strawberry\n",
      "banana\n"
     ]
    }
   ],
   "source": [
    "print(\"strawberry\")\n",
    "\n",
    "# loss function and metrics\n",
    "from trustworthai.utils.losses_and_metrics.dice_loss import DiceLossWithWeightedEmptySlices\n",
    "from trustworthai.utils.losses_and_metrics.dice_loss_metric import DiceLossMetric, SsnDiceMeanMetricWrapper\n",
    "\n",
    "# predefined training dataset\n",
    "from trustworthai.utils.data_preprep.dataset_pipelines import load_data\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from trustworthai.utils.fitting_and_inference.fitters.p_unet_fitter import PUNetLitModelWrapper\n",
    "from trustworthai.utils.fitting_and_inference.get_trainer import get_trainer\n",
    "\n",
    "# model\n",
    "from trustworthai.journal_run.model_load.load_ssn import load_ssn\n",
    "from trustworthai.journal_run.model_load.load_punet import load_p_unet\n",
    "from trustworthai.journal_run.model_load.load_deterministic import load_deterministic\n",
    "from trustworthai.journal_run.model_load.load_evidential import load_evidential\n",
    "from trustworthai.models.stochastic_wrappers.ssn.LowRankMVCustom import LowRankMultivariateNormalCustom\n",
    "from trustworthai.models.stochastic_wrappers.ssn.ReshapedDistribution import ReshapedDistribution\n",
    "\n",
    "# optimizer and lr scheduler\n",
    "import torch\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "from trustworthai.utils.plotting.saving_plots import save, imsave\n",
    "from trustworthai.utils.print_and_write_func import print_and_write\n",
    "\n",
    "# misc\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import shlex\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "\n",
    "import pandas as pd\n",
    "from trustworthai.analysis.connected_components.connected_comps_2d import conn_comp_2d_analysis\n",
    "from trustworthai.analysis.evaluation_metrics.challenge_metrics import getAVD, getDSC, getHausdorff, getLesionDetection, do_challenge_metrics\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from trustworthai.utils.plotting.saving_plots import save\n",
    "from trustworthai.utils.print_and_write_func import print_and_write\n",
    "from trustworthai.analysis.calibration.helper_funcs import *\n",
    "from tqdm import tqdm\n",
    "from trustworthai.utils.logits_to_preds import normalize_samples\n",
    "\n",
    "# data\n",
    "from trustworthai.utils.data_preprep.dataset_pipelines import load_clinscores_data, load_data, ClinScoreDataRetriever\n",
    "from trustworthai.utils.uncertainty_maps.entropy_map import entropy_map_from_samples\n",
    "\n",
    "\n",
    "# evaluation code\n",
    "from trustworthai.journal_run.evaluation.new_scripts.eval_helper_functions import *\n",
    "from trustworthai.journal_run.evaluation.new_scripts.model_predictions import *\n",
    "from trustworthai.analysis.connected_components.connected_comps_2d import *\n",
    "print(\"banana\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec3f2d0b-1048-4f17-806a-24922861d152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5aaeef-6f46-4a31-b88c-e860925b5f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import proplot as pplt\n",
    "from trustworthai.utils.uncertainty_maps.entropy_map import entropy_map_from_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1764b2c-5348-41d8-91e6-9b345c8e7582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569ca0bb-880f-49d8-99fc-689a9db07e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from twaidata.torchdatasets_v2.individual_dataset_wrappers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8c1588b-0126-4401-976b-0e00f1d71ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOXELS_TO_WMH_RATIO = 382\n",
    "VOXELS_TO_WMH_RATIO_EXCLUDING_EMPTY_SLICES = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "315f9047-81d3-46fa-bbd8-186f14efeb29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    def __init__(self):\n",
    "    \n",
    "        # folder arguments\n",
    "        self.ckpt_dir = '/home/s2208943/ipdis/results/journal_models/cross_validated_models/'\n",
    "        self.model_name = \"ssn_ens0_cv0\"\n",
    "        self.model_ckpts_folder = \"/home/s2208943/ipdis/results/journal_models/cross_validated_models/\" # \"/home/s2208943/ipdis/results/cross_validated_models/\"\n",
    "        self.repo_dir = \"/home/s2208943/ipdis/WMH_UQ_assessment\"\n",
    "        self.result_dir = \"trustworthai/journal_run/interrater_experiments/results/\"\n",
    "        self.model_type = \"ssn\"\n",
    "        self.uncertainty_type = \"ssn\"\n",
    "        \n",
    "        # data generation arguments\n",
    "        self.dataset = 'chal'\n",
    "        self.seed = 3407\n",
    "        self.test_split = 0.15\n",
    "        self.val_split = 0.15\n",
    "        self.empty_slice_retention = 0.1\n",
    "        \n",
    "        # general arguments for the loss function\n",
    "        self.loss_name = 'dice+xent'#'dicev2'#'dice+xent'\n",
    "        self.dice_factor = 1#5\n",
    "        self.xent_factor = 1#0.01\n",
    "        self.xent_weight = 'none'\n",
    "        self.xent_reweighting=1\n",
    "        self.dice_empty_slice_weight = 0.5\n",
    "        self.tversky_beta = 0.7\n",
    "        self.reduction = 'mean'#'mean_sum'\n",
    "        \n",
    "        # evidential arguments\n",
    "        self.kl_factor=0.1\n",
    "        self.kl_anneal_count=452*4\n",
    "        self.use_mle=0\n",
    "        self.analytic_kl=0\n",
    "\n",
    "        # p-unet arguments\n",
    "        self.kl_beta=10.\n",
    "        self.use_prior_for_dice=\"false\"\n",
    "        self.punet_sample_dice_coeff=0.05\n",
    "        self.latent_dim=12\n",
    "\n",
    "        # ssn arguments\n",
    "        self.ssn_rank=25\n",
    "        self.ssn_epsilon=1e-5\n",
    "        self.ssn_mc_samples=10\n",
    "        self.ssn_sample_dice_coeff=0.05\n",
    "        self.ssn_pre_head_layers=32\n",
    "        \n",
    "        # training paradigm arguments\n",
    "        self.lr = 2e-4\n",
    "        self.dropout_p = 0.1\n",
    "        self.encoder_dropout1 = 0\n",
    "        self.encoder_dropout2 = 0\n",
    "        self.decoder_dropout1 = 0\n",
    "        self.decoder_dropout2 = 0\n",
    "        self.max_epochs = 100\n",
    "        self.early_stop_patience = 15\n",
    "        self.batch_size = 8#32\n",
    "        self.cross_validate = \"true\"\n",
    "        self.cv_split = 0\n",
    "        self.cv_test_fold_smooth = 1\n",
    "        self.weight_decay = 0.0001\n",
    "        self.overwrite = \"true\"\n",
    "        self.no_test_fold = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30e24919-ad0a-46bb-8d81-d5cb9227d9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKPOINT DIR: /home/s2208943/ipdis/results/journal_models/cross_validated_models/\n"
     ]
    }
   ],
   "source": [
    "args = ARGS()\n",
    "\n",
    "# sanitise arguments\n",
    "args.overwrite = True if args.overwrite.lower() == \"true\" else False\n",
    "args.cross_validate = True if args.cross_validate.lower() == \"true\" else False\n",
    "args.use_prior_for_dice = True if args.use_prior_for_dice.lower() == \"true\" else False\n",
    "print(f\"CHECKPOINT DIR: {args.ckpt_dir}\")\n",
    "#print(args)\n",
    "\n",
    "\n",
    "# check if folder exists\n",
    "model_result_folder = os.path.join(args.repo_dir, args.result_dir)\n",
    "if not args.overwrite:\n",
    "    existing_files = os.listdir(model_result_folder)\n",
    "    for f in existing_files:\n",
    "        if args.model_name + \"_\" in f:\n",
    "            raise ValueError(f\"ovewrite = false and model results exist! folder={model_result_folder}, model_name={args.model_name}\")\n",
    "with open(os.path.join(model_result_folder, f\"{args.model_name}_init.txt\"), \"w\") as f:\n",
    "                      f.write(\"generating results\\n\")\n",
    "        \n",
    "# setup xent reweighting factor\n",
    "XENT_VOXEL_RESCALE = VOXELS_TO_WMH_RATIO - (1-args.empty_slice_retention) * (VOXELS_TO_WMH_RATIO - VOXELS_TO_WMH_RATIO_EXCLUDING_EMPTY_SLICES)\n",
    "\n",
    "XENT_WEIGHTING = XENT_VOXEL_RESCALE/2\n",
    "args.xent_reweighting = XENT_WEIGHTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2c4bef-2034-4649-aa5b-a7ceb5ff45c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_LOADERS = {\n",
    "    \"deterministic\":load_deterministic,\n",
    "    \"mc_drop\":load_deterministic,\n",
    "    \"evidential\":load_evidential,\n",
    "    \"ssn\":load_ssn,\n",
    "    \"punet\":load_p_unet,\n",
    "}\n",
    "\n",
    "MODEL_OUTPUT_GENERATORS = {\n",
    "    \"deterministic\":mc_drop_mean_and_samples,\n",
    "    \"mc_drop\":mc_drop_mean_and_samples,\n",
    "    \"evidential\":evid_mean,\n",
    "    \"ssn\":ssn_mean_and_samples,\n",
    "    \"punet\":punet_mean_and_samples,\n",
    "    \"ind\":ssn_mean_and_samples,\n",
    "    \"ens\":ensemble_mean_and_samples,\n",
    "    \"ssn_ens\":ssn_ensemble_mean_and_samples,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00558556-8dfd-42fc-acc6-f49fd4fe49ac",
   "metadata": {},
   "source": [
    "### setting up model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ab784d-ddb6-451d-b6a8-9f217f1e2b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the 3d dataloader\n",
    "ds_name = \"mss3\"\n",
    "mss3_ds = MSS3InterRaterDataset()#WMHChallengeInterRaterDataset()#LBCInterRaterDataset()#MSS3InterRaterDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4675ba7b-e3b6-4713-80ae-71a42d02783b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mss3_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15a77f66-2d91-43db-a424-2a65040bbbba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, ys, ind, _ = mss3_ds[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6935545-1eee-4a06-92c3-eeeba6919c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['FLAIR', 'T1', 'mask', 'vent_distance'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f711e95b-7d7c-4855-a1ce-d94ea38d9e26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSS3_ED_003_V1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "439046b4-bdbf-4712-92ee-c9bffb0d1767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['FLAIR', 'T1', 'mask', 'vent_distance']),\n",
       " dict_keys(['lacune', 'wmhes', 'wmhmvh']))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.keys(), ys.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ea9642-8a74-4269-8248-e0d9138a9bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53, 240, 240])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs['mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73f6895b-0582-4bf6-ab94-eda22ea3a9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uncertainty_thresholds = torch.arange(0, 0.7, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0594338-aa9f-4a00-9243-ceddb5863229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dir:  /home/s2208943/ipdis/results/journal_models/cross_validated_models/ssn_ens0_cv0\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model_dir = os.path.join(args.ckpt_dir, args.model_name)  \n",
    "print(\"model dir: \", model_dir)\n",
    "model_raw, loss, val_loss = MODEL_LOADERS[args.model_type](args)\n",
    "model = load_best_checkpoint(model_raw, loss, model_dir, punet=args.model_type == \"punet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bed43b00-18a0-4750-8e02-a16ccfaca543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 60/68 [00:21<00:02,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                    | 61/68 [00:21<00:02,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 63/68 [00:22<00:01,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏           | 64/68 [00:22<00:01,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:24<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "xs3d_test = []\n",
    "ys3d_test = []\n",
    "inds_test = []\n",
    "pv_region_masks = []\n",
    "\n",
    "if ds_name == \"mss3\":\n",
    "    r0_id = \"wmhes\"\n",
    "    r1_id = \"wmhmvh\"\n",
    "    ds_ir_folder = \"MSS3_InterRaterData\"\n",
    "elif ds_name == \"lbc\":\n",
    "    r0_id = \"wmh\"\n",
    "    r1_id = \"wmh_flthresh\"\n",
    "    ds_ir_folder = \"LBC_InterRaterData\"\n",
    "elif ds_name == \"challenge\":\n",
    "    r0_id = \"wmho3\"\n",
    "    r1_id = \"wmho4\"\n",
    "    ds_ir_folder = \"WMHChallenge_InterRaterData\"\n",
    "\n",
    "\n",
    "for (xs, ys, ind, _) in tqdm(mss3_ds):\n",
    "    if ind in ['MSS3_ED_073_V1', 'MSS3_ED_075_V1', 'MSS3_ED_078_V1', 'MSS3_ED_079_V1']:\n",
    "        print(\"found\")\n",
    "        continue\n",
    "    if r0_id in ys.keys() and r1_id in ys.keys():\n",
    "        try:\n",
    "            x = torch.stack([xs['FLAIR'], xs['T1'], xs['mask']], dim=0)\n",
    "            y = torch.stack([ys[r0_id], ys[r1_id]], dim=0)\n",
    "\n",
    "            vent_distance_map = xs['vent_distance']\n",
    "        except:\n",
    "            print(f\"failed for {ind}\")\n",
    "            continue\n",
    "\n",
    "        xs3d_test.append(x)\n",
    "        ys3d_test.append(y)\n",
    "        inds_test.append(ind)\n",
    "        pv_region_masks.append((vent_distance_map < 10).type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55bf4120-daac-4895-96c3-fcdef6f6f0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rater0 = [y[0] for y in ys3d_test]\n",
    "rater1 = [y[1] for y in ys3d_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95911463-531a-4266-bd54-ed9b6ce9ad08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rater_union = [y[0] * y[1] for y in ys3d_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fff9600c-cb49-45f1-8354-4e699652687c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rater0_ds = list(zip(xs3d_test, rater0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "187f87c5-8471-4d17-85fb-bd69d7d9f392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ea7674f-bc5e-4e35-b921-8d6f179f1c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_vols = [(torch.sum(y[0]).item(), torch.sum(y[1]).item()) for y in ys3d_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40b5538b-b728-44cc-9227-514f6d2b1ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_gt_vols = [(torch.sum(y[0]).item() + torch.sum(y[1]).item())/2 for y in ys3d_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2ed8665-b08a-4b35-a5d8-fdaff37e2fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "print(len(mean_gt_vols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e656c71-40f5-420f-8070-052392c6d5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soft_dice(pred, target):\n",
    "    \n",
    "    numerator = 2 * (pred * target).sum()\n",
    "    denominator = (target**2).sum() + (pred**2).sum()\n",
    "    \n",
    "    return (numerator / denominator).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "802a74c0-4e7b-4145-a2a1-0fe9421b3258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_iou(pred, target):\n",
    "    p1 = (pred == 1)\n",
    "    t1 = (target == 1)\n",
    "    intersection = (pred == 1) & (target == 1)\n",
    "    numerator = intersection.sum()\n",
    "    denominator = p1.sum() + t1.sum() - numerator\n",
    "    return (numerator/(denominator + 1e-30)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98f2ab36-1ade-4892-9b43-6ef2ca8f98a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM SAMPLES:  10\n",
      "GENERATING PREDICTIONS\n",
      "ssn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                  | 0/61 [00:00<?, ?it/s]/home/s2208943/miniconda3/envs/wmh/lib/python3.10/site-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(f\"input's size at dim={feature_dim} does not match num_features. \"\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:30<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssn\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 61/61 [00:06<00:00,  9.94it/s]\n"
     ]
    }
   ],
   "source": [
    "raters = [rater0, rater1]\n",
    "rater_results = [defaultdict(lambda : {}) for _ in range(len(raters))]\n",
    "\n",
    "num_samples_list = [2, 3, 5, 7, 10, 15, 20, 25, 30]\n",
    "num_samples = 10\n",
    "print(\"NUM SAMPLES: \", num_samples)\n",
    "args.eval_sample_num = num_samples\n",
    "\n",
    "# load the predictions\n",
    "print(\"GENERATING PREDICTIONS\")\n",
    "print(args.uncertainty_type)\n",
    "means, samples, misc = get_means_and_samples(model_raw, rater0_ds, num_samples=num_samples, model_func=MODEL_OUTPUT_GENERATORS[args.uncertainty_type], args=args)\n",
    "\n",
    "uncertainty_thresholds = torch.arange(0, 0.7, 0.01)\n",
    "ent_maps = get_uncertainty_maps(means, samples, misc, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4aa62ea7-b237-4406-91a7-d16e5e20617f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rater0_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaf470b8-6938-4534-9b70-c2a734d35e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aae9e581-f37a-4bc6-9f8e-11cba4324cae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cc3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "182924b9-5e13-4e10-af1b-7557c498095e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_non_overlapping_ccs(ccs_y0, y1):\n",
    "    no_overlap_ccs = []\n",
    "    ccs_size = []\n",
    "    no_overlap_ccs_img = torch.zeros(y1.shape, device=y1.device, dtype=y1.dtype)\n",
    "    \n",
    "    for cc_id in ccs_y0.unique():\n",
    "        if cc_id == 0:\n",
    "            continue\n",
    "        cc = ccs_y0 == cc_id\n",
    "        if (cc * y1).sum() == 0:\n",
    "            no_overlap_ccs.append(int(cc_id.item()))\n",
    "            ccs_size.append(cc.sum().item())\n",
    "            no_overlap_ccs_img += cc\n",
    "    \n",
    "    return no_overlap_ccs, ccs_size, no_overlap_ccs_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b5fba0d-faf1-41a2-badc-0086abed2bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_ccids_with_0IOU(ccs_y0, ccs_y1, y0, y1):\n",
    "    y0_ccids = ccs_y0.unique().type(torch.int32).tolist()\n",
    "    y1_ccids = ccs_y1.unique().type(torch.int32).tolist()\n",
    "    y0_ccids.remove(0)\n",
    "    y1_ccids.remove(0)\n",
    "    zero_overlap_y0 = []\n",
    "    zero_overlap_y1 = []\n",
    "    for cc_id in y0_ccids:\n",
    "        cc = ccs_y0 == cc_id\n",
    "        if (cc * y1).sum() == 0:\n",
    "            zero_overlap_y0.append(cc_id)\n",
    "    for cc_id in y1_ccids:\n",
    "        if cc_id == 0:\n",
    "            continue\n",
    "        cc = ccs_y1 == cc_id\n",
    "        if (cc * y0).sum() == 0:\n",
    "            zero_overlap_y1.append(cc_id)\n",
    "    for cc_id in zero_overlap_y0:\n",
    "        y0_ccids.remove(cc_id)\n",
    "    for cc_id in zero_overlap_y1:\n",
    "        y1_ccids.remove(cc_id)\n",
    "        \n",
    "    return y0_ccids, y1_ccids\n",
    "\n",
    "def find_ious_between_raters(ccs_y0, ccs_y1, y0, y1):\n",
    "    \n",
    "    # first narrow down the list to all the connected components that do not have zero overlap\n",
    "    y0_ccids, y1_ccids = remove_ccids_with_0IOU(ccs_y0, ccs_y1, y0, y1)\n",
    "    \n",
    "    # loop through ccs to find the one with the highest iou\n",
    "    cc_ious = []\n",
    "    ccs_y1_match = []\n",
    "    sizes = []\n",
    "    match_sizes = []\n",
    "    for cc_id0 in y0_ccids:\n",
    "        cc0 = ccs_y0 == cc_id0\n",
    "        cc0_sum = cc0.sum().item()\n",
    "        best_iou = 0\n",
    "        best_iou_cc_id = None\n",
    "        match_size = None\n",
    "        for cc_id1 in y1_ccids:\n",
    "            cc1 = ccs_y1 == cc_id1\n",
    "            iou = (cc0 & cc1).sum() / ((cc1 + cc0) > 0).sum()\n",
    "            iou = iou.item()\n",
    "            if iou >= best_iou:\n",
    "                best_iou = iou\n",
    "                best_iou_cc_id = cc_id1\n",
    "                match_size = cc1.sum().item()\n",
    "        # print(best_iou_cc_id)\n",
    "        # y1_ccids.remove(best_iou_cc_id)\n",
    "        cc_ious.append(best_iou)\n",
    "        ccs_y1_match.append(best_iou_cc_id)\n",
    "        sizes.append(cc0_sum)\n",
    "        match_sizes.append(match_size)\n",
    "        \n",
    "    return cc_ious, y0_ccids, ccs_y1_match, sizes, match_sizes\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8418c2c-200f-47a0-9ce5-ef6fa0d77d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_overlap_image(y0_cc_ids, y1_cc_ids, y0_ccs, y1_ccs):\n",
    "    overlap_ccs_img = torch.zeros(y1_ccs.shape, device=y1_ccs.device, dtype=y1_ccs.dtype)\n",
    "    for cc_id in y0_cc_ids:\n",
    "        cc = y0_ccs == cc_id\n",
    "        overlap_ccs_img[cc] = 1\n",
    "    if y1_cc_ids is not None:\n",
    "        for cc_id in y1_cc_ids:\n",
    "            cc = y1_ccs == cc_id\n",
    "            overlap_ccs_img[cc] = 1\n",
    "        \n",
    "    return overlap_ccs_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27516284-5c9c-4f27-ade0-759a775cd571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_edt\n",
    "import SimpleITK as sitk\n",
    "from twaidata.MRI_preprep.resample import get_resampled_img\n",
    "\n",
    "def get_distance_map(img, rescale_ratio=3):\n",
    "    \n",
    "    # resample to 1x1x1 space\n",
    "    device = img.device\n",
    "    img = img.type(torch.float32)\n",
    "    img = torch.nn.functional.interpolate(img.unsqueeze(0).unsqueeze(0), size=None, scale_factor=(rescale_ratio, 1, 1), mode='nearest', align_corners=None, recompute_scale_factor=None, antialias=False)\n",
    "    img = img.squeeze().cpu().numpy()\n",
    "    \n",
    "    # compute distance map\n",
    "    distance_map = distance_transform_edt(1 - img)\n",
    "    \n",
    "    # resample back to original space\n",
    "    distance_map = torch.from_numpy(distance_map).to(device)\n",
    "    distance_map = torch.nn.functional.interpolate(distance_map.unsqueeze(0).unsqueeze(0), size=None, scale_factor=(1/rescale_ratio, 1, 1), mode='trilinear', align_corners=None, recompute_scale_factor=None, antialias=False)\n",
    "    distance_map = distance_map.squeeze()\n",
    "    \n",
    "    return distance_map\n",
    "\n",
    "\n",
    "# ### UIRO per region analysis.\n",
    "\n",
    "# no_overlap_distance_map = get_distance_map(combined_no_overlap_image)\n",
    "# low_overlap_distance_map = get_distance_map(combined_low_overlap_diff_image)\n",
    "# high_overlap_distance_map = get_distance_map(combined_high_overlap_diff_image)\n",
    "\n",
    "### split it into pv and deep\n",
    "\n",
    "\n",
    "## do whole image UIRO and JUEO in pv region and deep region. that can go along with the other analysis. Nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bd834ed-23fd-4137-9cdd-f8df6b990c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def IOU_region_UIRO(ent, rater_diff, no_overlap_distance_map, low_overlap_distance_map, high_overlap_distance_map):\n",
    "        uiro_no_overlap = []\n",
    "        uiro_low_overlap = []\n",
    "        uiro_high_overlap = []\n",
    "        \n",
    "        d = 5\n",
    "        no_exclusion_region = (no_overlap_distance_map < d) * (low_overlap_distance_map > d) * (high_overlap_distance_map > d)\n",
    "        low_exclusion_region = (no_overlap_distance_map > d) * (low_overlap_distance_map < d) * (high_overlap_distance_map > d)\n",
    "        high_exclusion_region = (no_overlap_distance_map > d) * (low_overlap_distance_map > d) * (high_overlap_distance_map < d)\n",
    "        \n",
    "        for t in uncertainty_thresholds:\n",
    "            e = ent > t\n",
    "            uiro_no_overlap.append(fast_dice(e * no_exclusion_region, rater_diff * no_exclusion_region))\n",
    "            uiro_low_overlap.append(fast_dice(e * low_exclusion_region, rater_diff * low_exclusion_region))\n",
    "            uiro_high_overlap.append(fast_dice(e * high_exclusion_region, rater_diff * high_exclusion_region))\n",
    "        \n",
    "        \n",
    "        return uiro_no_overlap, uiro_low_overlap, uiro_high_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8339bdb-ad5e-4e25-9842-09c8b1b7aea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## run cc analysis across the whole image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704207fb-2c66-45f2-968e-21edf6135de6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                    | 50/61 [03:31<00:42,  3.86s/it]"
     ]
    }
   ],
   "source": [
    "all_sizes = []\n",
    "all_ious = []\n",
    "all_match_sizes = []\n",
    "IOU0_ccs_sizes = []\n",
    "\n",
    "ent_no_overlap_all, ent_low_overlap_all, ent_high_overlap_all, ent_exact_overlap_all = [], [], [], []\n",
    "\n",
    "none_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "low_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "high_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "exact_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "non_useful_ccs_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "\n",
    "num_FP_uncertainty_ccs_all = []\n",
    "mean_size_FP_uncertainty_ccs_all = []\n",
    "\n",
    "none_cc_mean = []\n",
    "low_cc_mean = []\n",
    "high_cc_mean = []\n",
    "exact_cc_mean = []\n",
    "\n",
    "uiro_no_overlap_all = []\n",
    "uiro_low_overlap_all = []\n",
    "uiro_high_overlap_all = []\n",
    "\n",
    "for i in tqdm(range(len(means))):\n",
    "    x = xs3d_test[i].cuda()\n",
    "    pred = means[i].cuda().argmax(dim=1)\n",
    "    e = ent_maps[i].cuda()\n",
    "    y0 = rater0[i]\n",
    "    y1 = rater1[i]\n",
    "    \n",
    "    ccs_y0 = cc3d.connected_components(y0.type(torch.int32).numpy(), connectivity=26) # 26-connected\n",
    "    ccs_y0 = torch.from_numpy(ccs_y0.astype(np.float32)).cuda()\n",
    "    \n",
    "    ccs_y1 = cc3d.connected_components(y1.type(torch.int32).numpy(), connectivity=26) # 26-connected\n",
    "    ccs_y1 = torch.from_numpy(ccs_y1.astype(np.float32)).cuda()\n",
    "    \n",
    "    y0 = y0.cuda()\n",
    "    y1 = y1.cuda()\n",
    "    \n",
    "    diff_image = (y0 + y1) == 1\n",
    "    any_prediction_image = (pred + y0 + y1) > 0 # anywhere where either the model or the raters predict\n",
    "    \n",
    "    \n",
    "    # find type 1: connected components in either map with no overlap\n",
    "    no_overlap_ccs_y0, no_overlap_ccs_size_y0, no_overlap_ccs_img_y0 = find_non_overlapping_ccs(ccs_y0, y1)\n",
    "    no_overlap_ccs_y1, no_overlap_ccs_size_y1, no_overlap_ccs_img_y1 = find_non_overlapping_ccs(ccs_y1, y0)\n",
    "    IOU0_ccs_sizes.extend(no_overlap_ccs_size_y0 + no_overlap_ccs_size_y1)\n",
    "    combined_no_overlap_image = (no_overlap_ccs_img_y0 + no_overlap_ccs_img_y1).type(torch.int)\n",
    "    \n",
    "    # get information on the IOU of connected components between rater 0 and rater 1 where the IOU > 0\n",
    "    ious, y0_ccids, y1_ccid_matches, sizes, match_sizes = find_ious_between_raters(ccs_y0, ccs_y1, y0, y1)\n",
    "    all_ious.append(ious)\n",
    "    all_sizes.append(sizes)\n",
    "    all_match_sizes.append(match_sizes)\n",
    "    \n",
    "    ious = torch.Tensor(ious)\n",
    "    y0_ccids = torch.Tensor(y0_ccids)\n",
    "    y1_ccid_matches = torch.Tensor(y1_ccid_matches)\n",
    "    \n",
    "    # find type 2: areas where connected components have a poor overlap IOU of 0.5 and below but not 0.\n",
    "    # IOU of zero ccs have already been discounted in the previous step.\n",
    "    low_ious = ious < 0.5\n",
    "    low_IOU_y0_ccs = y0_ccids[low_ious]\n",
    "    low_IOU_y1_ccs = y1_ccid_matches[low_ious]\n",
    "    low_IOU_y1_ccs = torch.unique(low_IOU_y1_ccs)\n",
    "    combined_low_overlap_image = create_overlap_image(low_IOU_y0_ccs, low_IOU_y1_ccs, ccs_y0, ccs_y1).type(torch.int)\n",
    "    combined_low_overlap_diff_image = combined_low_overlap_image * diff_image\n",
    "    \n",
    "    # find type 3: high overlap\n",
    "    high_ious = (ious >= 0.5) * (ious < 1)\n",
    "    high_IOU_y0_ccs = y0_ccids[high_ious]\n",
    "    high_IOU_y1_ccs = y1_ccid_matches[high_ious]\n",
    "    high_IOU_y1_ccs = torch.unique(high_IOU_y1_ccs)\n",
    "    combined_high_overlap_image = create_overlap_image(high_IOU_y0_ccs, high_IOU_y1_ccs, ccs_y0, ccs_y1).type(torch.int)\n",
    "    combined_high_overlap_diff_image = combined_high_overlap_image * diff_image\n",
    "    \n",
    "    # find type 4: areas of exact overlap\n",
    "    exact_ious = ious == 1\n",
    "    exact_IOU_y0_ccs = y0_ccids[exact_ious]\n",
    "    exact_IOU_y1_ccs = y1_ccid_matches[exact_ious]\n",
    "    exact_IOU_y1_ccs = torch.unique(exact_IOU_y1_ccs)\n",
    "    combined_exact_overlap_image = create_overlap_image(exact_IOU_y0_ccs, None, ccs_y0, ccs_y1).type(torch.int)\n",
    "    \n",
    "    # then get the areas where the raters agree and remove those areas. see what we are left with...\n",
    "    # that is the joint uncertainty error overlap... but I want to look at the overlap away from the boundaries....\n",
    "    \n",
    "    # my concern is that we still have all of this edge information.\n",
    "    \n",
    "    # ANALYSIS 1 cc average uncertainty information\n",
    "    # we need average uncertainty per connected component in the following regions\n",
    "    # - IR IOU 0\n",
    "    # - IR IOU 1\n",
    "    # - diff of IR 0 < IOU < 0.5 regions\n",
    "    # - diff of IR 0.5 <= IOU < 1 regions\n",
    "    \n",
    "    # ANALYSIS 1.5 pixel wise information\n",
    "    # the same as analysis 1 but with individual voxels\n",
    "    # ef = e.flatten()\n",
    "    # ent_no_overlap, ent_low_overlap, ent_high_overlap, ent_exact_overlap = ef[combined_no_overlap_image.flatten()==1], ef[combined_low_overlap_diff_image.flatten()==1], ef[combined_high_overlap_diff_image.flatten()==1], ef[combined_exact_overlap_image.flatten()==1]\n",
    "    # ent_no_overlap_all.extend(ent_no_overlap.cpu())\n",
    "    # ent_low_overlap_all.extend(ent_low_overlap.cpu())\n",
    "    # ent_high_overlap_all.extend(ent_high_overlap.cpu())\n",
    "    # ent_exact_overlap_all.extend(ent_exact_overlap.cpu())\n",
    "    \n",
    "    \n",
    "    # Analysis 2 connected component extra analysis\n",
    "    # as the uncertainty threshold increases we look at:\n",
    "    # average proportion of IR IOU 0 that are uncertain\n",
    "    # average proportion of IR low IOU that are uncertain\n",
    "    # average proportion of IR IOU high that are uncertain\n",
    "    # average proportion of IR IOU 1 that are uncertain\n",
    "    # number of connected components in uncertainty map that have zero overlap with either rater. I should do this for a fewer number of connected components\n",
    "    # none_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    # low_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    # high_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    # exact_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    # non_useful_ccs = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    # num_FP_uncertainty_ccs = []\n",
    "    # mean_size_FP_uncertainty_ccs = []\n",
    "    \n",
    "    ccs_none = torch.from_numpy(cc3d.connected_components(combined_no_overlap_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_low = torch.from_numpy(cc3d.connected_components(combined_low_overlap_diff_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_high = torch.from_numpy(cc3d.connected_components(combined_high_overlap_diff_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_exact = torch.from_numpy(cc3d.connected_components(combined_exact_overlap_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    \n",
    "#     any_prediction_image_dist_map = get_distance_map(any_prediction_image)\n",
    "#     any_prediction_image_dist_map = any_prediction_image_dist_map > 5 # \n",
    "    \n",
    "    # print(ccs_none.unique())\n",
    "    # print(combined_no_overlap_image.sum())\n",
    "    for ti, t in enumerate(uncertainty_thresholds):\n",
    "        et = (e > t).type(torch.float32)\n",
    "        \n",
    "        # look at how many ccs there are\n",
    "        # non_overlapping_uncert_region = et * any_prediction_image_dist_map\n",
    "        # non_overlapping_uncert_ccs = torch.from_numpy(cc3d.connected_components(non_overlapping_uncert_region.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "        # num_FP_uncertainty_ccs.append(len(non_overlapping_uncert_ccs.unique()) - 1) # -1 to get rid of background class\n",
    "        # mean_size_FP_uncertainty_ccs.append(\n",
    "        #     torch.Tensor(\n",
    "        #         [(non_overlapping_uncert_ccs == cc).sum().item() for cc in non_overlapping_uncert_ccs.unique() if cc != 0]\n",
    "        #     ).mean()\n",
    "        # )\n",
    "        \n",
    "        # find proportion uncertain of each cc in each region\n",
    "        for cc_id in ccs_none.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_none == cc_id\n",
    "            # print(cc_id)\n",
    "            # print(cc.sum())\n",
    "            none_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                none_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_low.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_low == cc_id\n",
    "            low_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                low_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_high.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_high == cc_id\n",
    "            high_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                high_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_exact.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_exact == cc_id\n",
    "            exact_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                exact_cc_mean.append(e[cc==1].mean())\n",
    "                \n",
    "#     num_FP_uncertainty_ccs_all.append(num_FP_uncertainty_ccs)\n",
    "#     mean_size_FP_uncertainty_ccs_all.append(mean_size_FP_uncertainty_ccs)\n",
    "                \n",
    "    # ### UIRO per region analysis.\n",
    "    # no_overlap_distance_map = get_distance_map(combined_no_overlap_image)\n",
    "    # low_overlap_distance_map = get_distance_map(combined_low_overlap_diff_image)\n",
    "    # high_overlap_distance_map = get_distance_map(combined_high_overlap_diff_image)\n",
    "    # uiro_no_overlap, uiro_low_overlap, uiro_high_overlap = IOU_region_UIRO(e, diff_image, no_overlap_distance_map, low_overlap_distance_map, high_overlap_distance_map)\n",
    "    # uiro_no_overlap_all.append(uiro_no_overlap)\n",
    "    # uiro_low_overlap_all.append(uiro_low_overlap)\n",
    "    # uiro_high_overlap_all.append(uiro_high_overlap)\n",
    "    \n",
    "    # break\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a50861-8763-4a51-8e9a-fd16c5070020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=3, ncols=8)\n",
    "\n",
    "fontsize = 16\n",
    "\n",
    "if ds_name == \"challenge\":\n",
    "    sel_slices = [22, 24, 27]\n",
    "    \n",
    "elif ds_name == \"lbc\":\n",
    "    sel_slices = [29, 31, 35]\n",
    "\n",
    "elif ds_name == \"mss3\":\n",
    "    sel_slices = [22, 27, 33]\n",
    "\n",
    "for row, islice in enumerate(sel_slices):\n",
    "    PV_region = pv_region_masks[i]\n",
    "    PV_region_img = torch.ones([*PV_region.shape, 4])\n",
    "\n",
    "    PV_region_img[:,:,:,2] = 0.5 # create a pastel yellow\n",
    "    PV_region_img[:,:,:,3] = PV_region # set the rest of the voxels to have alpha of zero.\n",
    "\n",
    "    \n",
    "    b = 20\n",
    "    axs[0 + row*8].imshow(x.cpu()[0, islice][b:-b, b:-b], cmap='gray', vmin=-3, vmax=2.5)\n",
    "    axs[0 + row*8].imshow(PV_region_img[islice][b:-b, b:-b], alpha=0.5)\n",
    "    if row == 0:\n",
    "        axs[0 + row*8].set_title(\"FLAIR\", fontsize=fontsize)\n",
    "    axs[1 + row*8].imshow(y0.type(torch.float32).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "    axs[1 + row*8].imshow(PV_region_img[islice][b:-b, b:-b], alpha=0.5)\n",
    "    if row == 0:\n",
    "        axs[1 + row*8].set_title(\"analyst 1\", fontsize=fontsize)\n",
    "    axs[2 + row*8].imshow(y1.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "    axs[2 + row*8].imshow(PV_region_img[islice][b:-b, b:-b], alpha=0.5)\n",
    "    if row == 0:\n",
    "        axs[2 + row*8].set_title(\"analyst 2 \", fontsize=fontsize)\n",
    "    axs[3 + row*8].imshow(combined_no_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "    axs[3 + row*8].imshow(PV_region_img[islice][b:-b, b:-b], alpha=0.5)\n",
    "    if row == 0:\n",
    "        axs[3 + row*8].set_title(\"ccs with no overlap  \\n(in 3D) JI = 0\", fontsize=fontsize)\n",
    "    axs[4 + row*8].imshow(combined_low_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "    axs[4 + row*8].imshow(PV_region_img[islice][b:-b, b:-b], alpha=0.5)\n",
    "    if row == 0:\n",
    "        axs[4 + row*8].set_title(\"ccs with low overlap \\n(in 3D) 0 < JI < 0.5 \", fontsize=fontsize)\n",
    "    axs[5 + row*8].imshow(combined_high_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "    axs[5 + row*8].imshow(PV_region_img[islice][b:-b, b:-b], alpha=0.5)\n",
    "    if row == 0:\n",
    "        axs[5 + row*8].set_title(\"ccs with high overlap  \\n(in 3D) 0.5 <= JI < 1\", fontsize=fontsize)\n",
    "    axs[6 + row*8].imshow(combined_exact_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "    axs[6 + row*8].imshow(PV_region_img[islice][b:-b, b:-b], alpha=0.5)\n",
    "    if row == 0:\n",
    "        axs[6 + row*8].set_title(\"ccs with exact overlap \\n(in 3D) JI = 1\", fontsize=fontsize)\n",
    "    axs[7 + row*8].imshow(ent_maps[i].cpu()[islice][b:-b, b:-b], cmap='magma')\n",
    "    axs[7 + row*8].imshow(PV_region_img[islice][b:-b, b:-b], alpha=0.5)\n",
    "    if row == 0:\n",
    "        axs[7 + row*8].set_title(\"Uncertainty\", fontsize=fontsize)\n",
    "    axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "    for ax in axs:\n",
    "        for spine in ax.spines:\n",
    "            ax.spines[spine].set_color('none')\n",
    "        \n",
    "fig.savefig(f\"Example of overlap types under consideration {ds_name}.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4950e-e4ff-4309-8556-9858caf0ca4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islice = 30\n",
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=1, ncols=7)\n",
    "b = 20\n",
    "axs[0].imshow(x.cpu()[0, islice][b:-b, b:-b], cmap='gray')\n",
    "axs[0].set_title(\"FLAIR\")\n",
    "axs[1].imshow(y0.type(torch.float32).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[1].set_title(\"rater 0\")\n",
    "axs[2].imshow(combined_no_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[2].set_title(\"ccs with no overlap (in 3D) \\n IOU = 0\")\n",
    "axs[3].imshow((diff_image * combined_low_overlap_image).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[3].set_title(\"low IOU disagreement region\")\n",
    "axs[4].imshow((diff_image * combined_high_overlap_image).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "\n",
    "axs[4].set_title(\"high IOU disagreement region\")\n",
    "axs[5].imshow(ent_maps[i].cpu()[islice][b:-b, b:-b], cmap='Oranges')\n",
    "axs[5].set_title(\"uncertainty\")\n",
    "axs[6].imshow(means[i][islice].argmax(dim=0).cpu()[b:-b, b:-b], cmap='Greens')\n",
    "axs[6].set_title(\"model prediction\")\n",
    "axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "for ax in axs:\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_color('none')\n",
    "        \n",
    "# fig.savefig(\"Example of overlap and uncertainty.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a02066-4996-4799-821c-20e4b31ea8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islice=30\n",
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=1, ncols=5)\n",
    "axs[0].imshow(x.cpu()[0, islice], cmap='gray')\n",
    "axs[0].set_title(\"FLAIR\")\n",
    "axs[1].imshow(y0.cpu()[islice], cmap='gray')\n",
    "axs[1].set_title(\"rater 0\")\n",
    "axs[2].imshow(ccs_y0.cpu()[islice], cmap='Set2')\n",
    "axs[2].set_title(\"rater 0 ccs\")\n",
    "axs[3].imshow(y1.cpu()[islice], cmap='gray')\n",
    "axs[3].set_title(\"rater 1 \")\n",
    "axs[4].imshow(ccs_y1.cpu()[islice], cmap='Set2')\n",
    "axs[4].set_title(\"rater 1 ccs\")\n",
    "axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "for ax in axs:\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_color('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bed451-a127-4ba6-a0a1-607611ec7a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ious = torch.cat([torch.Tensor(t) for t in all_ious])\n",
    "all_sizes = torch.cat([torch.Tensor(t) for t in all_sizes])\n",
    "all_match_sizes = torch.cat([torch.Tensor(t) for t in all_match_sizes])\n",
    "IOU0_ccs_sizes = torch.Tensor(IOU0_ccs_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad10c15-44bb-4285-ad81-6ae1fd624f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.ticker import NullLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c227221-92b7-427d-9bae-60eab2e6b202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = pplt.figure(space=6, refwidth='20em', share=False)\n",
    "axs = fig.subplots(nrows=1, ncols=4)\n",
    "\n",
    "scale = 0.003\n",
    "scaled_all_sizes = all_sizes * scale\n",
    "scaled_IOU0_ccs_sizes = IOU0_ccs_sizes * scale\n",
    "scaled_all_match_sizes = all_match_sizes * scale\n",
    "\n",
    "axs[0].hist2d(all_ious[(scaled_all_sizes< 0.3) * (all_ious<1)].tolist(), (scaled_all_sizes[(scaled_all_sizes< 0.3) * (all_ious<1)]).tolist(), bins=10, colorbar='b',\n",
    "    colorbar_kw={'length': 1, 'label': \"Count\"})\n",
    "axs[0].set_xlabel(\"Conn. Comp. JI between analysts \\n (only when 0 < JI < 1)\")\n",
    "axs[0].set_ylabel(r\"Conn. Comp. Volume (ml)\")\n",
    "axs[0].set_title(\"Analyst JI vs Voxel count histogram per \\n Connected Component \" + r\"(Vol. < 0.3 ml)\")\n",
    "\n",
    "axs[1].scatter((scaled_all_sizes[all_ious<1]).tolist(), (scaled_all_match_sizes[all_ious<1]).tolist(), c=all_ious[all_ious<1].tolist(), alpha=0.5, cmap='summer', colorbar='b',\n",
    "    colorbar_kw={'length': 1, 'label': \"JI\"})\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel(r\"Analyst 1 Conn. Comp. Volume (ml)\")\n",
    "axs[1].set_ylabel(r\"Analyst 2 Conn. Comp. Volume (ml)\")\n",
    "axs[1].set_title(\"Volume of corresponding Connected \\n Components between analysts (0 < JI < 1)\")\n",
    "axs[1].set_xlim((None, 100))\n",
    "axs[1].set_ylim((None, 100))\n",
    "\n",
    "axs[2].hist(all_ious.tolist(), bins=20, color='goldenrod')\n",
    "axs[2].set_xlabel(\"Conn. Comp. JI between analysts\")\n",
    "axs[2].set_ylabel(\"Count\")\n",
    "axs[2].set_title(\"Histogram of Connected Component JI \\n between analysts (JI > 0)\")\n",
    "\n",
    "ji0_arr = scaled_IOU0_ccs_sizes[scaled_IOU0_ccs_sizes < 0.3].tolist()\n",
    "bins = len(ji0_arr) // 30\n",
    "axs[3].hist(ji0_arr, bins=bins, label='JI = 0', color='#d50032')\n",
    "ji1_arr = (scaled_all_sizes[(all_ious==1) * (scaled_all_sizes < 0.3)]).tolist()\n",
    "bins = len(ji1_arr) // 30\n",
    "if bins > 0:\n",
    "    axs[3].hist(ji1_arr, bins=bins, label='JI = 1', color='#002c53')\n",
    "axs[3].legend(loc='b')\n",
    "axs[3].set_xlabel(r\"Conn. Comp. Volume (ml)\")\n",
    "axs[3].set_ylabel(\"Count\")\n",
    "axs[3].set_title(\"Histogram of Volume of Conn. Comps. \\n with JI of 0 or 1 between analysts\")\n",
    "axs[3].set_xlim((0, 0.3))\n",
    "\n",
    "axs.format(abc=True, abcloc='ul')\n",
    "for ax in axs:\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['bottom'].set_linewidth(1.2)  # Thicker bottom spine\n",
    "    ax.spines['left'].set_linewidth(1.2)  # Thicker left spine\n",
    "\n",
    "fig.save(f\"Connected Component information {ds_name}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925f387-bcde-4d7f-8e77-06e4242f185d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len((scaled_IOU0_ccs_sizes[scaled_IOU0_ccs_sizes < 0.3]).tolist()) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f9d22-3186-44c1-bed1-017b5516ae3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist([scaled_IOU0_ccs_sizes[scaled_IOU0_ccs_sizes > 0.3].tolist(), scaled_all_sizes[(all_ious==1) * (scaled_all_sizes > 0.3)].tolist()], color=['#d50032', '#002c53'], bins=20, label=['JI = 0', 'JI = 1'])\n",
    "plt.legend()\n",
    "plt.xlabel(r\"Conn. Comp. Volume (ml)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of sizes of large Conn. Comps. \\n with JI of 0 or 1 between analysts\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['bottom'].set_linewidth(1.2)  # Thicker bottom spine\n",
    "ax.spines['left'].set_linewidth(1.2)  # Thicker left spine\n",
    "    \n",
    "plt.savefig(f\"Size of large CCS with 0or1 JI {ds_name}.pdf\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc49ec-7454-4a8d-8d17-1cc88ba7173d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## run cc analysis across PV region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa6a092-73d0-48ba-8186-0cb542f1858f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(means)):\n",
    "#     print(xs3d_test[i].shape, pv_region_masks[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6c0ab-6210-4235-90dc-d2054c733ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_sizes = []\n",
    "all_ious = []\n",
    "all_match_sizes = []\n",
    "IOU0_ccs_sizes = []\n",
    "\n",
    "ent_no_overlap_all, ent_low_overlap_all, ent_high_overlap_all, ent_exact_overlap_all = [], [], [], []\n",
    "\n",
    "none_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "low_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "high_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "exact_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "non_useful_ccs_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "\n",
    "none_cc_mean = []\n",
    "low_cc_mean = []\n",
    "high_cc_mean = []\n",
    "exact_cc_mean = []\n",
    "\n",
    "for i in tqdm(range(len(means))):\n",
    "    x = xs3d_test[i].cuda()\n",
    "    pred = means[i].cuda().argmax(dim=1)\n",
    "    e = ent_maps[i].cuda()\n",
    "    pv_region = pv_region_masks[i].cuda()\n",
    "    if x.shape[1] != pv_region.shape[0] or x.shape[2] != pv_region.shape[1] or x.shape[3] != pv_region.shape[2]:\n",
    "        continue\n",
    "    y0 = rater0[i].cuda() * pv_region\n",
    "    y1 = rater1[i].cuda() * pv_region\n",
    "    \n",
    "    ccs_y0 = cc3d.connected_components(y0.type(torch.int32).cpu().numpy(), connectivity=26) # 26-connected\n",
    "    ccs_y0 = torch.from_numpy(ccs_y0.astype(np.float32)).cuda()\n",
    "    \n",
    "    ccs_y1 = cc3d.connected_components(y1.type(torch.int32).cpu().numpy(), connectivity=26) # 26-connected\n",
    "    ccs_y1 = torch.from_numpy(ccs_y1.astype(np.float32)).cuda()\n",
    "    \n",
    "    y0 = y0.cuda()\n",
    "    y1 = y1.cuda()\n",
    "    \n",
    "    diff_image = (y0 + y1) == 1\n",
    "    \n",
    "    # find type 1: connected components in either map with no overlap\n",
    "    no_overlap_ccs_y0, no_overlap_ccs_size_y0, no_overlap_ccs_img_y0 = find_non_overlapping_ccs(ccs_y0, y1)\n",
    "    no_overlap_ccs_y1, no_overlap_ccs_size_y1, no_overlap_ccs_img_y1 = find_non_overlapping_ccs(ccs_y1, y0)\n",
    "    IOU0_ccs_sizes.extend(no_overlap_ccs_size_y0 + no_overlap_ccs_size_y1)\n",
    "    combined_no_overlap_image = (no_overlap_ccs_img_y0 + no_overlap_ccs_img_y1).type(torch.int)\n",
    "    \n",
    "    # get information on the IOU of connected components between rater 0 and rater 1 where the IOU > 0\n",
    "    ious, y0_ccids, y1_ccid_matches, sizes, match_sizes = find_ious_between_raters(ccs_y0, ccs_y1, y0, y1)\n",
    "    all_ious.append(ious)\n",
    "    all_sizes.append(sizes)\n",
    "    all_match_sizes.append(match_sizes)\n",
    "    \n",
    "    ious = torch.Tensor(ious)\n",
    "    y0_ccids = torch.Tensor(y0_ccids)\n",
    "    y1_ccid_matches = torch.Tensor(y1_ccid_matches)\n",
    "    \n",
    "    # find type 2: areas where connected components have a poor overlap IOU of 0.5 and below but not 0.\n",
    "    # IOU of zero ccs have already been discounted in the previous step.\n",
    "    low_ious = ious < 0.5\n",
    "    low_IOU_y0_ccs = y0_ccids[low_ious]\n",
    "    low_IOU_y1_ccs = y1_ccid_matches[low_ious]\n",
    "    low_IOU_y1_ccs = torch.unique(low_IOU_y1_ccs)\n",
    "    combined_low_overlap_image = create_overlap_image(low_IOU_y0_ccs, low_IOU_y1_ccs, ccs_y0, ccs_y1).type(torch.int)\n",
    "    combined_low_overlap_diff_image = combined_low_overlap_image * diff_image\n",
    "    \n",
    "    # find type 3: high overlap\n",
    "    high_ious = (ious >= 0.5) * (ious < 1)\n",
    "    high_IOU_y0_ccs = y0_ccids[high_ious]\n",
    "    high_IOU_y1_ccs = y1_ccid_matches[high_ious]\n",
    "    high_IOU_y1_ccs = torch.unique(high_IOU_y1_ccs)\n",
    "    combined_high_overlap_image = create_overlap_image(high_IOU_y0_ccs, high_IOU_y1_ccs, ccs_y0, ccs_y1).type(torch.int)\n",
    "    combined_high_overlap_diff_image = combined_high_overlap_image * diff_image\n",
    "    \n",
    "    # find type 4: areas of exact overlap\n",
    "    exact_ious = ious == 1\n",
    "    exact_IOU_y0_ccs = y0_ccids[exact_ious]\n",
    "    exact_IOU_y1_ccs = y1_ccid_matches[exact_ious]\n",
    "    exact_IOU_y1_ccs = torch.unique(exact_IOU_y1_ccs)\n",
    "    combined_exact_overlap_image = create_overlap_image(exact_IOU_y0_ccs, None, ccs_y0, ccs_y1).type(torch.int)\n",
    "    \n",
    "    # then get the areas where the raters agree and remove those areas. see what we are left with...\n",
    "    # that is the joint uncertainty error overlap... but I want to look at the overlap away from the boundaries....\n",
    "    \n",
    "    # my concern is that we still have all of this edge information.\n",
    "    \n",
    "    # ANALYSIS 1 cc average uncertainty information\n",
    "    # we need average uncertainty per connected component in the following regions\n",
    "    # - IR IOU 0\n",
    "    # - IR IOU 1\n",
    "    # - diff of IR 0 < IOU < 0.5 regions\n",
    "    # - diff of IR 0.5 <= IOU < 1 regions\n",
    "    \n",
    "    # ANALYSIS 1.5 pixel wise information\n",
    "    # the same as analysis 1 but with individual voxels\n",
    "    ef = e.flatten()\n",
    "    ent_no_overlap, ent_low_overlap, ent_high_overlap, ent_exact_overlap = ef[combined_no_overlap_image.flatten()==1], ef[combined_low_overlap_diff_image.flatten()==1], ef[combined_high_overlap_diff_image.flatten()==1], ef[combined_exact_overlap_image.flatten()==1]\n",
    "    ent_no_overlap_all.extend(ent_no_overlap.cpu())\n",
    "    ent_low_overlap_all.extend(ent_low_overlap.cpu())\n",
    "    ent_high_overlap_all.extend(ent_high_overlap.cpu())\n",
    "    ent_exact_overlap_all.extend(ent_exact_overlap.cpu())\n",
    "    \n",
    "    \n",
    "    # Analysis 2 connected component extra analysis\n",
    "    # as the uncertainty threshold increases we look at:\n",
    "    # average proportion of IR IOU 0 that are uncertain\n",
    "    # average proportion of IR low IOU that are uncertain\n",
    "    # average proportion of IR IOU high that are uncertain\n",
    "    # average proportion of IR IOU 1 that are uncertain\n",
    "    # number of connected components in uncertainty map that have zero overlap with either rater. I should do this for a fewer number of connected components\n",
    "    none_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    low_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    high_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    exact_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    non_useful_ccs = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    \n",
    "    ccs_none = torch.from_numpy(cc3d.connected_components(combined_no_overlap_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_low = torch.from_numpy(cc3d.connected_components(combined_low_overlap_diff_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_high = torch.from_numpy(cc3d.connected_components(combined_high_overlap_diff_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_exact = torch.from_numpy(cc3d.connected_components(combined_exact_overlap_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    # print(ccs_none.unique())\n",
    "    # print(combined_no_overlap_image.sum())\n",
    "    for ti, t in enumerate(uncertainty_thresholds):\n",
    "        et = (e > t).type(torch.float32)\n",
    "        \n",
    "        for cc_id in ccs_none.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_none == cc_id\n",
    "            # print(cc_id)\n",
    "            # print(cc.sum())\n",
    "            none_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                none_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_low.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_low == cc_id\n",
    "            low_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                low_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_high.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_high == cc_id\n",
    "            high_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                high_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_exact.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_exact == cc_id\n",
    "            exact_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                exact_cc_mean.append(e[cc==1].mean())\n",
    "                \n",
    "                \n",
    "    # Analysis 2.5:\n",
    "    # average number of superfluous connected components across the dataset as the threshold increases.\n",
    "            \n",
    "    \n",
    "    # Analysis 3 UIRO outside of the regions of the segmentation (do euclidian distance or different components, square and cross for example?) Nice.\n",
    "    \n",
    "    # Analysis 4 JUEO outside the regions of the segmentation produced by the model (provide this with 2 different components or do euclidian distance?)\n",
    "    \n",
    "    # Analysis 5 pcitures\n",
    "    # Collect a number of images of different individuals, the different maps, as I have outlined below, and demonstrate the things that we are talking about.\n",
    "    # Just provide an image every 10 patients or something to demonstrate the examples. \n",
    "    # Nice.\n",
    "    \n",
    "    # yes this is a really good way to approach the analysis and I actually like it quite a lot.\n",
    "    # then I need to collect my nice plot of connected components for each dataset and also collect some nice visual examples from the different datasets as well.....\n",
    "    \n",
    "    \n",
    "    # if i == 1:\n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf8ab1-b809-4807-90cf-554c20fc7dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islice=30\n",
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=1, ncols=7)\n",
    "b = 20\n",
    "axs[0].imshow(x.cpu()[0, islice][b:-b, b:-b], cmap='gray')\n",
    "axs[0].set_title(\"FLAIR\")\n",
    "axs[1].imshow(y0.type(torch.float32).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[1].set_title(\"analyst 1\")\n",
    "axs[2].imshow(y1.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[2].set_title(\"analyst 2 \")\n",
    "axs[3].imshow(combined_no_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[3].set_title(\"ccs with no overlap (in 3D) \\n IOU = 0\")\n",
    "axs[4].imshow(combined_low_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[4].set_title(\"ccs with low overlap (in 3D)\\n 0 < IOU < 0.5 \")\n",
    "axs[5].imshow(combined_high_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[5].set_title(\"ccs with high overlap (in 3D) \\n 0.5 <= IOU < 1\")\n",
    "axs[6].imshow(combined_exact_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[6].set_title(\"ccs with exact overlap (in 3D)\\n IOU = 1\")\n",
    "axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "for ax in axs:\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_color('none')\n",
    "        \n",
    "fig.savefig(\"Example of overlap types under consideration.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d31783-e888-473a-a7c7-caf89b47c94a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islice = 30\n",
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=1, ncols=7)\n",
    "b = 20\n",
    "axs[0].imshow(x.cpu()[0, islice][b:-b, b:-b], cmap='gray')\n",
    "axs[0].set_title(\"FLAIR\")\n",
    "axs[1].imshow(y0.type(torch.float32).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[1].set_title(\"analyst 1\")\n",
    "axs[2].imshow(combined_no_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[2].set_title(\"ccs with no overlap (in 3D) \\n IOU = 0\")\n",
    "axs[3].imshow((diff_image * combined_low_overlap_image).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[3].set_title(\"low IOU disagreement region\")\n",
    "axs[4].imshow((diff_image * combined_high_overlap_image).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "\n",
    "axs[4].set_title(\"high IOU disagreement region\")\n",
    "axs[5].imshow(ent_maps[i].cpu()[islice][b:-b, b:-b], cmap='Oranges')\n",
    "axs[5].set_title(\"uncertainty\")\n",
    "axs[6].imshow(means[i][islice].argmax(dim=0).cpu()[b:-b, b:-b], cmap='Greens')\n",
    "axs[6].set_title(\"model prediction\")\n",
    "axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "for ax in axs:\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_color('none')\n",
    "        \n",
    "# fig.savefig(\"Example of overlap and uncertainty.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dde175-7401-415b-9e15-41630817aa68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islice=30\n",
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=1, ncols=5)\n",
    "axs[0].imshow(x.cpu()[0, islice], cmap='gray')\n",
    "axs[0].set_title(\"FLAIR\")\n",
    "axs[1].imshow(y0.cpu()[islice], cmap='gray')\n",
    "axs[1].set_title(\"analyst 1\")\n",
    "axs[2].imshow(ccs_y0.cpu()[islice], cmap='Set2')\n",
    "axs[2].set_title(\"analyst 1 ccs\")\n",
    "axs[3].imshow(y1.cpu()[islice], cmap='gray')\n",
    "axs[3].set_title(\"analyst 2 \")\n",
    "axs[4].imshow(ccs_y1.cpu()[islice], cmap='Set2')\n",
    "axs[4].set_title(\"analyst 2 ccs\")\n",
    "axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "for ax in axs:\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_color('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81722d5d-459d-4384-a488-778bb00baf4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ious = torch.cat([torch.Tensor(t) for t in all_ious])\n",
    "all_sizes = torch.cat([torch.Tensor(t) for t in all_sizes])\n",
    "all_match_sizes = torch.cat([torch.Tensor(t) for t in all_match_sizes])\n",
    "IOU0_ccs_sizes = torch.Tensor(IOU0_ccs_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203a28b-7e06-439a-a09c-389c6a99dce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.ticker import NullLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d1432-d6b9-4dee-bb84-684211b373f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = pplt.figure(space=6, refwidth='20em', share=False)\n",
    "axs = fig.subplots(nrows=1, ncols=4)\n",
    "\n",
    "scale = 0.003\n",
    "scaled_all_sizes = all_sizes * scale\n",
    "scaled_IOU0_ccs_sizes = IOU0_ccs_sizes * scale\n",
    "scaled_all_match_sizes = all_match_sizes * scale\n",
    "\n",
    "axs[0].hist2d(all_ious[(scaled_all_sizes< 0.3) * (all_ious<1)].tolist(), (scaled_all_sizes[(scaled_all_sizes< 0.3) * (all_ious<1)]).tolist(), bins=10, colorbar='b',\n",
    "    colorbar_kw={'length': 1, 'label': \"Count\"})\n",
    "axs[0].set_xlabel(\"Conn. Comp. JI between analysts \\n (only when 0 < JI < 1)\")\n",
    "axs[0].set_ylabel(r\"Conn. Comp. Volume (ml)\")\n",
    "axs[0].set_title(\"Analyst JI vs Voxel count histogram per \\n Connected Component \" + r\"(Vol. < 0.3 ml)\")\n",
    "\n",
    "axs[1].scatter((scaled_all_sizes[all_ious<1]).tolist(), (scaled_all_match_sizes[all_ious<1]).tolist(), c=all_ious[all_ious<1].tolist(), alpha=0.5, cmap='summer', colorbar='b',\n",
    "    colorbar_kw={'length': 1, 'label': \"JI\"})\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel(r\"Analyst 1 Conn. Comp. Volume (ml)\")\n",
    "axs[1].set_ylabel(r\"Analyst 2 Conn. Comp. Volume (ml)\")\n",
    "axs[1].set_title(\"Volume of corresponding Connected \\n Components between analysts (0 < JI < 1)\")\n",
    "axs[1].set_xlim((None, 100))\n",
    "axs[1].set_ylim((None, 100))\n",
    "\n",
    "axs[2].hist(all_ious.tolist(), bins=20, color='goldenrod')\n",
    "axs[2].set_xlabel(\"Conn. Comp. JI between analysts\")\n",
    "axs[2].set_ylabel(\"Count\")\n",
    "axs[2].set_title(\"Histogram of Connected Component JI \\n between analysts (JI > 0)\")\n",
    "\n",
    "ji0_arr = scaled_IOU0_ccs_sizes[scaled_IOU0_ccs_sizes < 0.3].tolist()\n",
    "bins = len(ji0_arr) // 30\n",
    "axs[3].hist(ji0_arr, bins=bins, label='JI = 0', color='#d50032')\n",
    "ji1_arr = (scaled_all_sizes[(all_ious==1) * (scaled_all_sizes < 0.3)]).tolist()\n",
    "bins = len(ji1_arr) // 30\n",
    "if bins > 0:\n",
    "    axs[3].hist(ji1_arr, bins=bins, label='JI = 1', color='#002c53')\n",
    "axs[3].legend(loc='b')\n",
    "axs[3].set_xlabel(r\"Conn. Comp. Volume (ml)\")\n",
    "axs[3].set_ylabel(\"Count\")\n",
    "axs[3].set_title(\"Histogram of Volume of Conn. Comps. \\n with JI of 0 or 1 between analysts\")\n",
    "axs[3].set_xlim((0, 0.3))\n",
    "\n",
    "axs.format(abc=True, abcloc='ul')\n",
    "for ax in axs:\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['bottom'].set_linewidth(1.2)  # Thicker bottom spine\n",
    "    ax.spines['left'].set_linewidth(1.2)  # Thicker left spine\n",
    "\n",
    "fig.save(f\"Connected Component information PV REGION {ds_name}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1c57d-c8c3-4a0e-b9fd-88992d1024fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist([scaled_IOU0_ccs_sizes[scaled_IOU0_ccs_sizes > 0.3].tolist(), scaled_all_sizes[(all_ious==1) * (scaled_all_sizes > 0.3)].tolist()], color=['#d50032', '#002c53'], bins=20, label=['JI = 0', 'JI = 1'])\n",
    "plt.legend()\n",
    "plt.xlabel(r\"Conn. Comp. Volume (ml)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of sizes of large Conn. Comps. \\n with JI of 0 or 1 between analysts\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['bottom'].set_linewidth(1.2)  # Thicker bottom spine\n",
    "ax.spines['left'].set_linewidth(1.2)  # Thicker left spine\n",
    "    \n",
    "plt.savefig(f\"Size of large CCS with 0or1 JI PV REGION {ds_name}.pdf\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23adb09-5c1b-4c74-b247-c078f4d2c8bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## run cc analysis across Deep region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f9fc6-37e2-4606-95f8-bce0074ce201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(means)):\n",
    "#     print(xs3d_test[i].shape, pv_region_masks[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ed34c-cba0-488c-aa52-472e3a8ca99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_sizes = []\n",
    "all_ious = []\n",
    "all_match_sizes = []\n",
    "IOU0_ccs_sizes = []\n",
    "\n",
    "ent_no_overlap_all, ent_low_overlap_all, ent_high_overlap_all, ent_exact_overlap_all = [], [], [], []\n",
    "\n",
    "none_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "low_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "high_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "exact_prop_uncert_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "non_useful_ccs_all = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "\n",
    "none_cc_mean = []\n",
    "low_cc_mean = []\n",
    "high_cc_mean = []\n",
    "exact_cc_mean = []\n",
    "\n",
    "for i in tqdm(range(len(means))):\n",
    "    x = xs3d_test[i].cuda()\n",
    "    pred = means[i].cuda().argmax(dim=1)\n",
    "    e = ent_maps[i].cuda()\n",
    "    deep_region = 1 - pv_region_masks[i].cuda()\n",
    "    if x.shape[1] != deep_region.shape[0] or x.shape[2] != deep_region.shape[1] or x.shape[3] != deep_region.shape[2]:\n",
    "        continue\n",
    "    y0 = rater0[i].cuda() * deep_region\n",
    "    y1 = rater1[i].cuda() * deep_region\n",
    "    \n",
    "    ccs_y0 = cc3d.connected_components(y0.type(torch.int32).cpu().numpy(), connectivity=26) # 26-connected\n",
    "    ccs_y0 = torch.from_numpy(ccs_y0.astype(np.float32)).cuda()\n",
    "    \n",
    "    ccs_y1 = cc3d.connected_components(y1.type(torch.int32).cpu().numpy(), connectivity=26) # 26-connected\n",
    "    ccs_y1 = torch.from_numpy(ccs_y1.astype(np.float32)).cuda()\n",
    "    \n",
    "    y0 = y0.cuda()\n",
    "    y1 = y1.cuda()\n",
    "    \n",
    "    diff_image = (y0 + y1) == 1\n",
    "    \n",
    "    # find type 1: connected components in either map with no overlap\n",
    "    no_overlap_ccs_y0, no_overlap_ccs_size_y0, no_overlap_ccs_img_y0 = find_non_overlapping_ccs(ccs_y0, y1)\n",
    "    no_overlap_ccs_y1, no_overlap_ccs_size_y1, no_overlap_ccs_img_y1 = find_non_overlapping_ccs(ccs_y1, y0)\n",
    "    IOU0_ccs_sizes.extend(no_overlap_ccs_size_y0 + no_overlap_ccs_size_y1)\n",
    "    combined_no_overlap_image = (no_overlap_ccs_img_y0 + no_overlap_ccs_img_y1).type(torch.int)\n",
    "    \n",
    "    # get information on the IOU of connected components between rater 0 and rater 1 where the IOU > 0\n",
    "    ious, y0_ccids, y1_ccid_matches, sizes, match_sizes = find_ious_between_raters(ccs_y0, ccs_y1, y0, y1)\n",
    "    all_ious.append(ious)\n",
    "    all_sizes.append(sizes)\n",
    "    all_match_sizes.append(match_sizes)\n",
    "    \n",
    "    ious = torch.Tensor(ious)\n",
    "    y0_ccids = torch.Tensor(y0_ccids)\n",
    "    y1_ccid_matches = torch.Tensor(y1_ccid_matches)\n",
    "    \n",
    "    # find type 2: areas where connected components have a poor overlap IOU of 0.5 and below but not 0.\n",
    "    # IOU of zero ccs have already been discounted in the previous step.\n",
    "    low_ious = ious < 0.5\n",
    "    low_IOU_y0_ccs = y0_ccids[low_ious]\n",
    "    low_IOU_y1_ccs = y1_ccid_matches[low_ious]\n",
    "    low_IOU_y1_ccs = torch.unique(low_IOU_y1_ccs)\n",
    "    combined_low_overlap_image = create_overlap_image(low_IOU_y0_ccs, low_IOU_y1_ccs, ccs_y0, ccs_y1).type(torch.int)\n",
    "    combined_low_overlap_diff_image = combined_low_overlap_image * diff_image\n",
    "    \n",
    "    # find type 3: high overlap\n",
    "    high_ious = (ious >= 0.5) * (ious < 1)\n",
    "    high_IOU_y0_ccs = y0_ccids[high_ious]\n",
    "    high_IOU_y1_ccs = y1_ccid_matches[high_ious]\n",
    "    high_IOU_y1_ccs = torch.unique(high_IOU_y1_ccs)\n",
    "    combined_high_overlap_image = create_overlap_image(high_IOU_y0_ccs, high_IOU_y1_ccs, ccs_y0, ccs_y1).type(torch.int)\n",
    "    combined_high_overlap_diff_image = combined_high_overlap_image * diff_image\n",
    "    \n",
    "    # find type 4: areas of exact overlap\n",
    "    exact_ious = ious == 1\n",
    "    exact_IOU_y0_ccs = y0_ccids[exact_ious]\n",
    "    exact_IOU_y1_ccs = y1_ccid_matches[exact_ious]\n",
    "    exact_IOU_y1_ccs = torch.unique(exact_IOU_y1_ccs)\n",
    "    combined_exact_overlap_image = create_overlap_image(exact_IOU_y0_ccs, None, ccs_y0, ccs_y1).type(torch.int)\n",
    "    \n",
    "    # then get the areas where the raters agree and remove those areas. see what we are left with...\n",
    "    # that is the joint uncertainty error overlap... but I want to look at the overlap away from the boundaries....\n",
    "    \n",
    "    # my concern is that we still have all of this edge information.\n",
    "    \n",
    "    # ANALYSIS 1 cc average uncertainty information\n",
    "    # we need average uncertainty per connected component in the following regions\n",
    "    # - IR IOU 0\n",
    "    # - IR IOU 1\n",
    "    # - diff of IR 0 < IOU < 0.5 regions\n",
    "    # - diff of IR 0.5 <= IOU < 1 regions\n",
    "    \n",
    "    # ANALYSIS 1.5 pixel wise information\n",
    "    # the same as analysis 1 but with individual voxels\n",
    "    ef = e.flatten()\n",
    "    ent_no_overlap, ent_low_overlap, ent_high_overlap, ent_exact_overlap = ef[combined_no_overlap_image.flatten()==1], ef[combined_low_overlap_diff_image.flatten()==1], ef[combined_high_overlap_diff_image.flatten()==1], ef[combined_exact_overlap_image.flatten()==1]\n",
    "    ent_no_overlap_all.extend(ent_no_overlap.cpu())\n",
    "    ent_low_overlap_all.extend(ent_low_overlap.cpu())\n",
    "    ent_high_overlap_all.extend(ent_high_overlap.cpu())\n",
    "    ent_exact_overlap_all.extend(ent_exact_overlap.cpu())\n",
    "    \n",
    "    \n",
    "    # Analysis 2 connected component extra analysis\n",
    "    # as the uncertainty threshold increases we look at:\n",
    "    # average proportion of IR IOU 0 that are uncertain\n",
    "    # average proportion of IR low IOU that are uncertain\n",
    "    # average proportion of IR IOU high that are uncertain\n",
    "    # average proportion of IR IOU 1 that are uncertain\n",
    "    # number of connected components in uncertainty map that have zero overlap with either rater. I should do this for a fewer number of connected components\n",
    "    none_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    low_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    high_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    exact_prop_uncert = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    non_useful_ccs = [[] for _ in range(len(uncertainty_thresholds))]\n",
    "    \n",
    "    ccs_none = torch.from_numpy(cc3d.connected_components(combined_no_overlap_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_low = torch.from_numpy(cc3d.connected_components(combined_low_overlap_diff_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_high = torch.from_numpy(cc3d.connected_components(combined_high_overlap_diff_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    ccs_exact = torch.from_numpy(cc3d.connected_components(combined_exact_overlap_image.type(torch.int32).cpu().numpy(), connectivity=26).astype(np.float32)).cuda()\n",
    "    # print(ccs_none.unique())\n",
    "    # print(combined_no_overlap_image.sum())\n",
    "    for ti, t in enumerate(uncertainty_thresholds):\n",
    "        et = (e > t).type(torch.float32)\n",
    "        \n",
    "        for cc_id in ccs_none.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_none == cc_id\n",
    "            # print(cc_id)\n",
    "            # print(cc.sum())\n",
    "            none_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                none_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_low.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_low == cc_id\n",
    "            low_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                low_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_high.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_high == cc_id\n",
    "            high_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                high_cc_mean.append(e[cc==1].mean())\n",
    "        for cc_id in ccs_exact.unique():\n",
    "            if cc_id == 0:\n",
    "                continue\n",
    "            cc = ccs_exact == cc_id\n",
    "            exact_prop_uncert_all[ti].append(et[cc==1].mean().item())\n",
    "            if ti == 0:\n",
    "                exact_cc_mean.append(e[cc==1].mean())\n",
    "                \n",
    "                \n",
    "    # Analysis 2.5:\n",
    "    # average number of superfluous connected components across the dataset as the threshold increases.\n",
    "            \n",
    "    \n",
    "    # Analysis 3 UIRO outside of the regions of the segmentation (do euclidian distance or different components, square and cross for example?) Nice.\n",
    "    \n",
    "    # Analysis 4 JUEO outside the regions of the segmentation produced by the model (provide this with 2 different components or do euclidian distance?)\n",
    "    \n",
    "    # Analysis 5 pcitures\n",
    "    # Collect a number of images of different individuals, the different maps, as I have outlined below, and demonstrate the things that we are talking about.\n",
    "    # Just provide an image every 10 patients or something to demonstrate the examples. \n",
    "    # Nice.\n",
    "    \n",
    "    # yes this is a really good way to approach the analysis and I actually like it quite a lot.\n",
    "    # then I need to collect my nice plot of connected components for each dataset and also collect some nice visual examples from the different datasets as well.....\n",
    "    \n",
    "    \n",
    "    # if i == 1:\n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1cde3-762c-4aa6-b098-13bdfebfe868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islice=30\n",
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=1, ncols=7)\n",
    "b = 20\n",
    "axs[0].imshow(x.cpu()[0, islice][b:-b, b:-b], cmap='gray')\n",
    "axs[0].set_title(\"FLAIR\")\n",
    "axs[1].imshow(y0.type(torch.float32).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[1].set_title(\"analyst 1\")\n",
    "axs[2].imshow(y1.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[2].set_title(\"analyst 2 \")\n",
    "axs[3].imshow(combined_no_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[3].set_title(\"ccs with no overlap (in 3D) \\n IOU = 0\")\n",
    "axs[4].imshow(combined_low_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[4].set_title(\"ccs with low overlap (in 3D)\\n 0 < IOU < 0.5 \")\n",
    "axs[5].imshow(combined_high_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[5].set_title(\"ccs with high overlap (in 3D) \\n 0.5 <= IOU < 1\")\n",
    "axs[6].imshow(combined_exact_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[6].set_title(\"ccs with exact overlap (in 3D)\\n IOU = 1\")\n",
    "axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "for ax in axs:\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_color('none')\n",
    "        \n",
    "fig.savefig(\"Example of overlap types under consideration DEEP REGION.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01c3a1-fd0a-43ad-b339-cb3903c5ad02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islice = 30\n",
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=1, ncols=7)\n",
    "b = 20\n",
    "axs[0].imshow(x.cpu()[0, islice][b:-b, b:-b], cmap='gray')\n",
    "axs[0].set_title(\"FLAIR\")\n",
    "axs[1].imshow(y0.type(torch.float32).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[1].set_title(\"analyst 1\")\n",
    "axs[2].imshow(combined_no_overlap_image.cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[2].set_title(\"ccs with no overlap (in 3D) \\n IOU = 0\")\n",
    "axs[3].imshow((diff_image * combined_low_overlap_image).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "axs[3].set_title(\"low IOU disagreement region\")\n",
    "axs[4].imshow((diff_image * combined_high_overlap_image).cpu()[islice][b:-b, b:-b], cmap='gray')\n",
    "\n",
    "axs[4].set_title(\"high IOU disagreement region\")\n",
    "axs[5].imshow(ent_maps[i].cpu()[islice][b:-b, b:-b], cmap='Oranges')\n",
    "axs[5].set_title(\"uncertainty\")\n",
    "axs[6].imshow(means[i][islice].argmax(dim=0).cpu()[b:-b, b:-b], cmap='Greens')\n",
    "axs[6].set_title(\"model prediction\")\n",
    "axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "for ax in axs:\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_color('none')\n",
    "        \n",
    "# fig.savefig(\"Example of overlap and uncertainty.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82821c7-1ba9-470b-b6b2-f034b4c741de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aaac94-a0a8-45d4-8162-4720958eb741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islice=30\n",
    "fig = pplt.figure(space=0, refwidth='20em')\n",
    "axs = fig.subplots(nrows=1, ncols=5)\n",
    "axs[0].imshow(x.cpu()[0, islice], cmap='gray')\n",
    "axs[0].set_title(\"FLAIR\")\n",
    "axs[1].imshow(y0.cpu()[islice], cmap='gray')\n",
    "axs[1].set_title(\"analyst 1\")\n",
    "axs[2].imshow(ccs_y0.cpu()[islice], cmap='Set2')\n",
    "axs[2].set_title(\"analyst 1 ccs\")\n",
    "axs[3].imshow(y1.cpu()[islice], cmap='gray')\n",
    "axs[3].set_title(\"analyst 2 \")\n",
    "axs[4].imshow(ccs_y1.cpu()[islice], cmap='Set2')\n",
    "axs[4].set_title(\"analyst 2 ccs\")\n",
    "axs.format(grid=False, xlocator='null', ylocator='null')\n",
    "for ax in axs:\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_color('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85785b42-3bea-446a-b6dd-d71cdd2fd970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ious = torch.cat([torch.Tensor(t) for t in all_ious])\n",
    "all_sizes = torch.cat([torch.Tensor(t) for t in all_sizes])\n",
    "all_match_sizes = torch.cat([torch.Tensor(t) for t in all_match_sizes])\n",
    "IOU0_ccs_sizes = torch.Tensor(IOU0_ccs_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49129aff-4d86-48d5-89cb-2f70f3ebad62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.ticker import NullLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae103291-435b-42e2-9f87-a3c772f39c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = pplt.figure(space=6, refwidth='20em', share=False)\n",
    "axs = fig.subplots(nrows=1, ncols=4)\n",
    "\n",
    "scale = 0.003\n",
    "scaled_all_sizes = all_sizes * scale\n",
    "scaled_IOU0_ccs_sizes = IOU0_ccs_sizes * scale\n",
    "scaled_all_match_sizes = all_match_sizes * scale\n",
    "\n",
    "axs[0].hist2d(all_ious[(scaled_all_sizes< 0.3) * (all_ious<1)].tolist(), (scaled_all_sizes[(scaled_all_sizes< 0.3) * (all_ious<1)]).tolist(), bins=10, colorbar='b',\n",
    "    colorbar_kw={'length': 1, 'label': \"Count\"})\n",
    "axs[0].set_xlabel(\"Conn. Comp. JI between analysts \\n (only when 0 < JI < 1)\")\n",
    "axs[0].set_ylabel(r\"Conn. Comp. Volume (ml)\")\n",
    "axs[0].set_title(\"Analyst JI vs Voxel count histogram per \\n Connected Component \" + r\"(Vol. < 0.3 ml)\")\n",
    "\n",
    "axs[1].scatter((scaled_all_sizes[all_ious<1]).tolist(), (scaled_all_match_sizes[all_ious<1]).tolist(), c=all_ious[all_ious<1].tolist(), alpha=0.5, cmap='summer', colorbar='b',\n",
    "    colorbar_kw={'length': 1, 'label': \"JI\"})\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel(r\"Analyst 1 Conn. Comp. Volume (ml)\")\n",
    "axs[1].set_ylabel(r\"Analyst 2 Conn. Comp. Volume (ml)\")\n",
    "axs[1].set_title(\"Volume of corresponding Connected \\n Components between analysts (0 < JI < 1)\")\n",
    "axs[1].set_xlim((None, 100))\n",
    "axs[1].set_ylim((None, 100))\n",
    "\n",
    "axs[2].hist(all_ious.tolist(), bins=20, color='goldenrod')\n",
    "axs[2].set_xlabel(\"Conn. Comp. JI between analysts\")\n",
    "axs[2].set_ylabel(\"Count\")\n",
    "axs[2].set_title(\"Histogram of Connected Component JI \\n between analysts (JI > 0)\")\n",
    "\n",
    "ji0_arr = scaled_IOU0_ccs_sizes[scaled_IOU0_ccs_sizes < 0.3].tolist()\n",
    "bins = len(ji0_arr) // 30\n",
    "axs[3].hist(ji0_arr, bins=bins, label='JI = 0', color='#d50032')\n",
    "ji1_arr = (scaled_all_sizes[(all_ious==1) * (scaled_all_sizes < 0.3)]).tolist()\n",
    "bins = len(ji1_arr) // 30\n",
    "if bins > 0:\n",
    "    axs[3].hist(ji1_arr, bins=bins, label='JI = 1', color='#002c53')\n",
    "axs[3].legend(loc='b')\n",
    "axs[3].set_xlabel(r\"Conn. Comp. Volume (ml)\")\n",
    "axs[3].set_ylabel(\"Count\")\n",
    "axs[3].set_title(\"Histogram of Volume of Conn. Comps. \\n with JI of 0 or 1 between analysts\")\n",
    "axs[3].set_xlim((0, 0.3))\n",
    "\n",
    "axs.format(abc=True, abcloc='ul')\n",
    "for ax in axs:\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['bottom'].set_linewidth(1.2)  # Thicker bottom spine\n",
    "    ax.spines['left'].set_linewidth(1.2)  # Thicker left spine\n",
    "\n",
    "fig.save(f\"Connected Component information DEEP REGION {ds_name}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468def5-79c3-4e9b-b488-f3987243d545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist([scaled_IOU0_ccs_sizes[scaled_IOU0_ccs_sizes > 0.3].tolist(), scaled_all_sizes[(all_ious==1) * (scaled_all_sizes > 0.3)].tolist()], color=['#d50032', '#002c53'], bins=20, label=['JI = 0', 'JI = 1'])\n",
    "plt.legend()\n",
    "plt.xlabel(r\"Conn. Comp. Volume (ml)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of sizes of large Conn. Comps. \\n with JI of 0 or 1 between analysts\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['bottom'].set_linewidth(1.2)  # Thicker bottom spine\n",
    "ax.spines['left'].set_linewidth(1.2)  # Thicker left spine\n",
    "    \n",
    "plt.savefig(f\"Size of large CCS with 0or1 JI DEEP REGION {ds_name}.pdf\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f4d1c-3ba9-4efc-af7d-4de20bed2f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
