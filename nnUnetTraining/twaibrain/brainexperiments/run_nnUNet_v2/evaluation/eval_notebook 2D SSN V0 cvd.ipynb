{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7705cec-1a60-40eb-8a22-3dc28bea40fa",
   "metadata": {},
   "source": [
    "### running the evaluation for the challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1924ce-955d-4eac-99bf-5962f5cb6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63cf7422-bf0a-45bd-b171-2ded47bd5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa14325f-b699-4d1d-806c-11ab977230d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from collections import defaultdict, namedtuple\n",
    "import pandas as pd\n",
    "# import proplot as pplt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # I should only put this in place when I am doing plotting and using proplot....\n",
    "from twaibrain.braintorch.utils.resize import crop_or_pad_dims\n",
    "from twaibrain.brainpreprep.utils.image_io import load_image\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "# model architecture\n",
    "import json\n",
    "from twaibrain.braintorch.models.nnUNet.nnUNetV2_model_loader import get_network_from_plans\n",
    "from twaibrain.braintorch.models.ssn import SSN_Wrapped_Deep_Supervision, SSN_Wrapped_Deep_Supervision_LLO, Hierarchical_SSN_with_ConvRefine, Hierarchical_SSN_with_ConvSpatialAttention\n",
    "\n",
    "# fitting code\n",
    "from twaibrain.braintorch.fitting_and_inference.get_trainer import get_trainer\n",
    "from twaibrain.braintorch.fitting_and_inference.get_scratch_dir import scratch_dir\n",
    "from twaibrain.braintorch.fitting_and_inference.optimizer_constructor import OptimizerConfigurator\n",
    "from twaibrain.braintorch.fitting_and_inference.lightning_fitter import StandardLitModelWrapper\n",
    "\n",
    "# loss function\n",
    "from twaibrain.braintorch.losses.ssn_losses import DeepSupervisionSSN, SSNCombinedDiceXent_and_MC_loss, SSNCombinedDiceXent_and_MC_loss_FromSamples\n",
    "from twaibrain.braintorch.losses.generic_deep_supervision import MultiDeepSupervisionLoss, DeepSupervisionLoss\n",
    "from twaibrain.braintorch.losses.dice_loss import SoftDiceV2\n",
    "from twaibrain.braintorch.losses.xent import dice_xent_loss\n",
    "\n",
    "# data\n",
    "from twaibrain.brainexperiments.run_nnUNet_v2.old_dataloading.dataset_pipelines import load_data\n",
    "from twaibrain.braintorch.data.legacy_dataset_types.dataset_wrappers import MonaiAugmentedDataset\n",
    "from twaibrain.braintorch.augmentation.nnunet_augmentations import get_nnunet_transforms, get_val_transforms\n",
    "from torch.utils.data import ConcatDataset\n",
    "from twaibrain.braintorch.data.legacy_dataset_types.mri_dataset_inram import MRISegmentation3DDataset\n",
    "from twaibrain.braintorch.data.legacy_dataset_types.mri_dataset_from_file import MRISegmentationDatasetFromFile, ArrayMRISegmentationDatasetFromFile\n",
    "from twaibrain.braintorch.data.legacy_dataset_types.mri_dataset_directory_parsers import *\n",
    "\n",
    "# evaluation code\n",
    "from twaibrain.brainexperiments.run_nnUNet_v2.evaluation.eval_helper_functions import *\n",
    "from twaibrain.brainexperiments.run_nnUNet_v2.evaluation.model_predictions import get_means_and_samples_2D, ssn_ensemble_mean_and_samples\n",
    "from twaibrain.brainexperiments.run_nnUNet_v2.evaluation.model_predictions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ee30e-c703-4087-9cbf-960cd128ac38",
   "metadata": {},
   "source": [
    "### setting up params for the rest of the code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2162225-8732-4b26-a257-a8a33bd9b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = namedtuple(\"args\", \"dataset test_split val_split seed \" + \n",
    "                  \"empty_slice_retention batch_size cross_validate cv_split cv_test_fold_smooth no_test_fold \" +\n",
    "                  \"num_workers dice_factor xent_factor xent_reweighting eval_split uncertainty_type ckpt_dir\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7526adce-3f7e-473b-914c-a5494205ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOXELS_TO_WMH_RATIO = 382\n",
    "VOXELS_TO_WMH_RATIO_EXCLUDING_EMPTY_SLICES = 140\n",
    "ESR = 0.5\n",
    "\n",
    "\n",
    "# setup xent reweighting factor\n",
    "XENT_VOXEL_RESCALE = VOXELS_TO_WMH_RATIO - (1-ESR) * (VOXELS_TO_WMH_RATIO - VOXELS_TO_WMH_RATIO_EXCLUDING_EMPTY_SLICES)\n",
    "\n",
    "XENT_WEIGHTING = XENT_VOXEL_RESCALE/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cac5d8e-f4b5-4f59-ae62-2b00f0052dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS(\n",
    "    dataset = \"ed\",\n",
    "    \n",
    "    test_split=0.15,\n",
    "    val_split=0.15,\n",
    "    eval_split='test',\n",
    "\n",
    "    seed=5,\n",
    "\n",
    "    empty_slice_retention=ESR,\n",
    "\n",
    "    uncertainty_type=\"ssn\",\n",
    "\n",
    "    batch_size=2,\n",
    "    cross_validate=True,\n",
    "    cv_split=0,\n",
    "    cv_test_fold_smooth=1,\n",
    "    no_test_fold=\"false\",\n",
    "    num_workers=16,\n",
    "\n",
    "    dice_factor=1,\n",
    "    xent_factor=1,\n",
    "    xent_reweighting=XENT_WEIGHTING,\n",
    "    ckpt_dir= \"/home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fb744-1fc3-42d7-b839-291269aac125",
   "metadata": {},
   "source": [
    "### loading eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d644bf7-475f-4c17-8310-3992d81b22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cv_test_set(cv_split):\n",
    "\n",
    "    data_dict = load_data(\n",
    "        dataset=args.dataset, \n",
    "        test_proportion=args.test_split, \n",
    "        validation_proportion=args.val_split,\n",
    "        seed=args.seed,\n",
    "        empty_proportion_retained=args.empty_slice_retention,\n",
    "        batch_size=args.batch_size,\n",
    "        dataloader2d_only=False,\n",
    "        cross_validate=True,\n",
    "        cv_split=cv_split,\n",
    "        cv_test_fold_smooth=args.cv_test_fold_smooth,\n",
    "        merge_val_test=args.no_test_fold\n",
    "    )\n",
    "    \n",
    "    if args.eval_split == \"all\":\n",
    "        eval_ds = ConcatDataset([data_dict['train_dataset3d'], data_dict['val_dataset3d'], data_dict['test_dataset3d']])\n",
    "    else:\n",
    "        eval_ds = data_dict[f'{args.eval_split}_dataset3d']\n",
    "    \n",
    "    # get the xs and ys\n",
    "    xs3d_test = []\n",
    "    ys3d_test = []\n",
    "    \n",
    "    for i, data in enumerate(eval_ds):\n",
    "        ys3d_test.append(data[1].squeeze())\n",
    "        xs3d_test.append(data[0])\n",
    "    \n",
    "    ys3d_test = [y * (y==1).type(y.dtype) for y in ys3d_test] # fix bug with challenge data having 3 classes on cluster only?\n",
    "    gt_vols = GT_volumes(ys3d_test)\n",
    "    \n",
    "    # to run on the nnUnet version of the model,\n",
    "    # I should crop the x and y to the min and max points\n",
    "    # this will also effectively centre the images for evaluation.\n",
    "    for i in range(len(xs3d_test)):\n",
    "        x = xs3d_test[i]\n",
    "        y = ys3d_test[i]\n",
    "        wheres = torch.where(x[-1])\n",
    "        zs = (wheres[0].min().item(), wheres[0].max().item())\n",
    "        xs = (wheres[1].min().item(), wheres[1].max().item())\n",
    "        ys = (wheres[2].min().item(), wheres[2].max().item())\n",
    "        # print(zs, xs, ys)\n",
    "        # print(x.shape, y.shape)\n",
    "    \n",
    "        x = x[:, zs[0]:zs[1]+1, xs[0]:xs[1]+1, ys[0]:ys[1]+1]\n",
    "        y = y[zs[0]:zs[1]+1, xs[0]:xs[1]+1, ys[0]:ys[1]+1]\n",
    "    \n",
    "        # print(x.shape, y.shape)\n",
    "        \n",
    "        x = crop_or_pad_dims(x, [1,2,3], [48, 192, 192])\n",
    "        y = crop_or_pad_dims(y, [0,1,2], [48, 192, 192])\n",
    "    \n",
    "        x = x.unsqueeze(0)\n",
    "    \n",
    "        # print(x.shape, y.shape)\n",
    "        # print()\n",
    "        xs3d_test[i] = x\n",
    "        ys3d_test[i] = y\n",
    "\n",
    "    return xs3d_test, ys3d_test, gt_vols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb569f9-1531-47f4-8275-faaf9e030654",
   "metadata": {},
   "source": [
    "### load a model checkpoint and get relevant predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "306bae4d-122d-405c-bdf8-475bf2de1471",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = \"/home/s2208943/projects/twaibrain/twaibrain/braintorch/models/nnUNet/cvd_configs/nnUNetResEncUNetMPlans.json\"\n",
    "\n",
    "with open(model_config) as f:\n",
    "    model_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6095ad18-3907-4d2f-96a1-1cea9900b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = \"2d\"\n",
    "config = model_config['configurations'][dims]['architecture']\n",
    "network_name = config['network_class_name']\n",
    "kw_requires_import = config['_kw_requires_import']\n",
    "\n",
    "def get_model():\n",
    "    return get_network_from_plans(\n",
    "        arch_class_name=network_name,\n",
    "        arch_kwargs=config['arch_kwargs'],\n",
    "        arch_kwargs_req_import=kw_requires_import,\n",
    "        input_channels=3,\n",
    "        output_channels=32,\n",
    "        allow_init=True,\n",
    "        deep_supervision=True,\n",
    "    )\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7409a0a3-3203-4210-95e0-3ef7303f696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssn_config = {\n",
    "    'intermediate_channels':32,\n",
    "    'out_channels':2,\n",
    "    'dims':2,\n",
    "    'rank':25,\n",
    "    'diagonal':False,\n",
    "}\n",
    "\n",
    "ssn_model = SSN_Wrapped_Deep_Supervision(model, 5, ssn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee521ad-f14d-46f7-9369-f96b9eaeabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = [ssn_model] + [SSN_Wrapped_Deep_Supervision(get_model(), 5, ssn_config) for _ in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d7e873-f4c0-4328-bd61-0db14b041b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a76753a-b22d-4e03-9c0c-a45f9df8d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_preds(cv_fold, model=model, model_name=\"nnunet\", ckpt_path=None, model_func=deterministic_mean, do_reorder_samples=False, load_ckpt=True, out_domain=True):\n",
    "    if load_ckpt:\n",
    "        model = load_best_checkpoint(model, None, '.', cv_fold, ckpt_path).model\n",
    "\n",
    "    xs3d_test, ys3d_test, gt_vols = load_cv_test_set(cv_fold)\n",
    "\n",
    "    means, samples, miscs = get_means_and_samples_2D(model, zip(xs3d_test, ys3d_test), 10, model_func, args=args)\n",
    "\n",
    "    print(means[0].shape, samples[0].shape, ys3d_test[0].shape)\n",
    "\n",
    "    means = [m.squeeze(0).swapaxes(0, 1) for m in means]\n",
    "    means = [m[:,:2] for m in means]\n",
    "    if samples[0] is not None:\n",
    "        samples = [s.swapaxes(2, 3) for s in samples]\n",
    "        samples = [s[:,:,:,:2].squeeze() for s in samples]\n",
    "        \n",
    "\n",
    "    print(means[0].shape, samples[0].shape)\n",
    "\n",
    "    chal_results = per_model_chal_stats(means, ys3d_test)\n",
    "\n",
    "    rmses = []\n",
    "    for m, y in zip(means, ys3d_test):\n",
    "        m = m.cuda()\n",
    "        m = m.softmax(dim=1)[:,:2]\n",
    "        rmses.append(fast_rmse(m, y.cuda()).cpu())\n",
    "    rmses = torch.Tensor(rmses)\n",
    "    chal_results['rmse'] = rmses\n",
    "\n",
    "    chal_results['gt_vols'] = gt_vols\n",
    "\n",
    "    # run the evaluation on the samples\n",
    "    print(\"GETTING PER SAMPLE RESULTS\")\n",
    "    if samples[0] is not None:\n",
    "        if do_reorder_samples:\n",
    "            samples = [reorder_samples(s) for s in samples]\n",
    "        sample_top_dices, sample_dices = per_sample_metric(samples, ys3d_test, f=fast_dice, do_argmax=True, do_softmax=False, minimise=False)\n",
    "        sample_best_avds, sample_avds = per_sample_metric(samples, ys3d_test, f=fast_avd, do_argmax=True, do_softmax=False, minimise=True)\n",
    "        sample_best_rmses, sample_rmses = per_sample_metric(samples, ys3d_test, f=fast_rmse, do_argmax=False, do_softmax=True, minimise=True)\n",
    "    \n",
    "        # best dice, avd, rmse\n",
    "        chal_results['best_dice'] = sample_top_dices\n",
    "        chal_results['best_avd'] = sample_best_avds\n",
    "        chal_results['best_rmse'] = sample_best_rmses\n",
    "        \n",
    "        _, sample_vds = per_sample_metric(samples, ys3d_test, f=fast_vd, do_argmax=True, do_softmax=False, minimise=True, take_abs=False)\n",
    "        sample_vd_skew = torch.from_numpy(scipy.stats.skew(sample_vds, axis=1, bias=True))\n",
    "    \n",
    "        # vd of the sample distribution\n",
    "        chal_results['sample_vd_skew'] = sample_vd_skew\n",
    "        for s in range(sample_vds.shape[1]):\n",
    "            chal_results[f'sample_{s}_vd'] = sample_vds[:,s]\n",
    "            \n",
    "        # ged score\n",
    "        geds = iou_GED(means, ys3d_test, samples)\n",
    "        chal_results['GED^2'] = geds\n",
    "\n",
    "    # get the uncertainty maps\n",
    "    print(\"GENREATING UNCERTAINTY MAPS\")\n",
    "    uncertainty_thresholds = torch.arange(0, 0.7, 0.01)\n",
    "    ent_maps = get_uncertainty_maps(means, samples, miscs, args)\n",
    "\n",
    "    # pavpu\n",
    "    print(\"PAVPU\")\n",
    "    all_acc_cert, all_uncert_inacc,all_pavpu = all_individuals_pavpu(means, ent_maps, ys3d_test, 4, 0.8, uncertainty_thresholds)\n",
    "    \n",
    "    for i, tau in enumerate(uncertainty_thresholds):\n",
    "        chal_results[f'p_acc_cert_{tau:.2f}'] = all_acc_cert[:,i]\n",
    "        chal_results[f'p_uncert_inacc_{tau:.2f}'] = all_uncert_inacc[:,i]\n",
    "        chal_results[f'pavpu_{tau:.2f}'] = all_pavpu[:,i]\n",
    "    \n",
    "    # sUEO score and UEO per threshold\n",
    "    print(\"UEO\")\n",
    "    sUEOs = get_sUEOs(means, ys3d_test, ent_maps)\n",
    "    chal_results['sUEO'] = sUEOs\n",
    "    ueos = UEO_per_threshold_analysis(uncertainty_thresholds, ys3d_test, ent_maps, means, 0.7)\n",
    "    for i, tau in enumerate(uncertainty_thresholds):\n",
    "        chal_results[f'UEO_{tau:.2f}'] = ueos[i]\n",
    "    \n",
    "    # 3D connected component analysis\n",
    "    print(\"3D CC ANALYSIS\")\n",
    "    num_lesions_all, sizes_all, mean_missed_area3d_all, mean_size_missed_lesions3d_all, mean_cov_mean_missed_lesions3d_all, prop_lesions_missed3d_all = do_3d_cc_analysis_per_individual(means, ys3d_test, ent_maps, uncertainty_thresholds)\n",
    "    for i, tau in enumerate(uncertainty_thresholds):\n",
    "        chal_results[f'mean_missed_area3d_all_{tau:.2f}'] = torch.stack(mean_missed_area3d_all)[:,i]\n",
    "        chal_results[f'mean_cov_mean_missed_lesions3d_all_{tau:.2f}'] = torch.stack(mean_cov_mean_missed_lesions3d_all)[:,i]\n",
    "        chal_results[f'mean_size_missed_lesions3d_all_{tau:.2f}'] = torch.stack(mean_size_missed_lesions3d_all)[:,i]\n",
    "        chal_results[f'prop_lesions_missed3d_all_{tau:.2f}'] = torch.stack(prop_lesions_missed3d_all)[:,i]\n",
    "        \n",
    "\n",
    "    # save the results\n",
    "    print(\"SAVING RESULTS\")\n",
    "    domain_folder = \"out_domain_results\" if out_domain else \"in_domain_results\"\n",
    "    results_out_dir = f\"/home/s2208943/ipdis/WMH_UQ_assessment/trustworthai/journal_run/evaluation/results/cross_validated_results/{domain_folder}/\"\n",
    "    write_per_model_channel_stats(results_out_dir, model_name, f\"{model_name}0_cv{cv_fold}\", preds=None, ys3d_test=None, args=args, chal_results=chal_results)\n",
    "    \n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7892c1b-68c4-4c2a-b3de-13fa4ae3153a",
   "metadata": {},
   "source": [
    "### X2 SSN Ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a3adc-05fc-4b20-9b95-6506880198d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5456d36e-1692-4259-9ec6-1c6fb7e4c6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens0_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens1_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens2_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens3_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens4_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens5_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens6_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens7_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens8_cv0\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens9_cv0\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [01:25,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 48, 192, 192]) torch.Size([10, 1, 2, 48, 192, 192]) torch.Size([48, 192, 192])\n",
      "torch.Size([48, 2, 192, 192]) torch.Size([10, 48, 2, 192, 192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:43<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00, 10.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00,  9.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:05<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENREATING UNCERTAINTY MAPS\n",
      "ssn\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 28.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:07<00:00,  5.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:20<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens0_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens1_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens2_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens3_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens4_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens5_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens6_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens7_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens8_cv1\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens9_cv1\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [01:25,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 48, 192, 192]) torch.Size([10, 1, 2, 48, 192, 192]) torch.Size([48, 192, 192])\n",
      "torch.Size([48, 2, 192, 192]) torch.Size([10, 48, 2, 192, 192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:43<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00, 10.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00, 10.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:05<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENREATING UNCERTAINTY MAPS\n",
      "ssn\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:07<00:00,  5.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:25<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens0_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens1_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens2_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens3_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens4_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens5_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens6_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens7_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens8_cv2\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens9_cv2\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [01:25,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 48, 192, 192]) torch.Size([10, 1, 2, 48, 192, 192]) torch.Size([48, 192, 192])\n",
      "torch.Size([48, 2, 192, 192]) torch.Size([10, 48, 2, 192, 192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:42<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00, 10.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00, 10.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:05<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENREATING UNCERTAINTY MAPS\n",
      "ssn\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:07<00:00,  5.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:13<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens0_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens1_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens2_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens3_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens4_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens5_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens6_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens7_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens8_cv3\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens9_cv3\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [01:25,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 48, 192, 192]) torch.Size([10, 1, 2, 48, 192, 192]) torch.Size([48, 192, 192])\n",
      "torch.Size([48, 2, 192, 192]) torch.Size([10, 48, 2, 192, 192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:42<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00, 10.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00,  9.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:05<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENREATING UNCERTAINTY MAPS\n",
      "ssn\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:07<00:00,  5.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:20<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens0_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens1_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens2_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens3_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens4_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens5_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens6_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens7_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens8_cv4\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens9_cv4\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [01:25,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 48, 192, 192]) torch.Size([10, 1, 2, 48, 192, 192]) torch.Size([48, 192, 192])\n",
      "torch.Size([48, 2, 192, 192]) torch.Size([10, 48, 2, 192, 192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:42<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00, 10.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:04<00:00,  9.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 10.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:05<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENREATING UNCERTAINTY MAPS\n",
      "ssn\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:03<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:01<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:07<00:00,  5.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:29<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens0_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens1_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens2_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens3_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens4_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens5_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens6_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens7_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens8_cv5\n",
      "model dir:  /home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/nnunet2D_ssnX2_ens9_cv5\n",
      "175 35 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [01:21,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 48, 192, 192]) torch.Size([10, 1, 2, 48, 192, 192]) torch.Size([48, 192, 192])\n",
      "torch.Size([48, 2, 192, 192]) torch.Size([10, 48, 2, 192, 192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:42<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 10.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 10.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:04<00:00,  9.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 10.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:05<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENREATING UNCERTAINTY MAPS\n",
      "ssn\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:07<00:00,  5.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:08<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [01:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"/home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts_redo/\"\n",
    "\n",
    "for cv_split in range(6):\n",
    "    loaded_ensemble_models = []\n",
    "    for m in range(10):\n",
    "        model_dir = os.path.join(base_folder, f\"nnunet2D_ssnX2_ens{m}_cv{cv_split}\")  \n",
    "        print(\"model dir: \", model_dir)\n",
    "        ckpt = sorted([f for f in os.listdir(model_dir) if f.endswith(\".ckpt\")])[-1]\n",
    "        \n",
    "        loaded_ensemble_models.append(load_best_checkpoint(ensemble_models[m], None, None, None, os.path.join(model_dir, ckpt)).model.cuda())\n",
    "    \n",
    "    get_model_preds(cv_split, model=loaded_ensemble_models, model_name=\"SsnEnsNnunet2DX2\", ckpt_path=None, model_func=ssn_ensemble_mean_and_samples, load_ckpt=False, out_domain=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315e45e-c30e-4b2d-80a4-ad56f8ee7bb6",
   "metadata": {},
   "source": [
    "### SSN X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b01333-7a24-4eba-a39b-cfef88cfc33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee11eb2-ba01-4d92-960f-81613d6ed730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ca087-a27a-4fc3-969a-a87045d84807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6a088-bd9b-493d-bb25-f882c8eb9ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b80ad-20ff-4bb4-8727-8c9282866b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
