{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7705cec-1a60-40eb-8a22-3dc28bea40fa",
   "metadata": {},
   "source": [
    "### running the evaluation for the challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1924ce-955d-4eac-99bf-5962f5cb6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63cf7422-bf0a-45bd-b171-2ded47bd5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa14325f-b699-4d1d-806c-11ab977230d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from collections import defaultdict, namedtuple\n",
    "import pandas as pd\n",
    "# import proplot as pplt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # I should only put this in place when I am doing plotting and using proplot....\n",
    "from twaibrain.braintorch.utils.resize import crop_or_pad_dims\n",
    "from twaibrain.brainpreprep.utils.image_io import load_image\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "# model architecture\n",
    "import json\n",
    "from twaibrain.braintorch.models.nnUNet.nnUNetV2_model_loader import get_network_from_plans\n",
    "from twaibrain.braintorch.models.ssn import SSN_Wrapped_Deep_Supervision, SSN_Wrapped_Deep_Supervision_LLO, Hierarchical_SSN_with_ConvRefine, Hierarchical_SSN_with_ConvSpatialAttention\n",
    "\n",
    "# fitting code\n",
    "from twaibrain.braintorch.fitting_and_inference.get_trainer import get_trainer\n",
    "from twaibrain.braintorch.fitting_and_inference.get_scratch_dir import scratch_dir\n",
    "from twaibrain.braintorch.fitting_and_inference.optimizer_constructor import OptimizerConfigurator\n",
    "from twaibrain.braintorch.fitting_and_inference.lightning_fitter import StandardLitModelWrapper\n",
    "\n",
    "# loss function\n",
    "from twaibrain.braintorch.losses.ssn_losses import DeepSupervisionSSN, SSNCombinedDiceXent_and_MC_loss, SSNCombinedDiceXent_and_MC_loss_FromSamples\n",
    "from twaibrain.braintorch.losses.generic_deep_supervision import MultiDeepSupervisionLoss, DeepSupervisionLoss\n",
    "from twaibrain.braintorch.losses.dice_loss import SoftDiceV2\n",
    "from twaibrain.braintorch.losses.xent import dice_xent_loss\n",
    "\n",
    "# data\n",
    "from twaibrain.brainexperiments.run_nnUNet_v2.old_dataloading.dataset_pipelines import load_data\n",
    "from twaibrain.braintorch.data.legacy_dataset_types.dataset_wrappers import MonaiAugmentedDataset\n",
    "from twaibrain.braintorch.augmentation.nnunet_augmentations import get_nnunet_transforms, get_val_transforms\n",
    "from torch.utils.data import ConcatDataset\n",
    "from twaibrain.braintorch.data.legacy_dataset_types.mri_dataset_inram import MRISegmentation3DDataset\n",
    "from twaibrain.braintorch.data.legacy_dataset_types.mri_dataset_from_file import MRISegmentationDatasetFromFile, ArrayMRISegmentationDatasetFromFile\n",
    "from twaibrain.braintorch.data.legacy_dataset_types.mri_dataset_directory_parsers import *\n",
    "\n",
    "# evaluation code\n",
    "from twaibrain.brainexperiments.run_nnUNet_v2.evaluation.eval_helper_functions import *\n",
    "from twaibrain.brainexperiments.run_nnUNet_v2.evaluation.model_predictions import get_means_and_samples_2D, ssn_ensemble_mean_and_samples\n",
    "from twaibrain.brainexperiments.run_nnUNet_v2.evaluation.model_predictions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ee30e-c703-4087-9cbf-960cd128ac38",
   "metadata": {},
   "source": [
    "### setting up params for the rest of the code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2162225-8732-4b26-a257-a8a33bd9b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = namedtuple(\"args\", \"dataset test_split val_split seed \" + \n",
    "                  \"empty_slice_retention batch_size cross_validate cv_split cv_test_fold_smooth no_test_fold \" +\n",
    "                  \"num_workers dice_factor xent_factor xent_reweighting eval_split uncertainty_type ckpt_dir\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7526adce-3f7e-473b-914c-a5494205ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOXELS_TO_WMH_RATIO = 382\n",
    "VOXELS_TO_WMH_RATIO_EXCLUDING_EMPTY_SLICES = 140\n",
    "ESR = 0.5\n",
    "\n",
    "\n",
    "# setup xent reweighting factor\n",
    "XENT_VOXEL_RESCALE = VOXELS_TO_WMH_RATIO - (1-ESR) * (VOXELS_TO_WMH_RATIO - VOXELS_TO_WMH_RATIO_EXCLUDING_EMPTY_SLICES)\n",
    "\n",
    "XENT_WEIGHTING = XENT_VOXEL_RESCALE/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cac5d8e-f4b5-4f59-ae62-2b00f0052dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ARGS(\n",
    "    dataset = \"ed\",\n",
    "    \n",
    "    test_split=0.15,\n",
    "    val_split=0.15,\n",
    "    eval_split='test',\n",
    "\n",
    "    seed=5,\n",
    "\n",
    "    empty_slice_retention=ESR,\n",
    "\n",
    "    uncertainty_type=\"deterministic\",\n",
    "\n",
    "    batch_size=2,\n",
    "    cross_validate=True,\n",
    "    cv_split=0,\n",
    "    cv_test_fold_smooth=1,\n",
    "    no_test_fold=\"false\",\n",
    "    num_workers=16,\n",
    "\n",
    "    dice_factor=1,\n",
    "    xent_factor=1,\n",
    "    xent_reweighting=XENT_WEIGHTING,\n",
    "    ckpt_dir= \"/home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/ssn_model_ckpts/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fb744-1fc3-42d7-b839-291269aac125",
   "metadata": {},
   "source": [
    "### loading eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d644bf7-475f-4c17-8310-3992d81b22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cv_test_set(cv_split):\n",
    "\n",
    "    data_dict = load_data(\n",
    "        dataset=args.dataset, \n",
    "        test_proportion=args.test_split, \n",
    "        validation_proportion=args.val_split,\n",
    "        seed=args.seed,\n",
    "        empty_proportion_retained=args.empty_slice_retention,\n",
    "        batch_size=args.batch_size,\n",
    "        dataloader2d_only=False,\n",
    "        cross_validate=True,\n",
    "        cv_split=cv_split,\n",
    "        cv_test_fold_smooth=args.cv_test_fold_smooth,\n",
    "        merge_val_test=args.no_test_fold\n",
    "    )\n",
    "    \n",
    "    if args.eval_split == \"all\":\n",
    "        eval_ds = ConcatDataset([data_dict['train_dataset3d'], data_dict['val_dataset3d'], data_dict['test_dataset3d']])\n",
    "    else:\n",
    "        eval_ds = data_dict[f'{args.eval_split}_dataset3d']\n",
    "    \n",
    "    # get the xs and ys\n",
    "    xs3d_test = []\n",
    "    ys3d_test = []\n",
    "    \n",
    "    for i, data in enumerate(eval_ds):\n",
    "        ys3d_test.append(data[1].squeeze())\n",
    "        xs3d_test.append(data[0])\n",
    "    \n",
    "    ys3d_test = [y * (y==1).type(y.dtype) for y in ys3d_test] # fix bug with challenge data having 3 classes on cluster only?\n",
    "    gt_vols = GT_volumes(ys3d_test)\n",
    "    \n",
    "    # to run on the nnUnet version of the model,\n",
    "    # I should crop the x and y to the min and max points\n",
    "    # this will also effectively centre the images for evaluation.\n",
    "    for i in range(len(xs3d_test)):\n",
    "        x = xs3d_test[i]\n",
    "        y = ys3d_test[i]\n",
    "        wheres = torch.where(x[-1])\n",
    "        zs = (wheres[0].min().item(), wheres[0].max().item())\n",
    "        xs = (wheres[1].min().item(), wheres[1].max().item())\n",
    "        ys = (wheres[2].min().item(), wheres[2].max().item())\n",
    "        # print(zs, xs, ys)\n",
    "        # print(x.shape, y.shape)\n",
    "    \n",
    "        x = x[:, zs[0]:zs[1]+1, xs[0]:xs[1]+1, ys[0]:ys[1]+1]\n",
    "        y = y[zs[0]:zs[1]+1, xs[0]:xs[1]+1, ys[0]:ys[1]+1]\n",
    "    \n",
    "        # print(x.shape, y.shape)\n",
    "        \n",
    "        x = crop_or_pad_dims(x, [1,2,3], [48, 192, 192])\n",
    "        y = crop_or_pad_dims(y, [0,1,2], [48, 192, 192])\n",
    "    \n",
    "        x = x.unsqueeze(0)\n",
    "    \n",
    "        # print(x.shape, y.shape)\n",
    "        # print()\n",
    "        xs3d_test[i] = x\n",
    "        ys3d_test[i] = y\n",
    "\n",
    "    return xs3d_test, ys3d_test, gt_vols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb569f9-1531-47f4-8275-faaf9e030654",
   "metadata": {},
   "source": [
    "### load a model checkpoint and get relevant predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306bae4d-122d-405c-bdf8-475bf2de1471",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = \"/home/s2208943/projects/twaibrain/twaibrain/braintorch/models/nnUNet/cvd_configs/nnUNetResEncUNetMPlans.json\"\n",
    "\n",
    "with open(model_config) as f:\n",
    "    model_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6095ad18-3907-4d2f-96a1-1cea9900b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = \"2d\"\n",
    "config = model_config['configurations'][dims]['architecture']\n",
    "network_name = config['network_class_name']\n",
    "kw_requires_import = config['_kw_requires_import']\n",
    "\n",
    "def get_model():\n",
    "    return get_network_from_plans(\n",
    "        arch_class_name=network_name,\n",
    "        arch_kwargs=config['arch_kwargs'],\n",
    "        arch_kwargs_req_import=kw_requires_import,\n",
    "        input_channels=3,\n",
    "        output_channels=2,\n",
    "        allow_init=True,\n",
    "        deep_supervision=True,\n",
    "    )\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a76753a-b22d-4e03-9c0c-a45f9df8d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_preds(cv_fold, model=model, model_name=\"nnunet\", ckpt_path=None, model_func=deterministic_mean, do_reorder_samples=False, load_ckpt=True, out_domain=True):\n",
    "    if load_ckpt:\n",
    "        model = load_best_checkpoint(model, None, '.', cv_fold, ckpt_path).model\n",
    "\n",
    "    xs3d_test, ys3d_test, gt_vols = load_cv_test_set(int(cv_fold))\n",
    "\n",
    "    means, samples, miscs = get_means_and_samples_2D(model, zip(xs3d_test, ys3d_test), 10, model_func, args=args)\n",
    "\n",
    "    means = [m.squeeze(0).swapaxes(0, 1) for m in means]\n",
    "    means = [m[:,:2] for m in means]\n",
    "    if samples[0] is not None:\n",
    "        samples = [s.swapaxes(2, 3) for s in samples]\n",
    "        samples = [s[:,:,:,:2].squeeze() for s in samples]\n",
    "\n",
    "    chal_results = per_model_chal_stats(means, ys3d_test)\n",
    "\n",
    "    rmses = []\n",
    "    for m, y in zip(means, ys3d_test):\n",
    "        m = m.cuda()\n",
    "        m = m.softmax(dim=1)[:,:2]\n",
    "        rmses.append(fast_rmse(m, y.cuda()).cpu())\n",
    "    rmses = torch.Tensor(rmses)\n",
    "    chal_results['rmse'] = rmses\n",
    "\n",
    "    chal_results['gt_vols'] = gt_vols\n",
    "\n",
    "    # run the evaluation on the samples\n",
    "    print(\"GETTING PER SAMPLE RESULTS\")\n",
    "    if samples[0] is not None:\n",
    "        if do_reorder_samples:\n",
    "            samples = [reorder_samples(s) for s in samples]\n",
    "        sample_top_dices, sample_dices = per_sample_metric(samples, ys3d_test, f=fast_dice, do_argmax=True, do_softmax=False, minimise=False)\n",
    "        sample_best_avds, sample_avds = per_sample_metric(samples, ys3d_test, f=fast_avd, do_argmax=True, do_softmax=False, minimise=True)\n",
    "        sample_best_rmses, sample_rmses = per_sample_metric(samples, ys3d_test, f=fast_rmse, do_argmax=False, do_softmax=True, minimise=True)\n",
    "    \n",
    "        # best dice, avd, rmse\n",
    "        chal_results['best_dice'] = sample_top_dices\n",
    "        chal_results['best_avd'] = sample_best_avds\n",
    "        chal_results['best_rmse'] = sample_best_rmses\n",
    "        \n",
    "        _, sample_vds = per_sample_metric(samples, ys3d_test, f=fast_vd, do_argmax=True, do_softmax=False, minimise=True, take_abs=False)\n",
    "        sample_vd_skew = torch.from_numpy(scipy.stats.skew(sample_vds, axis=1, bias=True))\n",
    "    \n",
    "        # vd of the sample distribution\n",
    "        chal_results['sample_vd_skew'] = sample_vd_skew\n",
    "        for s in range(sample_vds.shape[1]):\n",
    "            chal_results[f'sample_{s}_vd'] = sample_vds[:,s]\n",
    "            \n",
    "        # ged score\n",
    "        geds = iou_GED(means, ys3d_test, samples)\n",
    "        chal_results['GED^2'] = geds\n",
    "\n",
    "    # get the uncertainty maps\n",
    "    print(\"GENREATING UNCERTAINTY MAPS\")\n",
    "    uncertainty_thresholds = torch.arange(0, 0.7, 0.01)\n",
    "    ent_maps = get_uncertainty_maps(means, samples, miscs, args)\n",
    "\n",
    "    # pavpu\n",
    "    print(\"PAVPU\")\n",
    "    all_acc_cert, all_uncert_inacc,all_pavpu = all_individuals_pavpu(means, ent_maps, ys3d_test, 4, 0.8, uncertainty_thresholds)\n",
    "    \n",
    "    for i, tau in enumerate(uncertainty_thresholds):\n",
    "        chal_results[f'p_acc_cert_{tau:.2f}'] = all_acc_cert[:,i]\n",
    "        chal_results[f'p_uncert_inacc_{tau:.2f}'] = all_uncert_inacc[:,i]\n",
    "        chal_results[f'pavpu_{tau:.2f}'] = all_pavpu[:,i]\n",
    "    \n",
    "    # sUEO score and UEO per threshold\n",
    "    print(\"UEO\")\n",
    "    sUEOs = get_sUEOs(means, ys3d_test, ent_maps)\n",
    "    chal_results['sUEO'] = sUEOs\n",
    "    ueos = UEO_per_threshold_analysis(uncertainty_thresholds, ys3d_test, ent_maps, means, 0.7)\n",
    "    for i, tau in enumerate(uncertainty_thresholds):\n",
    "        chal_results[f'UEO_{tau:.2f}'] = ueos[i]\n",
    "    \n",
    "    # 3D connected component analysis\n",
    "    print(\"3D CC ANALYSIS\")\n",
    "    num_lesions_all, sizes_all, mean_missed_area3d_all, mean_size_missed_lesions3d_all, mean_cov_mean_missed_lesions3d_all, prop_lesions_missed3d_all = do_3d_cc_analysis_per_individual(means, ys3d_test, ent_maps, uncertainty_thresholds)\n",
    "    for i, tau in enumerate(uncertainty_thresholds):\n",
    "        chal_results[f'mean_missed_area3d_all_{tau:.2f}'] = torch.stack(mean_missed_area3d_all)[:,i]\n",
    "        chal_results[f'mean_cov_mean_missed_lesions3d_all_{tau:.2f}'] = torch.stack(mean_cov_mean_missed_lesions3d_all)[:,i]\n",
    "        chal_results[f'mean_size_missed_lesions3d_all_{tau:.2f}'] = torch.stack(mean_size_missed_lesions3d_all)[:,i]\n",
    "        chal_results[f'prop_lesions_missed3d_all_{tau:.2f}'] = torch.stack(prop_lesions_missed3d_all)[:,i]\n",
    "        \n",
    "\n",
    "    # save the results\n",
    "    print(\"SAVING RESULTS\")\n",
    "    domain_folder = \"out_domain_results\" if out_domain else \"in_domain_results\"\n",
    "    results_out_dir = f\"/home/s2208943/ipdis/WMH_UQ_assessment/trustworthai/journal_run/evaluation/results/cross_validated_results/{domain_folder}/\"\n",
    "    write_per_model_channel_stats(results_out_dir, model_name, f\"{model_name}0_cv{cv_fold}\", preds=None, ys3d_test=None, args=args, chal_results=chal_results)\n",
    "    \n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c97e0-f770-489e-9976-69561f1b20e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a8d7ef1-c570-4043-91df-9788dcbede3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnunet2D_ens0_cv4\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:08,  5.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:38<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n",
      "GENREATING UNCERTAINTY MAPS\n",
      "deterministic\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 101.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:07<00:00,  5.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:09<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:30<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "nnunet2D_ens0_cv3\n",
      "nnunet2D_ens0_cv0\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:08,  5.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:39<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n",
      "GENREATING UNCERTAINTY MAPS\n",
      "deterministic\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 112.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:09<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:20<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "nnunet2D_ens0_cv2\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:08,  5.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:39<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n",
      "GENREATING UNCERTAINTY MAPS\n",
      "deterministic\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 130.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 18.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:09<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:12<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "nnunet2D_ens0_cv5\n",
      "175 35 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:07,  5.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n",
      "GENREATING UNCERTAINTY MAPS\n",
      "deterministic\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 110.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:07<00:00,  5.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 40/40 [00:08<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 40/40 [01:19<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "nnunet2D_ens0_cv1\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:08,  5.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:38<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n",
      "GENREATING UNCERTAINTY MAPS\n",
      "deterministic\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 115.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 18.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:09<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:23<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"/home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/model_ckpts/\"\n",
    "for folder in os.listdir(base_folder):\n",
    "    if \"3D\" in folder:\n",
    "        continue\n",
    "    print(folder)\n",
    "    cv_split = folder[-1]\n",
    "\n",
    "    if cv_split == \"3\":\n",
    "        continue\n",
    "    \n",
    "    # try:\n",
    "    ckpt = sorted([f for f in os.listdir(os.path.join(base_folder, folder)) if f.endswith(\".ckpt\")])[-1]\n",
    "    get_model_preds(cv_split, model=model, model_name=\"nnunet2D\", ckpt_path=os.path.join(base_folder, folder, ckpt), model_func=deterministic_mean, out_domain=False)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "099400ab-e0d4-47f1-8696-60fbbfa092f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnunet2D_ens0_cv4\n",
      "nnunet2D_ens0_cv3\n",
      "173 35 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:08,  4.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:39<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING PER SAMPLE RESULTS\n",
      "GENREATING UNCERTAINTY MAPS\n",
      "deterministic\n",
      "generating uncertainty maps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 42/42 [00:00<00:00, 105.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAVPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:08<00:00,  5.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 42/42 [00:09<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D CC ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 42/42 [01:20<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING RESULTS\n",
      "DONE\n",
      "nnunet2D_ens0_cv0\n",
      "nnunet2D_ens0_cv2\n",
      "nnunet2D_ens0_cv5\n",
      "nnunet2D_ens0_cv1\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"/home/s2208943/projects/twaibrain/twaibrain/brainexperiments/run_nnUNet_v2/training/model_ckpts/\"\n",
    "for folder in os.listdir(base_folder):\n",
    "    if \"3D\" in folder:\n",
    "        continue\n",
    "    print(folder)\n",
    "    cv_split = folder[-1]\n",
    "\n",
    "    if cv_split != \"3\":\n",
    "        continue\n",
    "    \n",
    "    # try:\n",
    "    ckpt = sorted([f for f in os.listdir(os.path.join(base_folder, folder)) if f.endswith(\".ckpt\")])[-1]\n",
    "    get_model_preds(cv_split, model=model, model_name=\"nnunet2D\", ckpt_path=os.path.join(base_folder, folder, ckpt), model_func=deterministic_mean, out_domain=False)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b7693-a63b-442c-a41e-878064275434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b80ad-20ff-4bb4-8727-8c9282866b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
