digraph {
	graph [size="130.35,130.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140182249393328 [label="
 (1, 2, 256, 256)" fillcolor=darkolivegreen1]
	140182247703696 [label=ConvolutionBackward0]
	140182247703840 -> 140182247703696
	140182247703840 [label=AsStridedBackward0]
	140182247704128 -> 140182247703840
	140182247704128 [label=CopySlices]
	140182247704224 -> 140182247704128
	140182247704224 [label=CudnnBatchNormBackward0]
	140182247703456 -> 140182247704224
	140182247703456 [label=ViewBackward0]
	140182247704416 -> 140182247703456
	140182247704416 [label=ConvolutionBackward0]
	140182247704512 -> 140182247704416
	140182247704512 [label=AsStridedBackward0]
	140182247704704 -> 140182247704512
	140182247704704 [label=CopySlices]
	140182247704800 -> 140182247704704
	140182247704800 [label=CudnnBatchNormBackward0]
	140182247704896 -> 140182247704800
	140182247704896 [label=ViewBackward0]
	140182247705088 -> 140182247704896
	140182247705088 [label=ConvolutionBackward0]
	140182247705184 -> 140182247705088
	140182247705184 [label=CatBackward0]
	140182247705376 -> 140182247705184
	140182247705376 [label=ConvolutionBackward0]
	140182247705520 -> 140182247705376
	140182247705520 [label=AsStridedBackward0]
	140182247705712 -> 140182247705520
	140182247705712 [label=CopySlices]
	140182247705808 -> 140182247705712
	140182247705808 [label=CudnnBatchNormBackward0]
	140182247705904 -> 140182247705808
	140182247705904 [label=ViewBackward0]
	140182247706096 -> 140182247705904
	140182247706096 [label=ConvolutionBackward0]
	140182253715120 -> 140182247706096
	140182253715120 [label=AsStridedBackward0]
	140182672264832 -> 140182253715120
	140182672264832 [label=CopySlices]
	140182247706336 -> 140182672264832
	140182247706336 [label=CudnnBatchNormBackward0]
	140182247706432 -> 140182247706336
	140182247706432 [label=ViewBackward0]
	140182247706624 -> 140182247706432
	140182247706624 [label=ConvolutionBackward0]
	140182247706720 -> 140182247706624
	140182247706720 [label=CatBackward0]
	140182247706912 -> 140182247706720
	140182247706912 [label=ConvolutionBackward0]
	140182247707056 -> 140182247706912
	140182247707056 [label=AsStridedBackward0]
	140182247707248 -> 140182247707056
	140182247707248 [label=CopySlices]
	140182247707344 -> 140182247707248
	140182247707344 [label=CudnnBatchNormBackward0]
	140182247707440 -> 140182247707344
	140182247707440 [label=ViewBackward0]
	140182247707632 -> 140182247707440
	140182247707632 [label=ConvolutionBackward0]
	140182247707728 -> 140182247707632
	140182247707728 [label=AsStridedBackward0]
	140182247707920 -> 140182247707728
	140182247707920 [label=CopySlices]
	140182247708016 -> 140182247707920
	140182247708016 [label=CudnnBatchNormBackward0]
	140182247708112 -> 140182247708016
	140182247708112 [label=ViewBackward0]
	140182247708304 -> 140182247708112
	140182247708304 [label=ConvolutionBackward0]
	140182247708400 -> 140182247708304
	140182247708400 [label=CatBackward0]
	140182247708592 -> 140182247708400
	140182247708592 [label=ConvolutionBackward0]
	140182247708736 -> 140182247708592
	140182247708736 [label=AsStridedBackward0]
	140182247708928 -> 140182247708736
	140182247708928 [label=CopySlices]
	140182247709024 -> 140182247708928
	140182247709024 [label=CudnnBatchNormBackward0]
	140182247709120 -> 140182247709024
	140182247709120 [label=ViewBackward0]
	140182247709312 -> 140182247709120
	140182247709312 [label=ConvolutionBackward0]
	140182247709408 -> 140182247709312
	140182247709408 [label=AsStridedBackward0]
	140182247709600 -> 140182247709408
	140182247709600 [label=CopySlices]
	140182247709696 -> 140182247709600
	140182247709696 [label=CudnnBatchNormBackward0]
	140182247709792 -> 140182247709696
	140182247709792 [label=ViewBackward0]
	140182247709984 -> 140182247709792
	140182247709984 [label=ConvolutionBackward0]
	140182247710080 -> 140182247709984
	140182247710080 [label=CatBackward0]
	140182247710272 -> 140182247710080
	140182247710272 [label=ConvolutionBackward0]
	140182247710416 -> 140182247710272
	140182247710416 [label=AsStridedBackward0]
	140182247710608 -> 140182247710416
	140182247710608 [label=CopySlices]
	140182247710704 -> 140182247710608
	140182247710704 [label=CudnnBatchNormBackward0]
	140182247710800 -> 140182247710704
	140182247710800 [label=ViewBackward0]
	140182247710992 -> 140182247710800
	140182247710992 [label=ConvolutionBackward0]
	140182247711088 -> 140182247710992
	140182247711088 [label=AsStridedBackward0]
	140182247711280 -> 140182247711088
	140182247711280 [label=CopySlices]
	140182247711376 -> 140182247711280
	140182247711376 [label=CudnnBatchNormBackward0]
	140182247711472 -> 140182247711376
	140182247711472 [label=ViewBackward0]
	140182247711664 -> 140182247711472
	140182247711664 [label=ConvolutionBackward0]
	140182247711760 -> 140182247711664
	140182247711760 [label=CatBackward0]
	140182247711952 -> 140182247711760
	140182247711952 [label=ConvolutionBackward0]
	140182247712096 -> 140182247711952
	140182247712096 [label=AsStridedBackward0]
	140182247712288 -> 140182247712096
	140182247712288 [label=CopySlices]
	140182247712384 -> 140182247712288
	140182247712384 [label=CudnnBatchNormBackward0]
	140182247712480 -> 140182247712384
	140182247712480 [label=ViewBackward0]
	140182247712672 -> 140182247712480
	140182247712672 [label=ConvolutionBackward0]
	140182247712768 -> 140182247712672
	140182247712768 [label=AsStridedBackward0]
	140182247712960 -> 140182247712768
	140182247712960 [label=CopySlices]
	140182247713056 -> 140182247712960
	140182247713056 [label=CudnnBatchNormBackward0]
	140182247713152 -> 140182247713056
	140182247713152 [label=ViewBackward0]
	140182247713344 -> 140182247713152
	140182247713344 [label=ConvolutionBackward0]
	140182247713440 -> 140182247713344
	140182247713440 [label=CatBackward0]
	140182247713632 -> 140182247713440
	140182247713632 [label=ConvolutionBackward0]
	140182247713776 -> 140182247713632
	140182247713776 [label=AsStridedBackward0]
	140182247713968 -> 140182247713776
	140182247713968 [label=CopySlices]
	140182247714064 -> 140182247713968
	140182247714064 [label=CudnnBatchNormBackward0]
	140182247714160 -> 140182247714064
	140182247714160 [label=ViewBackward0]
	140182247714352 -> 140182247714160
	140182247714352 [label=ConvolutionBackward0]
	140182247714448 -> 140182247714352
	140182247714448 [label=AsStridedBackward0]
	140182247714640 -> 140182247714448
	140182247714640 [label=CopySlices]
	140182247714736 -> 140182247714640
	140182247714736 [label=CudnnBatchNormBackward0]
	140182247714832 -> 140182247714736
	140182247714832 [label=ViewBackward0]
	140182247715024 -> 140182247714832
	140182247715024 [label=ConvolutionBackward0]
	140182247713584 -> 140182247715024
	140182247713584 [label=AsStridedBackward0]
	140182247715264 -> 140182247713584
	140182247715264 [label=CopySlices]
	140182247715360 -> 140182247715264
	140182247715360 [label=CudnnBatchNormBackward0]
	140182247715456 -> 140182247715360
	140182247715456 [label=ViewBackward0]
	140182247715648 -> 140182247715456
	140182247715648 [label=ConvolutionBackward0]
	140182247715744 -> 140182247715648
	140182247715744 [label=AsStridedBackward0]
	140182247715936 -> 140182247715744
	140182247715936 [label=CopySlices]
	140182247716032 -> 140182247715936
	140182247716032 [label=CudnnBatchNormBackward0]
	140182247716128 -> 140182247716032
	140182247716128 [label=ViewBackward0]
	140182247716320 -> 140182247716128
	140182247716320 [label=ConvolutionBackward0]
	140182247711904 -> 140182247716320
	140182247711904 [label=AsStridedBackward0]
	140182247716560 -> 140182247711904
	140182247716560 [label=CopySlices]
	140182247716656 -> 140182247716560
	140182247716656 [label=CudnnBatchNormBackward0]
	140182247716752 -> 140182247716656
	140182247716752 [label=ViewBackward0]
	140182247716944 -> 140182247716752
	140182247716944 [label=ConvolutionBackward0]
	140182247717040 -> 140182247716944
	140182247717040 [label=AsStridedBackward0]
	140182247717232 -> 140182247717040
	140182247717232 [label=CopySlices]
	140182247717328 -> 140182247717232
	140182247717328 [label=CudnnBatchNormBackward0]
	140182247717424 -> 140182247717328
	140182247717424 [label=ViewBackward0]
	140182247717616 -> 140182247717424
	140182247717616 [label=ConvolutionBackward0]
	140182247710224 -> 140182247717616
	140182247710224 [label=AsStridedBackward0]
	140182247717856 -> 140182247710224
	140182247717856 [label=CopySlices]
	140182247717952 -> 140182247717856
	140182247717952 [label=CudnnBatchNormBackward0]
	140182247718048 -> 140182247717952
	140182247718048 [label=ViewBackward0]
	140182247718240 -> 140182247718048
	140182247718240 [label=ConvolutionBackward0]
	140182247718336 -> 140182247718240
	140182247718336 [label=AsStridedBackward0]
	140182247718528 -> 140182247718336
	140182247718528 [label=CopySlices]
	140182247718624 -> 140182247718528
	140182247718624 [label=CudnnBatchNormBackward0]
	140182247718720 -> 140182247718624
	140182247718720 [label=ViewBackward0]
	140182247718864 -> 140182247718720
	140182247718864 [label=ConvolutionBackward0]
	140182247708544 -> 140182247718864
	140182247708544 [label=AsStridedBackward0]
	140182247751984 -> 140182247708544
	140182247751984 [label=CopySlices]
	140182247752080 -> 140182247751984
	140182247752080 [label=CudnnBatchNormBackward0]
	140182247752176 -> 140182247752080
	140182247752176 [label=ViewBackward0]
	140182247752368 -> 140182247752176
	140182247752368 [label=ConvolutionBackward0]
	140182247752464 -> 140182247752368
	140182247752464 [label=AsStridedBackward0]
	140182247752656 -> 140182247752464
	140182247752656 [label=CopySlices]
	140182247752752 -> 140182247752656
	140182247752752 [label=CudnnBatchNormBackward0]
	140182247752848 -> 140182247752752
	140182247752848 [label=ViewBackward0]
	140182247753040 -> 140182247752848
	140182247753040 [label=ConvolutionBackward0]
	140182247706864 -> 140182247753040
	140182247706864 [label=AsStridedBackward0]
	140182247753280 -> 140182247706864
	140182247753280 [label=CopySlices]
	140182247753376 -> 140182247753280
	140182247753376 [label=CudnnBatchNormBackward0]
	140182247753472 -> 140182247753376
	140182247753472 [label=ViewBackward0]
	140182247753664 -> 140182247753472
	140182247753664 [label=ConvolutionBackward0]
	140182247753760 -> 140182247753664
	140182247753760 [label=AsStridedBackward0]
	140182247753952 -> 140182247753760
	140182247753952 [label=CopySlices]
	140182247754048 -> 140182247753952
	140182247754048 [label=CudnnBatchNormBackward0]
	140182247754144 -> 140182247754048
	140182247754144 [label=ViewBackward0]
	140182247754336 -> 140182247754144
	140182247754336 [label=ConvolutionBackward0]
	140182247705328 -> 140182247754336
	140182247705328 [label=AsStridedBackward0]
	140182247754576 -> 140182247705328
	140182247754576 [label=CopySlices]
	140182247754672 -> 140182247754576
	140182247754672 [label=CudnnBatchNormBackward0]
	140182247754768 -> 140182247754672
	140182247754768 [label=ViewBackward0]
	140182247754960 -> 140182247754768
	140182247754960 [label=ConvolutionBackward0]
	140182247755056 -> 140182247754960
	140182247755056 [label=AsStridedBackward0]
	140182247755248 -> 140182247755056
	140182247755248 [label=CopySlices]
	140182247755344 -> 140182247755248
	140182247755344 [label=CudnnBatchNormBackward0]
	140182247755440 -> 140182247755344
	140182247755440 [label=ViewBackward0]
	140182247755632 -> 140182247755440
	140182247755632 [label=ConvolutionBackward0]
	140182247755728 -> 140182247755632
	140182675105520 [label="encoder.stages.0.0.convs.0.conv.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	140182675105520 -> 140182247755728
	140182247755728 [label=AccumulateGrad]
	140182247755680 -> 140182247755632
	140182675105616 [label="encoder.stages.0.0.convs.0.conv.bias
 (32)" fillcolor=lightblue]
	140182675105616 -> 140182247755680
	140182247755680 [label=AccumulateGrad]
	140182247755392 -> 140182247755344
	140182247755392 [label=RepeatBackward0]
	140182247755776 -> 140182247755392
	140182675105712 [label="encoder.stages.0.0.convs.0.norm.weight
 (32)" fillcolor=lightblue]
	140182675105712 -> 140182247755776
	140182247755776 [label=AccumulateGrad]
	140182247755152 -> 140182247755344
	140182247755152 [label=RepeatBackward0]
	140182247755824 -> 140182247755152
	140182675105808 [label="encoder.stages.0.0.convs.0.norm.bias
 (32)" fillcolor=lightblue]
	140182675105808 -> 140182247755824
	140182247755824 [label=AccumulateGrad]
	140182247755008 -> 140182247754960
	140182675105904 [label="encoder.stages.0.0.convs.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140182675105904 -> 140182247755008
	140182247755008 [label=AccumulateGrad]
	140182247754864 -> 140182247754960
	140182675106000 [label="encoder.stages.0.0.convs.1.conv.bias
 (32)" fillcolor=lightblue]
	140182675106000 -> 140182247754864
	140182247754864 [label=AccumulateGrad]
	140182247754720 -> 140182247754672
	140182247754720 [label=RepeatBackward0]
	140182247706144 -> 140182247754720
	140182675106096 [label="encoder.stages.0.0.convs.1.norm.weight
 (32)" fillcolor=lightblue]
	140182675106096 -> 140182247706144
	140182247706144 [label=AccumulateGrad]
	140182247754480 -> 140182247754672
	140182247754480 [label=RepeatBackward0]
	140180619140672 -> 140182247754480
	140182675106192 [label="encoder.stages.0.0.convs.1.norm.bias
 (32)" fillcolor=lightblue]
	140182675106192 -> 140180619140672
	140180619140672 [label=AccumulateGrad]
	140182247754432 -> 140182247754336
	140182675106288 [label="encoder.stages.1.0.convs.0.conv.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140182675106288 -> 140182247754432
	140182247754432 [label=AccumulateGrad]
	140182247754384 -> 140182247754336
	140182675106384 [label="encoder.stages.1.0.convs.0.conv.bias
 (64)" fillcolor=lightblue]
	140182675106384 -> 140182247754384
	140182247754384 [label=AccumulateGrad]
	140182247754096 -> 140182247754048
	140182247754096 [label=RepeatBackward0]
	140180619144512 -> 140182247754096
	140182675106480 [label="encoder.stages.1.0.convs.0.norm.weight
 (64)" fillcolor=lightblue]
	140182675106480 -> 140180619144512
	140180619144512 [label=AccumulateGrad]
	140182247753856 -> 140182247754048
	140182247753856 [label=RepeatBackward0]
	140182650410256 -> 140182247753856
	140182675106576 [label="encoder.stages.1.0.convs.0.norm.bias
 (64)" fillcolor=lightblue]
	140182675106576 -> 140182650410256
	140182650410256 [label=AccumulateGrad]
	140182247753712 -> 140182247753664
	140182675106672 [label="encoder.stages.1.0.convs.1.conv.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140182675106672 -> 140182247753712
	140182247753712 [label=AccumulateGrad]
	140182247753568 -> 140182247753664
	140182675106768 [label="encoder.stages.1.0.convs.1.conv.bias
 (64)" fillcolor=lightblue]
	140182675106768 -> 140182247753568
	140182247753568 [label=AccumulateGrad]
	140182247753424 -> 140182247753376
	140182247753424 [label=RepeatBackward0]
	140182650406560 -> 140182247753424
	140182675106864 [label="encoder.stages.1.0.convs.1.norm.weight
 (64)" fillcolor=lightblue]
	140182675106864 -> 140182650406560
	140182650406560 [label=AccumulateGrad]
	140182247753184 -> 140182247753376
	140182247753184 [label=RepeatBackward0]
	140182650407088 -> 140182247753184
	140182675106960 [label="encoder.stages.1.0.convs.1.norm.bias
 (64)" fillcolor=lightblue]
	140182675106960 -> 140182650407088
	140182650407088 [label=AccumulateGrad]
	140182247753136 -> 140182247753040
	140182675107056 [label="encoder.stages.2.0.convs.0.conv.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140182675107056 -> 140182247753136
	140182247753136 [label=AccumulateGrad]
	140182247753088 -> 140182247753040
	140182675107152 [label="encoder.stages.2.0.convs.0.conv.bias
 (128)" fillcolor=lightblue]
	140182675107152 -> 140182247753088
	140182247753088 [label=AccumulateGrad]
	140182247752800 -> 140182247752752
	140182247752800 [label=RepeatBackward0]
	140182650408528 -> 140182247752800
	140182675107248 [label="encoder.stages.2.0.convs.0.norm.weight
 (128)" fillcolor=lightblue]
	140182675107248 -> 140182650408528
	140182650408528 [label=AccumulateGrad]
	140182247752560 -> 140182247752752
	140182247752560 [label=RepeatBackward0]
	140182650405792 -> 140182247752560
	140182675107344 [label="encoder.stages.2.0.convs.0.norm.bias
 (128)" fillcolor=lightblue]
	140182675107344 -> 140182650405792
	140182650405792 [label=AccumulateGrad]
	140182247752416 -> 140182247752368
	140182675104944 [label="encoder.stages.2.0.convs.1.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140182675104944 -> 140182247752416
	140182247752416 [label=AccumulateGrad]
	140182247752272 -> 140182247752368
	140182675103984 [label="encoder.stages.2.0.convs.1.conv.bias
 (128)" fillcolor=lightblue]
	140182675103984 -> 140182247752272
	140182247752272 [label=AccumulateGrad]
	140182247752128 -> 140182247752080
	140182247752128 [label=RepeatBackward0]
	140182650410352 -> 140182247752128
	140182675107440 [label="encoder.stages.2.0.convs.1.norm.weight
 (128)" fillcolor=lightblue]
	140182675107440 -> 140182650410352
	140182650410352 [label=AccumulateGrad]
	140182247751888 -> 140182247752080
	140182247751888 [label=RepeatBackward0]
	140182247752608 -> 140182247751888
	140182675107536 [label="encoder.stages.2.0.convs.1.norm.bias
 (128)" fillcolor=lightblue]
	140182675107536 -> 140182247752608
	140182247752608 [label=AccumulateGrad]
	140182247751840 -> 140182247718864
	140182675107632 [label="encoder.stages.3.0.convs.0.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140182675107632 -> 140182247751840
	140182247751840 [label=AccumulateGrad]
	140182247751792 -> 140182247718864
	140182675107728 [label="encoder.stages.3.0.convs.0.conv.bias
 (256)" fillcolor=lightblue]
	140182675107728 -> 140182247751792
	140182247751792 [label=AccumulateGrad]
	140182247718672 -> 140182247718624
	140182247718672 [label=RepeatBackward0]
	140182247718816 -> 140182247718672
	140182675107824 [label="encoder.stages.3.0.convs.0.norm.weight
 (256)" fillcolor=lightblue]
	140182675107824 -> 140182247718816
	140182247718816 [label=AccumulateGrad]
	140182247718432 -> 140182247718624
	140182247718432 [label=RepeatBackward0]
	140182247752032 -> 140182247718432
	140182675107920 [label="encoder.stages.3.0.convs.0.norm.bias
 (256)" fillcolor=lightblue]
	140182675107920 -> 140182247752032
	140182247752032 [label=AccumulateGrad]
	140182247718288 -> 140182247718240
	140182675108016 [label="encoder.stages.3.0.convs.1.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140182675108016 -> 140182247718288
	140182247718288 [label=AccumulateGrad]
	140182247718144 -> 140182247718240
	140182675108112 [label="encoder.stages.3.0.convs.1.conv.bias
 (256)" fillcolor=lightblue]
	140182675108112 -> 140182247718144
	140182247718144 [label=AccumulateGrad]
	140182247718000 -> 140182247717952
	140182247718000 [label=RepeatBackward0]
	140182247718480 -> 140182247718000
	140182675108208 [label="encoder.stages.3.0.convs.1.norm.weight
 (256)" fillcolor=lightblue]
	140182675108208 -> 140182247718480
	140182247718480 [label=AccumulateGrad]
	140182247717760 -> 140182247717952
	140182247717760 [label=RepeatBackward0]
	140182247718576 -> 140182247717760
	140182675108304 [label="encoder.stages.3.0.convs.1.norm.bias
 (256)" fillcolor=lightblue]
	140182675108304 -> 140182247718576
	140182247718576 [label=AccumulateGrad]
	140182247717712 -> 140182247717616
	140182675108400 [label="encoder.stages.4.0.convs.0.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	140182675108400 -> 140182247717712
	140182247717712 [label=AccumulateGrad]
	140182247717664 -> 140182247717616
	140182675108496 [label="encoder.stages.4.0.convs.0.conv.bias
 (512)" fillcolor=lightblue]
	140182675108496 -> 140182247717664
	140182247717664 [label=AccumulateGrad]
	140182247717376 -> 140182247717328
	140182247717376 [label=RepeatBackward0]
	140182247717808 -> 140182247717376
	140182675108592 [label="encoder.stages.4.0.convs.0.norm.weight
 (512)" fillcolor=lightblue]
	140182675108592 -> 140182247717808
	140182247717808 [label=AccumulateGrad]
	140182247717136 -> 140182247717328
	140182247717136 [label=RepeatBackward0]
	140182247717904 -> 140182247717136
	140182675108688 [label="encoder.stages.4.0.convs.0.norm.bias
 (512)" fillcolor=lightblue]
	140182675108688 -> 140182247717904
	140182247717904 [label=AccumulateGrad]
	140182247716992 -> 140182247716944
	140182675108784 [label="encoder.stages.4.0.convs.1.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140182675108784 -> 140182247716992
	140182247716992 [label=AccumulateGrad]
	140182247716848 -> 140182247716944
	140182675108880 [label="encoder.stages.4.0.convs.1.conv.bias
 (512)" fillcolor=lightblue]
	140182675108880 -> 140182247716848
	140182247716848 [label=AccumulateGrad]
	140182247716704 -> 140182247716656
	140182247716704 [label=RepeatBackward0]
	140182247717184 -> 140182247716704
	140182675108976 [label="encoder.stages.4.0.convs.1.norm.weight
 (512)" fillcolor=lightblue]
	140182675108976 -> 140182247717184
	140182247717184 [label=AccumulateGrad]
	140182247716464 -> 140182247716656
	140182247716464 [label=RepeatBackward0]
	140182247717280 -> 140182247716464
	140182675109072 [label="encoder.stages.4.0.convs.1.norm.bias
 (512)" fillcolor=lightblue]
	140182675109072 -> 140182247717280
	140182247717280 [label=AccumulateGrad]
	140182247716416 -> 140182247716320
	140182675109168 [label="encoder.stages.5.0.convs.0.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140182675109168 -> 140182247716416
	140182247716416 [label=AccumulateGrad]
	140182247716368 -> 140182247716320
	140182675109264 [label="encoder.stages.5.0.convs.0.conv.bias
 (512)" fillcolor=lightblue]
	140182675109264 -> 140182247716368
	140182247716368 [label=AccumulateGrad]
	140182247716080 -> 140182247716032
	140182247716080 [label=RepeatBackward0]
	140182247716512 -> 140182247716080
	140182675109360 [label="encoder.stages.5.0.convs.0.norm.weight
 (512)" fillcolor=lightblue]
	140182675109360 -> 140182247716512
	140182247716512 [label=AccumulateGrad]
	140182247715840 -> 140182247716032
	140182247715840 [label=RepeatBackward0]
	140182247716608 -> 140182247715840
	140182675109456 [label="encoder.stages.5.0.convs.0.norm.bias
 (512)" fillcolor=lightblue]
	140182675109456 -> 140182247716608
	140182247716608 [label=AccumulateGrad]
	140182247715696 -> 140182247715648
	140182675109552 [label="encoder.stages.5.0.convs.1.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140182675109552 -> 140182247715696
	140182247715696 [label=AccumulateGrad]
	140182247715552 -> 140182247715648
	140182675109648 [label="encoder.stages.5.0.convs.1.conv.bias
 (512)" fillcolor=lightblue]
	140182675109648 -> 140182247715552
	140182247715552 [label=AccumulateGrad]
	140182247715408 -> 140182247715360
	140182247715408 [label=RepeatBackward0]
	140182247715888 -> 140182247715408
	140182675109744 [label="encoder.stages.5.0.convs.1.norm.weight
 (512)" fillcolor=lightblue]
	140182675109744 -> 140182247715888
	140182247715888 [label=AccumulateGrad]
	140182247715168 -> 140182247715360
	140182247715168 [label=RepeatBackward0]
	140182247715984 -> 140182247715168
	140182675109840 [label="encoder.stages.5.0.convs.1.norm.bias
 (512)" fillcolor=lightblue]
	140182675109840 -> 140182247715984
	140182247715984 [label=AccumulateGrad]
	140182247715120 -> 140182247715024
	140182675109936 [label="encoder.stages.6.0.convs.0.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140182675109936 -> 140182247715120
	140182247715120 [label=AccumulateGrad]
	140182247715072 -> 140182247715024
	140182675110032 [label="encoder.stages.6.0.convs.0.conv.bias
 (512)" fillcolor=lightblue]
	140182675110032 -> 140182247715072
	140182247715072 [label=AccumulateGrad]
	140182247714784 -> 140182247714736
	140182247714784 [label=RepeatBackward0]
	140182247715216 -> 140182247714784
	140182675110128 [label="encoder.stages.6.0.convs.0.norm.weight
 (512)" fillcolor=lightblue]
	140182675110128 -> 140182247715216
	140182247715216 [label=AccumulateGrad]
	140182247714544 -> 140182247714736
	140182247714544 [label=RepeatBackward0]
	140182247715312 -> 140182247714544
	140182675110224 [label="encoder.stages.6.0.convs.0.norm.bias
 (512)" fillcolor=lightblue]
	140182675110224 -> 140182247715312
	140182247715312 [label=AccumulateGrad]
	140182247714400 -> 140182247714352
	140182675110320 [label="encoder.stages.6.0.convs.1.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140182675110320 -> 140182247714400
	140182247714400 [label=AccumulateGrad]
	140182247714256 -> 140182247714352
	140182675110416 [label="encoder.stages.6.0.convs.1.conv.bias
 (512)" fillcolor=lightblue]
	140182675110416 -> 140182247714256
	140182247714256 [label=AccumulateGrad]
	140182247714112 -> 140182247714064
	140182247714112 [label=RepeatBackward0]
	140182247714592 -> 140182247714112
	140182675110512 [label="encoder.stages.6.0.convs.1.norm.weight
 (512)" fillcolor=lightblue]
	140182675110512 -> 140182247714592
	140182247714592 [label=AccumulateGrad]
	140182247713872 -> 140182247714064
	140182247713872 [label=RepeatBackward0]
	140182247714688 -> 140182247713872
	140182675110608 [label="encoder.stages.6.0.convs.1.norm.bias
 (512)" fillcolor=lightblue]
	140182675110608 -> 140182247714688
	140182247714688 [label=AccumulateGrad]
	140182247713728 -> 140182247713632
	140182675110704 [label="decoder.transpconvs.0.weight
 (512, 512, 2, 2)" fillcolor=lightblue]
	140182675110704 -> 140182247713728
	140182247713728 [label=AccumulateGrad]
	140182247713680 -> 140182247713632
	140182675110800 [label="decoder.transpconvs.0.bias
 (512)" fillcolor=lightblue]
	140182675110800 -> 140182247713680
	140182247713680 [label=AccumulateGrad]
	140182247713584 -> 140182247713440
	140182247713392 -> 140182247713344
	140182675110896 [label="decoder.stages.0.convs.0.conv.weight
 (512, 1024, 3, 3)" fillcolor=lightblue]
	140182675110896 -> 140182247713392
	140182247713392 [label=AccumulateGrad]
	140182247713248 -> 140182247713344
	140182675110992 [label="decoder.stages.0.convs.0.conv.bias
 (512)" fillcolor=lightblue]
	140182675110992 -> 140182247713248
	140182247713248 [label=AccumulateGrad]
	140182247713104 -> 140182247713056
	140182247713104 [label=RepeatBackward0]
	140182247713536 -> 140182247713104
	140182675111088 [label="decoder.stages.0.convs.0.norm.weight
 (512)" fillcolor=lightblue]
	140182675111088 -> 140182247713536
	140182247713536 [label=AccumulateGrad]
	140182247712864 -> 140182247713056
	140182247712864 [label=RepeatBackward0]
	140182247713824 -> 140182247712864
	140182675111184 [label="decoder.stages.0.convs.0.norm.bias
 (512)" fillcolor=lightblue]
	140182675111184 -> 140182247713824
	140182247713824 [label=AccumulateGrad]
	140182247712720 -> 140182247712672
	140182675111280 [label="decoder.stages.0.convs.1.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140182675111280 -> 140182247712720
	140182247712720 [label=AccumulateGrad]
	140182247712576 -> 140182247712672
	140182675111376 [label="decoder.stages.0.convs.1.conv.bias
 (512)" fillcolor=lightblue]
	140182675111376 -> 140182247712576
	140182247712576 [label=AccumulateGrad]
	140182247712432 -> 140182247712384
	140182247712432 [label=RepeatBackward0]
	140182247712912 -> 140182247712432
	140182675111472 [label="decoder.stages.0.convs.1.norm.weight
 (512)" fillcolor=lightblue]
	140182675111472 -> 140182247712912
	140182247712912 [label=AccumulateGrad]
	140182247712192 -> 140182247712384
	140182247712192 [label=RepeatBackward0]
	140182247713008 -> 140182247712192
	140182675111568 [label="decoder.stages.0.convs.1.norm.bias
 (512)" fillcolor=lightblue]
	140182675111568 -> 140182247713008
	140182247713008 [label=AccumulateGrad]
	140182247712048 -> 140182247711952
	140182675111856 [label="decoder.transpconvs.1.weight
 (512, 512, 2, 2)" fillcolor=lightblue]
	140182675111856 -> 140182247712048
	140182247712048 [label=AccumulateGrad]
	140182247712000 -> 140182247711952
	140182673440848 [label="decoder.transpconvs.1.bias
 (512)" fillcolor=lightblue]
	140182673440848 -> 140182247712000
	140182247712000 [label=AccumulateGrad]
	140182247711904 -> 140182247711760
	140182247711712 -> 140182247711664
	140182673440944 [label="decoder.stages.1.convs.0.conv.weight
 (512, 1024, 3, 3)" fillcolor=lightblue]
	140182673440944 -> 140182247711712
	140182247711712 [label=AccumulateGrad]
	140182247711568 -> 140182247711664
	140182673441040 [label="decoder.stages.1.convs.0.conv.bias
 (512)" fillcolor=lightblue]
	140182673441040 -> 140182247711568
	140182247711568 [label=AccumulateGrad]
	140182247711424 -> 140182247711376
	140182247711424 [label=RepeatBackward0]
	140182247711856 -> 140182247711424
	140182673441136 [label="decoder.stages.1.convs.0.norm.weight
 (512)" fillcolor=lightblue]
	140182673441136 -> 140182247711856
	140182247711856 [label=AccumulateGrad]
	140182247711184 -> 140182247711376
	140182247711184 [label=RepeatBackward0]
	140182247712144 -> 140182247711184
	140182673441232 [label="decoder.stages.1.convs.0.norm.bias
 (512)" fillcolor=lightblue]
	140182673441232 -> 140182247712144
	140182247712144 [label=AccumulateGrad]
	140182247711040 -> 140182247710992
	140182673441328 [label="decoder.stages.1.convs.1.conv.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140182673441328 -> 140182247711040
	140182247711040 [label=AccumulateGrad]
	140182247710896 -> 140182247710992
	140182673441424 [label="decoder.stages.1.convs.1.conv.bias
 (512)" fillcolor=lightblue]
	140182673441424 -> 140182247710896
	140182247710896 [label=AccumulateGrad]
	140182247710752 -> 140182247710704
	140182247710752 [label=RepeatBackward0]
	140182247711232 -> 140182247710752
	140182673441520 [label="decoder.stages.1.convs.1.norm.weight
 (512)" fillcolor=lightblue]
	140182673441520 -> 140182247711232
	140182247711232 [label=AccumulateGrad]
	140182247710512 -> 140182247710704
	140182247710512 [label=RepeatBackward0]
	140182247711328 -> 140182247710512
	140182673441616 [label="decoder.stages.1.convs.1.norm.bias
 (512)" fillcolor=lightblue]
	140182673441616 -> 140182247711328
	140182247711328 [label=AccumulateGrad]
	140182247710368 -> 140182247710272
	140182673441904 [label="decoder.transpconvs.2.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	140182673441904 -> 140182247710368
	140182247710368 [label=AccumulateGrad]
	140182247710320 -> 140182247710272
	140182673442000 [label="decoder.transpconvs.2.bias
 (256)" fillcolor=lightblue]
	140182673442000 -> 140182247710320
	140182247710320 [label=AccumulateGrad]
	140182247710224 -> 140182247710080
	140182247710032 -> 140182247709984
	140182673442096 [label="decoder.stages.2.convs.0.conv.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	140182673442096 -> 140182247710032
	140182247710032 [label=AccumulateGrad]
	140182247709888 -> 140182247709984
	140182673442192 [label="decoder.stages.2.convs.0.conv.bias
 (256)" fillcolor=lightblue]
	140182673442192 -> 140182247709888
	140182247709888 [label=AccumulateGrad]
	140182247709744 -> 140182247709696
	140182247709744 [label=RepeatBackward0]
	140182247710176 -> 140182247709744
	140182673442288 [label="decoder.stages.2.convs.0.norm.weight
 (256)" fillcolor=lightblue]
	140182673442288 -> 140182247710176
	140182247710176 [label=AccumulateGrad]
	140182247709504 -> 140182247709696
	140182247709504 [label=RepeatBackward0]
	140182247710464 -> 140182247709504
	140182673442384 [label="decoder.stages.2.convs.0.norm.bias
 (256)" fillcolor=lightblue]
	140182673442384 -> 140182247710464
	140182247710464 [label=AccumulateGrad]
	140182247709360 -> 140182247709312
	140182673442480 [label="decoder.stages.2.convs.1.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140182673442480 -> 140182247709360
	140182247709360 [label=AccumulateGrad]
	140182247709216 -> 140182247709312
	140182673442576 [label="decoder.stages.2.convs.1.conv.bias
 (256)" fillcolor=lightblue]
	140182673442576 -> 140182247709216
	140182247709216 [label=AccumulateGrad]
	140182247709072 -> 140182247709024
	140182247709072 [label=RepeatBackward0]
	140182247709552 -> 140182247709072
	140182673442672 [label="decoder.stages.2.convs.1.norm.weight
 (256)" fillcolor=lightblue]
	140182673442672 -> 140182247709552
	140182247709552 [label=AccumulateGrad]
	140182247708832 -> 140182247709024
	140182247708832 [label=RepeatBackward0]
	140182247709648 -> 140182247708832
	140182673442768 [label="decoder.stages.2.convs.1.norm.bias
 (256)" fillcolor=lightblue]
	140182673442768 -> 140182247709648
	140182247709648 [label=AccumulateGrad]
	140182247708688 -> 140182247708592
	140182673443056 [label="decoder.transpconvs.3.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	140182673443056 -> 140182247708688
	140182247708688 [label=AccumulateGrad]
	140182247708640 -> 140182247708592
	140182673443152 [label="decoder.transpconvs.3.bias
 (128)" fillcolor=lightblue]
	140182673443152 -> 140182247708640
	140182247708640 [label=AccumulateGrad]
	140182247708544 -> 140182247708400
	140182247708352 -> 140182247708304
	140182673443248 [label="decoder.stages.3.convs.0.conv.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	140182673443248 -> 140182247708352
	140182247708352 [label=AccumulateGrad]
	140182247708208 -> 140182247708304
	140182673443344 [label="decoder.stages.3.convs.0.conv.bias
 (128)" fillcolor=lightblue]
	140182673443344 -> 140182247708208
	140182247708208 [label=AccumulateGrad]
	140182247708064 -> 140182247708016
	140182247708064 [label=RepeatBackward0]
	140182247708496 -> 140182247708064
	140182673443440 [label="decoder.stages.3.convs.0.norm.weight
 (128)" fillcolor=lightblue]
	140182673443440 -> 140182247708496
	140182247708496 [label=AccumulateGrad]
	140182247707824 -> 140182247708016
	140182247707824 [label=RepeatBackward0]
	140182247708784 -> 140182247707824
	140182673443536 [label="decoder.stages.3.convs.0.norm.bias
 (128)" fillcolor=lightblue]
	140182673443536 -> 140182247708784
	140182247708784 [label=AccumulateGrad]
	140182247707680 -> 140182247707632
	140182673443632 [label="decoder.stages.3.convs.1.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140182673443632 -> 140182247707680
	140182247707680 [label=AccumulateGrad]
	140182247707536 -> 140182247707632
	140182673443728 [label="decoder.stages.3.convs.1.conv.bias
 (128)" fillcolor=lightblue]
	140182673443728 -> 140182247707536
	140182247707536 [label=AccumulateGrad]
	140182247707392 -> 140182247707344
	140182247707392 [label=RepeatBackward0]
	140182247707872 -> 140182247707392
	140182673443824 [label="decoder.stages.3.convs.1.norm.weight
 (128)" fillcolor=lightblue]
	140182673443824 -> 140182247707872
	140182247707872 [label=AccumulateGrad]
	140182247707152 -> 140182247707344
	140182247707152 [label=RepeatBackward0]
	140182247707968 -> 140182247707152
	140182673443920 [label="decoder.stages.3.convs.1.norm.bias
 (128)" fillcolor=lightblue]
	140182673443920 -> 140182247707968
	140182247707968 [label=AccumulateGrad]
	140182247707008 -> 140182247706912
	140182673444208 [label="decoder.transpconvs.4.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	140182673444208 -> 140182247707008
	140182247707008 [label=AccumulateGrad]
	140182247706960 -> 140182247706912
	140182673444304 [label="decoder.transpconvs.4.bias
 (64)" fillcolor=lightblue]
	140182673444304 -> 140182247706960
	140182247706960 [label=AccumulateGrad]
	140182247706864 -> 140182247706720
	140182247706672 -> 140182247706624
	140182673444400 [label="decoder.stages.4.convs.0.conv.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	140182673444400 -> 140182247706672
	140182247706672 [label=AccumulateGrad]
	140182247706528 -> 140182247706624
	140182673444496 [label="decoder.stages.4.convs.0.conv.bias
 (64)" fillcolor=lightblue]
	140182673444496 -> 140182247706528
	140182247706528 [label=AccumulateGrad]
	140182247706384 -> 140182247706336
	140182247706384 [label=RepeatBackward0]
	140182247706816 -> 140182247706384
	140182673444592 [label="decoder.stages.4.convs.0.norm.weight
 (64)" fillcolor=lightblue]
	140182673444592 -> 140182247706816
	140182247706816 [label=AccumulateGrad]
	140182247706192 -> 140182247706336
	140182247706192 [label=RepeatBackward0]
	140182247707104 -> 140182247706192
	140182673444688 [label="decoder.stages.4.convs.0.norm.bias
 (64)" fillcolor=lightblue]
	140182673444688 -> 140182247707104
	140182247707104 [label=AccumulateGrad]
	140182253715072 -> 140182247706096
	140182673444784 [label="decoder.stages.4.convs.1.conv.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140182673444784 -> 140182253715072
	140182253715072 [label=AccumulateGrad]
	140182650406224 -> 140182247706096
	140182673444880 [label="decoder.stages.4.convs.1.conv.bias
 (64)" fillcolor=lightblue]
	140182673444880 -> 140182650406224
	140182650406224 [label=AccumulateGrad]
	140182247705856 -> 140182247705808
	140182247705856 [label=RepeatBackward0]
	140182672262432 -> 140182247705856
	140182673444976 [label="decoder.stages.4.convs.1.norm.weight
 (64)" fillcolor=lightblue]
	140182673444976 -> 140182672262432
	140182672262432 [label=AccumulateGrad]
	140182247705616 -> 140182247705808
	140182247705616 [label=RepeatBackward0]
	140182247706288 -> 140182247705616
	140182673445072 [label="decoder.stages.4.convs.1.norm.bias
 (64)" fillcolor=lightblue]
	140182673445072 -> 140182247706288
	140182247706288 [label=AccumulateGrad]
	140182247705472 -> 140182247705376
	140182673445360 [label="decoder.transpconvs.5.weight
 (64, 32, 2, 2)" fillcolor=lightblue]
	140182673445360 -> 140182247705472
	140182247705472 [label=AccumulateGrad]
	140182247705424 -> 140182247705376
	140182673445456 [label="decoder.transpconvs.5.bias
 (32)" fillcolor=lightblue]
	140182673445456 -> 140182247705424
	140182247705424 [label=AccumulateGrad]
	140182247705328 -> 140182247705184
	140182247705136 -> 140182247705088
	140182673445552 [label="decoder.stages.5.convs.0.conv.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	140182673445552 -> 140182247705136
	140182247705136 [label=AccumulateGrad]
	140182247704992 -> 140182247705088
	140182673445648 [label="decoder.stages.5.convs.0.conv.bias
 (32)" fillcolor=lightblue]
	140182673445648 -> 140182247704992
	140182247704992 [label=AccumulateGrad]
	140182247704848 -> 140182247704800
	140182247704848 [label=RepeatBackward0]
	140182247705280 -> 140182247704848
	140182673445744 [label="decoder.stages.5.convs.0.norm.weight
 (32)" fillcolor=lightblue]
	140182673445744 -> 140182247705280
	140182247705280 [label=AccumulateGrad]
	140182247704608 -> 140182247704800
	140182247704608 [label=RepeatBackward0]
	140182247705568 -> 140182247704608
	140182673445840 [label="decoder.stages.5.convs.0.norm.bias
 (32)" fillcolor=lightblue]
	140182673445840 -> 140182247705568
	140182247705568 [label=AccumulateGrad]
	140182247704464 -> 140182247704416
	140182673445936 [label="decoder.stages.5.convs.1.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140182673445936 -> 140182247704464
	140182247704464 [label=AccumulateGrad]
	140182247702976 -> 140182247704416
	140182673446032 [label="decoder.stages.5.convs.1.conv.bias
 (32)" fillcolor=lightblue]
	140182673446032 -> 140182247702976
	140182247702976 [label=AccumulateGrad]
	140182247704272 -> 140182247704224
	140182247704272 [label=RepeatBackward0]
	140182247704656 -> 140182247704272
	140182673446128 [label="decoder.stages.5.convs.1.norm.weight
 (32)" fillcolor=lightblue]
	140182673446128 -> 140182247704656
	140182247704656 [label=AccumulateGrad]
	140182247703936 -> 140182247704224
	140182247703936 [label=RepeatBackward0]
	140182247704752 -> 140182247703936
	140182673446224 [label="decoder.stages.5.convs.1.norm.bias
 (32)" fillcolor=lightblue]
	140182673446224 -> 140182247704752
	140182247704752 [label=AccumulateGrad]
	140182247703792 -> 140182247703696
	140182673446320 [label="decoder.seg_layers.5.weight
 (2, 32, 1, 1)" fillcolor=lightblue]
	140182673446320 -> 140182247703792
	140182247703792 [label=AccumulateGrad]
	140182247703744 -> 140182247703696
	140182673446416 [label="decoder.seg_layers.5.bias
 (2)" fillcolor=lightblue]
	140182673446416 -> 140182247703744
	140182247703744 [label=AccumulateGrad]
	140182247703696 -> 140182249393328
}
